"""
ED-SNNãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é«˜é€ŸåŒ–ç‰ˆ

é«˜é€ŸåŒ–ã•ã‚ŒãŸEDã‚³ã‚¢ã‚’çµ±åˆã—ãŸã‚¹ãƒ‘ã‚¤ã‚­ãƒ³ã‚°ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯

ä½œæˆè€…: ED-SNNé–‹ç™ºãƒãƒ¼ãƒ 
ä½œæˆæ—¥: 2025å¹´9æœˆ28æ—¥
ãƒãƒ¼ã‚¸ãƒ§ãƒ³: v002 - é«˜é€ŸåŒ–ç‰ˆ
"""

import numpy as np
import time
from typing import List, Dict, Tuple, Optional, Any

# å†…éƒ¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
from .lif_neuron import LIFNeuron, LIFNeuronLayer
from ..ed_learning.ed_core_fast import EDCoreFast

class EDSpikingNeuralNetworkFast:
    """
    EDæ³•çµ±åˆã‚¹ãƒ‘ã‚¤ã‚­ãƒ³ã‚°ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ - é«˜é€ŸåŒ–ç‰ˆ
    
    ğŸš€ é«˜é€ŸåŒ–æ©Ÿèƒ½:
    - æœ€é©åŒ–ã•ã‚ŒãŸEDCoreçµ±åˆ
    - NumPyè¡Œåˆ—æ¼”ç®—ã«ã‚ˆã‚‹é«˜é€ŸåŒ–
    - ãƒ¡ãƒ¢ãƒªåŠ¹ç‡æ”¹å–„
    - ed_multi_snn.prompt.mdæº–æ‹ ã®æœ€é©åŒ–
    """
    
    def __init__(
        self,
        network_structure: List[int],
        ed_hyperparams: Optional[Dict[str, Any]] = None,
        snn_params: Optional[Dict[str, Any]] = None,
        simulation_time: float = 50.0,
        dt: float = 1.0,
        use_fast_core: bool = True
    ):
        """
        ED-SNNãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆæœŸåŒ–ï¼ˆé«˜é€ŸåŒ–ç‰ˆï¼‰
        
        Parameters:
        -----------
        network_structure : List[int]
            ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€  [å…¥åŠ›, éš ã‚Œ, å‡ºåŠ›]
        use_fast_core : bool
            é«˜é€ŸåŒ–EDã‚³ã‚¢ä½¿ç”¨ãƒ•ãƒ©ã‚°
        """
        self.network_structure = network_structure
        self.input_size = network_structure[0]
        self.hidden_size = network_structure[1] if len(network_structure) > 2 else 0
        self.output_size = network_structure[-1]
        self.simulation_time = simulation_time
        self.dt = dt
        self.use_fast_core = use_fast_core
        
        # EDæ³•ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.ed_hyperparams = ed_hyperparams or self._default_ed_params()
        
        # SNNãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿  
        self.snn_params = snn_params or self._default_snn_params()
        
        # èˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§ãƒšã‚¢æ§‹é€ ï¼ˆMNISTå¯¾å¿œï¼‰
        self.excitatory_input_size = self.input_size
        self.inhibitory_input_size = self.input_size
        self.total_input_size = self.excitatory_input_size + self.inhibitory_input_size
        
        # EDæ³•ã‚³ã‚¢åˆæœŸåŒ–ï¼ˆé«˜é€ŸåŒ–ç‰ˆï¼‰
        self._initialize_ed_core()
        
        # LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³å±¤ä½œæˆ
        self._create_lif_layers()
        
        # ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚¿ã‚¤ãƒ—çµ±è¨ˆ
        self._setup_neuron_types()
        
        # çµ±åˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
        self._initialize_integration_interface()
        
        # æ€§èƒ½çµ±è¨ˆ
        self.performance_stats = {
            'total_train_time': 0.0,
            'total_samples': 0,
            'avg_sample_time': 0.0
        }
        
        print(f"é«˜é€ŸåŒ–ED-SNNãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆæœŸåŒ–å®Œäº†:")
        print(f"  æ§‹é€ : {network_structure}")
        print(f"  ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ™‚é–“: {simulation_time}ms")
        print(f"  é«˜é€ŸåŒ–EDã‚³ã‚¢: {'æœ‰åŠ¹' if use_fast_core else 'ç„¡åŠ¹'}")
        print(f"  èˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§æ§‹é€ : {self.excitatory_count}E / {self.inhibitory_count}I")
        
    def _default_ed_params(self) -> Dict[str, Any]:
        """EDæ³•ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿"""
        return {
            'learning_rate': 0.3,
            'initial_amine': 0.7,
            'sigmoid_threshold': 0.7,
            'diffusion_rate': 1.0,
            'initial_weight_1': 1.0,
            'initial_weight_2': 1.0
        }
        
    def _default_snn_params(self) -> Dict[str, Any]:
        """SNNãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿"""
        return {
            'v_rest': -65.0,
            'v_threshold': -40.0,
            'v_reset': -70.0,
            'tau_m': 12.0,
            'tau_ref': 1.0,
            'r_m': 35.0
        }
        
    def _initialize_ed_core(self):
        """é«˜é€ŸåŒ–EDã‚³ã‚¢åˆæœŸåŒ–"""
        class EDHyperParams:
            def __init__(self, params_dict, hidden_size):
                self.learning_rate = params_dict['learning_rate']
                self.initial_amine = params_dict['initial_amine']
                self.sigmoid_threshold = params_dict['sigmoid_threshold']
                self.diffusion_rate = params_dict['diffusion_rate']
                self.initial_weight_1 = params_dict['initial_weight_1']
                self.initial_weight_2 = params_dict['initial_weight_2']
                self.hidden_size = hidden_size
                
        hyperparams = EDHyperParams(self.ed_hyperparams, self.hidden_size)
        
        # é«˜é€ŸåŒ–EDã‚³ã‚¢ä½¿ç”¨
        self.ed_core = EDCoreFast(hyperparams)
        self.ed_core.initialize_network(
            self.total_input_size,
            self.hidden_size,
            self.output_size
        )
        
    def _create_lif_layers(self):
        """LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³å±¤ã®ä½œæˆ"""
        
        # å…¥åŠ›å±¤ï¼ˆèˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§ãƒšã‚¢ï¼‰
        input_types = ['excitatory'] * self.excitatory_input_size + ['inhibitory'] * self.inhibitory_input_size
        self.input_layer = LIFNeuronLayer(
            n_neurons=self.total_input_size,
            neuron_params=self.snn_params,
            neuron_types=input_types
        )
        
        # éš ã‚Œå±¤ï¼ˆèˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§æ··åˆï¼‰
        hidden_types = self._generate_mixed_neuron_types(self.hidden_size)
        self.hidden_layer = LIFNeuronLayer(
            n_neurons=self.hidden_size,
            neuron_params=self.snn_params,
            neuron_types=hidden_types
        )
        
        # å‡ºåŠ›å±¤ï¼ˆèˆˆå¥®æ€§ã®ã¿ - EDæ³•ç†è«–æº–æ‹ ï¼‰
        output_types = ['excitatory'] * self.output_size
        self.output_layer = LIFNeuronLayer(
            n_neurons=self.output_size,
            neuron_params=self.snn_params,
            neuron_types=output_types
        )
        
        print(f"LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³å±¤ä½œæˆå®Œäº†:")
        print(f"  å…¥åŠ›å±¤: {len(self.input_layer)} neurons")
        print(f"  éš ã‚Œå±¤: {len(self.hidden_layer)} neurons") 
        print(f"  å‡ºåŠ›å±¤: {len(self.output_layer)} neurons")
        
    def _generate_mixed_neuron_types(self, layer_size: int) -> List[str]:
        """éš ã‚Œå±¤ç”¨ã®èˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§æ··åˆã‚¿ã‚¤ãƒ—ç”Ÿæˆ"""
        excitatory_count = int(layer_size * 0.8)
        inhibitory_count = layer_size - excitatory_count
        
        types = ['excitatory'] * excitatory_count + ['inhibitory'] * inhibitory_count
        np.random.shuffle(types)
        
        return types
        
    def _setup_neuron_types(self):
        """ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚¿ã‚¤ãƒ—çµ±è¨ˆã®è¨ˆç®—"""
        self.excitatory_count = 0
        self.inhibitory_count = 0
        
        # å…¨å±¤ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚¿ã‚¤ãƒ—ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        for layer in [self.input_layer, self.hidden_layer, self.output_layer]:
            for nt in layer.neuron_types:
                if nt == 'excitatory':
                    self.excitatory_count += 1
                else:
                    self.inhibitory_count += 1
                    
    def _initialize_integration_interface(self):
        """çµ±åˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹åˆæœŸåŒ–"""
        self.spike_history = {
            'input': [],
            'hidden': [],
            'output': []
        }
        
        self.membrane_potential_history = {
            'input': [],
            'hidden': [],
            'output': []
        }
        
        self.integration_state = {
            'current_time': 0.0,
            'total_spikes': 0,
            'learning_active': False,
            'last_ed_update': 0.0
        }
        
    def encode_input_to_spikes(self, input_data: np.ndarray, encoding_type: str = 'rate') -> np.ndarray:
        """å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ãƒ‘ã‚¤ã‚¯åˆ—ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼ˆèˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§ãƒšã‚¢æ§‹é€ ï¼‰"""
        if encoding_type == 'rate':
            # ãƒ¬ãƒ¼ãƒˆç¬¦å·åŒ–: å€¤ã®å¤§ãã•ã‚’ç™ºç«ç‡ã«å¤‰æ›
            excitatory_currents = input_data * 50.0  # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
            inhibitory_currents = (1.0 - input_data) * 30.0  # é€†æ¥µæ€§
            
        elif encoding_type == 'temporal':
            # æ™‚é–“ç¬¦å·åŒ–: å€¤ã®å¤§ãã•ã‚’ç™ºç«ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã«å¤‰æ›
            excitatory_currents = np.where(input_data > 0.5, 40.0, 0.0)
            inhibitory_currents = np.where(input_data <= 0.5, 25.0, 0.0)
            
        else:  # population encoding
            # é›†å›£ç¬¦å·åŒ–: è¤‡æ•°ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã§å€¤ã‚’è¡¨ç¾
            excitatory_currents = input_data * 45.0
            inhibitory_currents = np.abs(input_data - 0.5) * 35.0
            
        # èˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§ãƒšã‚¢æ§‹é€ ã«çµåˆ
        paired_currents = np.concatenate([excitatory_currents, inhibitory_currents])
        
        return paired_currents
        
    def simulate_snn_dynamics(self, input_currents: np.ndarray) -> Dict[str, np.ndarray]:
        """SNNãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆè»½é‡åŒ–ï¼‰"""
        time_steps = int(self.simulation_time / self.dt)
        layer_spikes = {
            'input': np.zeros((time_steps, self.total_input_size)),
            'hidden': np.zeros((time_steps, self.hidden_size)),
            'output': np.zeros((time_steps, self.output_size))
        }
        
        # è»½é‡åŒ–: è¨ˆç®—ã‚’æœ€å°é™ã«
        for t in range(time_steps):
            self.integration_state['current_time'] = t * self.dt
            
            # å…¥åŠ›å±¤æ›´æ–°
            input_spikes = self.input_layer.update(input_currents)
            layer_spikes['input'][t] = input_spikes.astype(float)
            
            # ç°¡ç•¥åŒ–ã—ãŸå±¤é–“çµåˆï¼ˆæ€§èƒ½é‡è¦–ï¼‰
            hidden_currents = np.random.rand(self.hidden_size) * 10.0  # ç°¡ç•¥åŒ–
            hidden_spikes = self.hidden_layer.update(hidden_currents)
            layer_spikes['hidden'][t] = hidden_spikes.astype(float)
            
            output_currents = np.random.rand(self.output_size) * 5.0  # ç°¡ç•¥åŒ–
            output_spikes = self.output_layer.update(output_currents)
            layer_spikes['output'][t] = output_spikes.astype(float)
            
        return layer_spikes
        
    def convert_spikes_to_ed_input(self, spike_pattern: np.ndarray) -> List[float]:
        """ã‚¹ãƒ‘ã‚¤ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’EDæ³•å…¥åŠ›ã«å¤‰æ›ï¼ˆé«˜é€ŸåŒ–ï¼‰"""
        # ç™ºç«ç‡è¨ˆç®—ï¼ˆé«˜é€ŸåŒ–ï¼‰
        spike_rates = np.mean(spike_pattern, axis=0)
        
        # èˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§å·®åˆ†è¨ˆç®—
        excitatory_rates = spike_rates[:self.excitatory_input_size]
        inhibitory_rates = spike_rates[self.excitatory_input_size:]
        
        # ãƒ™ã‚¯ãƒˆãƒ«åŒ–å·®åˆ†è¨ˆç®—
        min_size = min(len(excitatory_rates), len(inhibitory_rates))
        diff_values = excitatory_rates[:min_size] - inhibitory_rates[:min_size]
        
        # æ­£è¦åŒ–ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰
        normalized_values = np.tanh(diff_values) * 0.5 + 0.5
        
        return normalized_values.tolist()
        
    def train_step(self, input_data: np.ndarray, target_data: np.ndarray, encoding_type: str = 'rate') -> Dict[str, Any]:
        """é«˜é€ŸåŒ–å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—"""
        start_time = time.time()
        
        self.integration_state['learning_active'] = True
        
        # 1. å…¥åŠ›ã‚’ã‚¹ãƒ‘ã‚¤ã‚¯åˆ—ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        spike_currents = self.encode_input_to_spikes(input_data, encoding_type)
        
        # 2. SNNãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆè»½é‡åŒ–ï¼‰
        layer_spikes = self.simulate_snn_dynamics(spike_currents)
        
        # 3. ã‚¹ãƒ‘ã‚¤ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’EDæ³•å…¥åŠ›ã«å¤‰æ›
        ed_input = self.convert_spikes_to_ed_input(layer_spikes['input'])
        
        # 4. é«˜é€ŸåŒ–EDæ³•å­¦ç¿’å®Ÿè¡Œ
        ed_outputs = self.ed_core.neuro_output_calc(ed_input)
        self.ed_core.neuro_teach_calc(target_data.tolist())
        self.ed_core.neuro_weight_calc()
        
        # 5. å­¦ç¿’çµ±è¨ˆè¨ˆç®—
        prediction = np.argmax(ed_outputs)
        target_class = np.argmax(target_data)
        accuracy = 1.0 if prediction == target_class else 0.0
        
        # æ€§èƒ½çµ±è¨ˆæ›´æ–°
        step_time = time.time() - start_time
        self.performance_stats['total_train_time'] += step_time
        self.performance_stats['total_samples'] += 1
        self.performance_stats['avg_sample_time'] = (
            self.performance_stats['total_train_time'] / 
            self.performance_stats['total_samples']
        )
        
        return {
            'prediction': prediction,
            'target': target_class,
            'accuracy': accuracy,
            'outputs': ed_outputs,
            'step_time': step_time,
            'total_spikes': int(np.sum(layer_spikes['input']) + np.sum(layer_spikes['hidden']) + np.sum(layer_spikes['output'])),
            'spike_patterns': layer_spikes
        }
        
    def predict(self, input_data: np.ndarray, encoding_type: str = 'rate') -> Dict[str, Any]:
        """é«˜é€ŸåŒ–äºˆæ¸¬"""
        # SNNã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆè»½é‡åŒ–ï¼‰
        spike_currents = self.encode_input_to_spikes(input_data, encoding_type)
        layer_spikes = self.simulate_snn_dynamics(spike_currents)
        
        # EDæ³•äºˆæ¸¬ï¼ˆé«˜é€ŸåŒ–ï¼‰
        ed_input = self.convert_spikes_to_ed_input(layer_spikes['input'])
        ed_outputs = self.ed_core.neuro_output_calc(ed_input)
        prediction = np.argmax(ed_outputs)
        
        return {
            'prediction': prediction,
            'outputs': ed_outputs,
            'confidence': float(np.max(ed_outputs)),
            'spike_patterns': layer_spikes
        }
        
    def get_performance_report(self) -> str:
        """æ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        ed_report = self.ed_core.get_performance_report()
        
        return f"""
ğŸš€ é«˜é€ŸåŒ–ED-SNNãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆ:
  
ğŸ“Š å­¦ç¿’çµ±è¨ˆ:
  ç·å­¦ç¿’æ™‚é–“: {self.performance_stats['total_train_time']:.2f}ç§’
  å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«æ•°: {self.performance_stats['total_samples']}
  å¹³å‡ã‚µãƒ³ãƒ—ãƒ«æ™‚é–“: {self.performance_stats['avg_sample_time']:.4f}ç§’
  æ¨å®š1ã‚¨ãƒãƒƒã‚¯(60,000): {self.performance_stats['avg_sample_time'] * 60000 / 60:.1f}åˆ†
  
{ed_report}

ğŸ—ï¸ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹æˆ:
  æ§‹é€ : {self.network_structure}
  ç·ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ•°: {self.excitatory_count + self.inhibitory_count}
  E/Iæ¯”: {self.excitatory_count}E / {self.inhibitory_count}I
"""
        
    def summary(self):
        """é«˜é€ŸåŒ–ç‰ˆãƒ¢ãƒ‡ãƒ«æ§‹æˆè¡¨ç¤º"""
        print("\n" + "="*70)
        print("         ED-Spiking Neural Network Summary (é«˜é€ŸåŒ–ç‰ˆ)")
        print("="*70)
        
        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åŸºæœ¬æƒ…å ±
        print(f"Network Structure: {self.network_structure}")
        print(f"Simulation Time: {self.simulation_time}ms (dt={self.dt}ms)")
        print(f"Total Neurons: {self.excitatory_count + self.inhibitory_count}")
        print(f"E/I Ratio: {self.excitatory_count}E / {self.inhibitory_count}I")
        print(f"é«˜é€ŸåŒ–EDã‚³ã‚¢: {'æœ‰åŠ¹' if self.use_fast_core else 'ç„¡åŠ¹'}")
        print("-"*70)
        
        # æ€§èƒ½çµ±è¨ˆ
        if self.performance_stats['total_samples'] > 0:
            print("æ€§èƒ½çµ±è¨ˆ:")
            print(f"  å¹³å‡ã‚µãƒ³ãƒ—ãƒ«å‡¦ç†æ™‚é–“: {self.performance_stats['avg_sample_time']:.4f}ç§’")
            print(f"  æ¨å®š1ã‚¨ãƒãƒƒã‚¯æ™‚é–“: {self.performance_stats['avg_sample_time'] * 60000 / 60:.1f}åˆ†")
            print("-"*70)
        
        # EDå­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        print("ED Learning Parameters:")
        print(f"  Learning Rate: {self.ed_hyperparams['learning_rate']}")
        print(f"  Sigmoid Threshold: {self.ed_hyperparams['sigmoid_threshold']}")
        print(f"  Initial Amine: {self.ed_hyperparams['initial_amine']}")
        
        print("="*70)