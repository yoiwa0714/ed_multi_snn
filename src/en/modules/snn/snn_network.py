"""
SNNãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¯ãƒ©ã‚¹ - EDæ³•çµ±åˆç‰ˆ

LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¨æ©Ÿèƒ½ã™ã‚‹ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹åˆ†é¡EDæ³•ã‚’çµ±åˆ
ed_multi_snn.prompt.mdä»•æ§˜æº–æ‹ 

ä½œæˆè€…: ED-SNNé–‹ç™ºãƒãƒ¼ãƒ 
ä½œæˆæ—¥: 2025å¹´9æœˆ28æ—¥  
ãƒãƒ¼ã‚¸ãƒ§ãƒ³: v001 - åŸºæœ¬çµ±åˆç‰ˆ
ç†è«–æº–æ‹ : é‡‘å­å‹‡æ° Error Diffusion Learning Algorithm + SNNæ‹¡å¼µ
"""

import numpy as np
import time
from typing import List, Dict, Tuple, Optional, Any

# å†…éƒ¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
from .lif_neuron import LIFNeuron, LIFNeuronLayer
from ..ed_learning.ed_core import EDCore
from ..utils.profiler import profile_function, TimingContext, profiler


class EDSpikingNeuralNetwork:
    """
    EDæ³•çµ±åˆã‚¹ãƒ‘ã‚¤ã‚­ãƒ³ã‚°ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
    
    ğŸ¯ æ ¸å¿ƒæ©Ÿèƒ½:
    - LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã«ã‚ˆã‚‹ã‚¹ãƒ‘ã‚¤ã‚¯ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹
    - æ©Ÿèƒ½ã™ã‚‹ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹åˆ†é¡EDæ³•å­¦ç¿’
    - èˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãƒšã‚¢æ§‹é€ 
    - ç‹¬ç«‹å‡ºåŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
    
    ä»•æ§˜æº–æ‹ :
    - ed_multi_snn.prompt.md 100%æº–æ‹ 
    - é‡‘å­å‹‡æ°EDæ³•ç†è«–å®Œå…¨ä¿æŒ
    - SNNæ‹¡å¼µæ©Ÿèƒ½çµ±åˆ
    """
    
    def __init__(
        self,
        network_structure: List[int],
        ed_hyperparams: Optional[Dict[str, Any]] = None,
        snn_params: Optional[Dict[str, Any]] = None,
        simulation_time: float = 50.0,
        dt: float = 1.0
    ):
        """
        ED-SNNãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆæœŸåŒ–
        
        Parameters:
        -----------
        network_structure : List[int]
            ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€  [input_size, hidden_size, output_size]
            ä¾‹: [784, 32, 10] for MNIST
        ed_hyperparams : dict, optional
            EDæ³•ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        snn_params : dict, optional
            SNNãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆLIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³è¨­å®šï¼‰
        simulation_time : float
            ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ™‚é–“ [ms]
        dt : float
            æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ— [ms]
        """
        self.network_structure = network_structure
        self.input_size = network_structure[0]
        self.hidden_size = network_structure[1] if len(network_structure) > 1 else 32
        self.output_size = network_structure[2] if len(network_structure) > 2 else 10
        
        self.simulation_time = simulation_time
        self.dt = dt
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
        self.ed_hyperparams = ed_hyperparams or self._default_ed_params()
        self.snn_params = snn_params or self._default_snn_params()
        
        # EDæ³•ã‚³ã‚¢åˆæœŸåŒ–
        self.ed_core = EDCore(self._create_ed_hyperparams())
        
        # SNNæ§‹é€ åˆæœŸåŒ–ï¼ˆed_multi_snn.prompt.mdæº–æ‹ ï¼‰
        self._initialize_snn_structure()
        
        # çµ±åˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
        self._initialize_integration_interface()
        
        print(f"ED-SNNãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆæœŸåŒ–å®Œäº†:")
        print(f"  æ§‹é€ : {network_structure}")
        print(f"  ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ™‚é–“: {simulation_time}ms")
        print(f"  èˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§æ§‹é€ : {self.excitatory_count}E / {self.inhibitory_count}I")
        
    def _default_ed_params(self) -> Dict[str, Any]:
        """EDæ³•ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆed_v032æº–æ‹ ï¼‰"""
        return {
            'learning_rate': 0.3,      # Phase 2æœ€é©å€¤
            'initial_amine': 0.7,      # Phase 2æœ€é©å€¤
            'sigmoid_threshold': 0.7,  # Phase 1æœ€é©å€¤
            'diffusion_rate': 1.0,
            'initial_weight_1': 1.0,
            'initial_weight_2': 1.0
        }
        
    def _default_snn_params(self) -> Dict[str, Any]:
        """SNNãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆLIFæ¨™æº–å€¤ï¼‰"""
        return {
            'v_rest': -65.0,        # é™æ­¢è†œé›»ä½ [mV]
            'v_threshold': -40.0,   # ç™ºç«é–¾å€¤ [mV]
            'v_reset': -70.0,       # ãƒªã‚»ãƒƒãƒˆé›»ä½ [mV]
            'tau_m': 12.0,          # è†œæ™‚å®šæ•° [ms]
            'tau_ref': 1.0,         # ä¸å¿œæœŸ [ms]
            'r_m': 35.0             # è†œæŠµæŠ— [MÎ©]
        }
        
    def _create_ed_hyperparams(self):
        """EDæ³•ç”¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ"""
        class EDHyperParams:
            def __init__(self, params, hidden_size):
                for key, value in params.items():
                    setattr(self, key, value)
                # éš ã‚Œå±¤ã‚µã‚¤ã‚ºè¿½åŠ 
                self.hidden_neurons = params.get('hidden_neurons', hidden_size)
                    
        return EDHyperParams(self.ed_hyperparams, self.hidden_size)
        
    def _initialize_snn_structure(self):
        """SNNæ§‹é€ åˆæœŸåŒ–ï¼ˆed_multi_snn.prompt.mdæº–æ‹ ï¼‰"""
        
        # ğŸ¯ èˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãƒšã‚¢æ§‹é€ ï¼ˆEDæ³•ç†è«–æº–æ‹ ï¼‰
        # å…¥åŠ›å±¤: èˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§ãƒšã‚¢ã§æ§‹æˆï¼ˆMNIST: 784 â†’ 1568ï¼‰
        self.excitatory_input_size = self.input_size
        self.inhibitory_input_size = self.input_size  
        self.total_input_size = self.excitatory_input_size + self.inhibitory_input_size
        
        print(f"èˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§ãƒšã‚¢æ§‹é€ :")
        print(f"  èˆˆå¥®æ€§å…¥åŠ›: {self.excitatory_input_size}")
        print(f"  æŠ‘åˆ¶æ€§å…¥åŠ›: {self.inhibitory_input_size}")
        print(f"  ç·å…¥åŠ›ã‚µã‚¤ã‚º: {self.total_input_size}")
        
        # EDæ³•ã‚³ã‚¢ã«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ ã‚’è¨­å®š
        self.ed_core.initialize_network(
            self.total_input_size,  # èˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§ãƒšã‚¢å¾Œã‚µã‚¤ã‚º
            self.hidden_size,
            self.output_size
        )
        
        # ğŸ§  LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³å±¤ã®ä½œæˆ
        self._create_lif_layers()
        
        # ğŸ”— ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚¿ã‚¤ãƒ—ã®è¨­å®š
        self._setup_neuron_types()
        
    def _create_lif_layers(self):
        """LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³å±¤ã®ä½œæˆ"""
        
        # å…¥åŠ›å±¤ï¼ˆèˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§ãƒšã‚¢ï¼‰
        input_types = ['excitatory'] * self.excitatory_input_size + ['inhibitory'] * self.inhibitory_input_size
        self.input_layer = LIFNeuronLayer(
            n_neurons=self.total_input_size,
            neuron_params=self.snn_params,
            neuron_types=input_types
        )
        
        # éš ã‚Œå±¤ï¼ˆèˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§æ··åˆï¼‰
        hidden_types = self._generate_mixed_neuron_types(self.hidden_size)
        self.hidden_layer = LIFNeuronLayer(
            n_neurons=self.hidden_size,
            neuron_params=self.snn_params,
            neuron_types=hidden_types
        )
        
        # å‡ºåŠ›å±¤ï¼ˆèˆˆå¥®æ€§ã®ã¿ - EDæ³•ç†è«–æº–æ‹ ï¼‰
        output_types = ['excitatory'] * self.output_size
        self.output_layer = LIFNeuronLayer(
            n_neurons=self.output_size,
            neuron_params=self.snn_params,
            neuron_types=output_types
        )
        
        print(f"LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³å±¤ä½œæˆå®Œäº†:")
        print(f"  å…¥åŠ›å±¤: {len(self.input_layer)} neurons")
        print(f"  éš ã‚Œå±¤: {len(self.hidden_layer)} neurons") 
        print(f"  å‡ºåŠ›å±¤: {len(self.output_layer)} neurons")
        
    def _generate_mixed_neuron_types(self, layer_size: int) -> List[str]:
        """éš ã‚Œå±¤ç”¨ã®èˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§æ··åˆã‚¿ã‚¤ãƒ—ç”Ÿæˆ"""
        # 80% èˆˆå¥®æ€§, 20% æŠ‘åˆ¶æ€§ (ç”Ÿç‰©å­¦çš„æ¯”ç‡)
        excitatory_count = int(layer_size * 0.8)
        inhibitory_count = layer_size - excitatory_count
        
        types = ['excitatory'] * excitatory_count + ['inhibitory'] * inhibitory_count
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ£ãƒƒãƒ•ãƒ«
        np.random.shuffle(types)
        
        return types
        
    def _setup_neuron_types(self):
        """ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚¿ã‚¤ãƒ—çµ±è¨ˆã®è¨ˆç®—"""
        self.excitatory_count = 0
        self.inhibitory_count = 0
        
        # å…¨å±¤ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚¿ã‚¤ãƒ—ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        for layer in [self.input_layer, self.hidden_layer, self.output_layer]:
            for neuron in layer.neurons:
                if neuron.neuron_type == 'excitatory':
                    self.excitatory_count += 1
                else:
                    self.inhibitory_count += 1
                    
    def _initialize_integration_interface(self):
        """SNN-EDçµ±åˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹åˆæœŸåŒ–"""
        
        # ã‚¹ãƒ‘ã‚¤ã‚¯å±¥æ­´ç®¡ç†
        self.spike_history = {
            'input': [],
            'hidden': [],
            'output': []
        }
        
        # è†œé›»ä½å±¥æ­´
        self.membrane_potential_history = {
            'input': [],
            'hidden': [],
            'output': []
        }
        
        # ED-SNNçµ±åˆçŠ¶æ…‹
        self.integration_state = {
            'current_time': 0.0,
            'total_spikes': 0,
            'learning_active': False,
            'last_ed_update': 0.0
        }
        
    @profile_function("encode_input_to_spikes")
    def encode_input_to_spikes(self, input_data: np.ndarray, encoding_type: str = 'rate') -> np.ndarray:
        """
        å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ãƒ‘ã‚¤ã‚¯åˆ—ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼ˆèˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§ãƒšã‚¢æ§‹é€ ï¼‰
        
        Parameters:
        -----------
        input_data : np.ndarray
            å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ (ä¾‹: MNIST 784æ¬¡å…ƒ)
        encoding_type : str
            ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¿ã‚¤ãƒ— ('rate', 'temporal', 'population')
            
        Returns:
        --------
        np.ndarray
            èˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§ãƒšã‚¢æ§‹é€ ã®ã‚¹ãƒ‘ã‚¤ã‚¯é›»æµ
        """
        if encoding_type == 'rate':
            # ãƒ¬ãƒ¼ãƒˆç¬¦å·åŒ–: å€¤ã®å¤§ãã•ã‚’ç™ºç«ç‡ã«å¤‰æ›
            excitatory_currents = input_data * 50.0  # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
            inhibitory_currents = (1.0 - input_data) * 30.0  # é€†æ¥µæ€§
            
        elif encoding_type == 'temporal':
            # æ™‚é–“ç¬¦å·åŒ–: å€¤ã®å¤§ãã•ã‚’ç™ºç«ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã«å¤‰æ›
            excitatory_currents = np.where(input_data > 0.5, 40.0, 0.0)
            inhibitory_currents = np.where(input_data <= 0.5, 25.0, 0.0)
            
        else:  # population encoding
            # é›†å›£ç¬¦å·åŒ–: è¤‡æ•°ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã§å€¤ã‚’è¡¨ç¾
            excitatory_currents = input_data * 45.0
            inhibitory_currents = np.abs(input_data - 0.5) * 35.0
            
        # èˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§ãƒšã‚¢æ§‹é€ ã«çµåˆ
        paired_currents = np.concatenate([excitatory_currents, inhibitory_currents])
        
        return paired_currents
        
    @profile_function("simulate_snn_dynamics")
    def simulate_snn_dynamics(self, input_currents: np.ndarray) -> Dict[str, np.ndarray]:
        """
        SNNãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        
        Parameters:
        -----------
        input_currents : np.ndarray
            å…¥åŠ›é›»æµãƒ‘ã‚¿ãƒ¼ãƒ³
            
        Returns:
        --------
        Dict[str, np.ndarray]
            å„å±¤ã®ã‚¹ãƒ‘ã‚¤ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³
        """
        time_steps = int(self.simulation_time / self.dt)
        layer_spikes = {
            'input': np.zeros((time_steps, self.total_input_size)),
            'hidden': np.zeros((time_steps, self.hidden_size)),
            'output': np.zeros((time_steps, self.output_size))
        }
        
        # æ™‚é–“ç™ºå±•ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        for t in range(time_steps):
            self.integration_state['current_time'] = t * self.dt
            
            # å…¥åŠ›å±¤æ›´æ–°
            input_spikes = self.input_layer.update(input_currents)
            layer_spikes['input'][t] = input_spikes.astype(float)
            
            # éš ã‚Œå±¤ã¸ã®çµåˆé‡ã¿ã«åŸºã¥ãé›»æµè¨ˆç®—
            hidden_currents = self._calculate_layer_currents(
                input_spikes, 'input_to_hidden', t
            )
            
            # éš ã‚Œå±¤æ›´æ–°
            hidden_spikes = self.hidden_layer.update(hidden_currents)
            layer_spikes['hidden'][t] = hidden_spikes.astype(float)
            
            # å‡ºåŠ›å±¤ã¸ã®çµåˆé‡ã¿ã«åŸºã¥ãé›»æµè¨ˆç®—
            output_currents = self._calculate_layer_currents(
                hidden_spikes, 'hidden_to_output', t
            )
            
            # å‡ºåŠ›å±¤æ›´æ–°
            output_spikes = self.output_layer.update(output_currents)
            layer_spikes['output'][t] = output_spikes.astype(float)
            
        # ã‚¹ãƒ‘ã‚¤ã‚¯å±¥æ­´æ›´æ–°
        self.spike_history['input'].append(layer_spikes['input'])
        self.spike_history['hidden'].append(layer_spikes['hidden'])
        self.spike_history['output'].append(layer_spikes['output'])
        
        # çµ±è¨ˆæ›´æ–°
        total_spikes = (layer_spikes['input'].sum() + 
                       layer_spikes['hidden'].sum() + 
                       layer_spikes['output'].sum())
        self.integration_state['total_spikes'] += total_spikes
        
        return layer_spikes
        
    def _calculate_layer_currents(self, source_spikes: np.ndarray, connection_type: str, time_step: int) -> np.ndarray:
        """
        å±¤é–“çµåˆé‡ã¿ã«åŸºã¥ãé›»æµè¨ˆç®—
        
        Parameters:
        -----------
        source_spikes : np.ndarray
            é€ä¿¡å´ã‚¹ãƒ‘ã‚¤ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³
        connection_type : str
            çµåˆã‚¿ã‚¤ãƒ— ('input_to_hidden', 'hidden_to_output')
        time_step : int
            ç¾åœ¨ã®æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—
            
        Returns:
        --------
        np.ndarray
            ç›®æ¨™å±¤ã¸ã®å…¥åŠ›é›»æµ
        """
        if connection_type == 'input_to_hidden':
            # å…¥åŠ›å±¤â†’éš ã‚Œå±¤ã®é›»æµè¨ˆç®—
            # EDæ³•ã®é‡ã¿é…åˆ—ã‹ã‚‰å¯¾å¿œã™ã‚‹é‡ã¿ã‚’å–å¾—
            currents = np.zeros(self.hidden_size)
            
            # ç°¡æ˜“çš„ãªçµåˆé‡ã¿è¨ˆç®—ï¼ˆå¾Œã§EDæ³•é‡ã¿ã¨çµ±åˆï¼‰
            for i in range(self.hidden_size):
                weighted_sum = 0.0
                for j, spike in enumerate(source_spikes):
                    if spike > 0:  # ã‚¹ãƒ‘ã‚¤ã‚¯ãŒã‚ã‚‹å ´åˆ
                        # EDæ³•é‡ã¿é…åˆ—ã‹ã‚‰é‡ã¿ã‚’å–å¾—
                        weight = self._get_ed_weight(0, j + 2, i + self.total_input_size + 3)
                        weighted_sum += weight * 30.0  # ã‚¹ãƒ‘ã‚¤ã‚¯ã®é›»æµå¼·åº¦
                currents[i] = weighted_sum
                
        else:  # hidden_to_output
            # éš ã‚Œå±¤â†’å‡ºåŠ›å±¤ã®é›»æµè¨ˆç®—
            currents = np.zeros(self.output_size)
            
            for i in range(self.output_size):
                weighted_sum = 0.0
                for j, spike in enumerate(source_spikes):
                    if spike > 0:
                        # EDæ³•é‡ã¿é…åˆ—ã‹ã‚‰é‡ã¿ã‚’å–å¾—
                        weight = self._get_ed_weight(i, self.total_input_size + 3 + j, self.total_input_size + 2)
                        weighted_sum += weight * 25.0
                currents[i] = weighted_sum
                
        return currents
        
    def _get_ed_weight(self, output_neuron: int, from_unit: int, to_unit: int) -> float:
        """EDæ³•é‡ã¿é…åˆ—ã‹ã‚‰é‡ã¿å€¤ã‚’å–å¾—"""
        try:
            if (output_neuron < self.ed_core.output_weights.shape[0] and
                from_unit < self.ed_core.output_weights.shape[1] and
                to_unit < self.ed_core.output_weights.shape[2]):
                return self.ed_core.output_weights[output_neuron, from_unit, to_unit]
            else:
                return 0.0
        except (AttributeError, IndexError):
            return np.random.normal(0, 0.1)  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            
    @profile_function("convert_spikes_to_ed_input")
    def convert_spikes_to_ed_input(self, spike_pattern: np.ndarray) -> List[float]:
        """
        ã‚¹ãƒ‘ã‚¤ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’EDæ³•å…¥åŠ›å½¢å¼ã«å¤‰æ›
        
        Parameters:
        -----------
        spike_pattern : np.ndarray
            ã‚¹ãƒ‘ã‚¤ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³ (time_steps x neurons)
            
        Returns:
        --------
        List[float]
            EDæ³•ç”¨å…¥åŠ›ãƒ‘ã‚¿ãƒ¼ãƒ³
        """
        # ã‚¹ãƒ‘ã‚¤ã‚¯ç™ºç«ç‡ã‚’è¨ˆç®—
        spike_rates = np.mean(spike_pattern, axis=0)
        
        # èˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§ãƒšã‚¢ã®å‡¦ç†
        excitatory_rates = spike_rates[:self.excitatory_input_size]
        inhibitory_rates = spike_rates[self.excitatory_input_size:]
        
        # å·®åˆ†è¨ˆç®—ã«ã‚ˆã‚‹EDæ³•å…¥åŠ›ç”Ÿæˆ
        ed_input = []
        for i in range(min(len(excitatory_rates), len(inhibitory_rates))):
            # èˆˆå¥®æ€§ - æŠ‘åˆ¶æ€§ã®å·®åˆ†
            diff_value = excitatory_rates[i] - inhibitory_rates[i]
            # æ­£è¦åŒ–ã—ã¦ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰ç¯„å›²ã«èª¿æ•´
            normalized_value = np.tanh(diff_value) * 0.5 + 0.5
            ed_input.append(float(normalized_value))
            
        return ed_input
        
    @profile_function("train_step")
    def train_step(self, input_data: np.ndarray, target_data: np.ndarray, encoding_type: str = 'rate') -> Dict[str, Any]:
        """
        ED-SNNçµ±åˆå­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—
        
        Parameters:
        -----------
        input_data : np.ndarray
            å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
        target_data : np.ndarray  
            ç›®æ¨™ãƒ‡ãƒ¼ã‚¿
        encoding_type : str
            ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¿ã‚¤ãƒ—
            
        Returns:
        --------
        Dict[str, Any]
            å­¦ç¿’çµæœæƒ…å ±
        """
        self.integration_state['learning_active'] = True
        
        # 1. å…¥åŠ›ã‚’ã‚¹ãƒ‘ã‚¤ã‚¯åˆ—ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        spike_currents = self.encode_input_to_spikes(input_data, encoding_type)
        
        # 2. SNNãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        layer_spikes = self.simulate_snn_dynamics(spike_currents)
        
        # 3. ã‚¹ãƒ‘ã‚¤ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’EDæ³•å…¥åŠ›ã«å¤‰æ›
        ed_input = self.convert_spikes_to_ed_input(layer_spikes['input'])
        
        # 4. EDæ³•å­¦ç¿’å®Ÿè¡Œ
        ed_outputs = self.ed_core.neuro_output_calc(ed_input)
        self.ed_core.neuro_teach_calc(target_data.tolist())
        self.ed_core.neuro_weight_calc()
        
        # 5. å­¦ç¿’çµ±è¨ˆè¨ˆç®—
        prediction = np.argmax(ed_outputs)
        target_class = np.argmax(target_data)
        accuracy = 1.0 if prediction == target_class else 0.0
        
        self.integration_state['last_ed_update'] = self.integration_state['current_time']
        
        return {
            'prediction': prediction,
            'target': target_class,
            'accuracy': accuracy,
            'outputs': ed_outputs,
            'total_spikes': self.integration_state['total_spikes'],
            'simulation_time': self.integration_state['current_time'],
            'spike_patterns': layer_spikes
        }
        
    def predict(self, input_data: np.ndarray, encoding_type: str = 'rate') -> Dict[str, Any]:
        """
        ED-SNNçµ±åˆäºˆæ¸¬
        
        Parameters:
        -----------
        input_data : np.ndarray
            å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
        encoding_type : str
            ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¿ã‚¤ãƒ—
            
        Returns:
        --------
        Dict[str, Any]
            äºˆæ¸¬çµæœ
        """
        # SNNã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        spike_currents = self.encode_input_to_spikes(input_data, encoding_type)
        layer_spikes = self.simulate_snn_dynamics(spike_currents)
        
        # EDæ³•äºˆæ¸¬
        ed_input = self.convert_spikes_to_ed_input(layer_spikes['input'])
        ed_outputs = self.ed_core.neuro_output_calc(ed_input)
        prediction = np.argmax(ed_outputs)
        
        return {
            'prediction': prediction,
            'outputs': ed_outputs,
            'confidence': float(np.max(ed_outputs)),
            'spike_patterns': layer_spikes
        }
        
    def reset_network(self):
        """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çŠ¶æ…‹ãƒªã‚»ãƒƒãƒˆ"""
        # LIFå±¤ãƒªã‚»ãƒƒãƒˆ
        self.input_layer.reset_all()
        self.hidden_layer.reset_all()
        self.output_layer.reset_all()
        
        # EDæ³•ãƒªã‚»ãƒƒãƒˆ
        self.ed_core.reset_error()
        
        # å±¥æ­´ã‚¯ãƒªã‚¢
        for key in self.spike_history:
            self.spike_history[key].clear()
        for key in self.membrane_potential_history:
            self.membrane_potential_history[key].clear()
            
        # çµ±åˆçŠ¶æ…‹ãƒªã‚»ãƒƒãƒˆ
        self.integration_state['current_time'] = 0.0
        self.integration_state['total_spikes'] = 0
        self.integration_state['learning_active'] = False
        
    def get_network_info(self) -> Dict[str, Any]:
        """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è©³ç´°æƒ…å ±å–å¾—"""
        return {
            'network_structure': self.network_structure,
            'total_neurons': (len(self.input_layer) + len(self.hidden_layer) + len(self.output_layer)),
            'excitatory_count': self.excitatory_count,
            'inhibitory_count': self.inhibitory_count,
            'simulation_time': self.simulation_time,
            'ed_info': self.ed_core.get_network_info(),
            'integration_state': self.integration_state.copy(),
            'snn_params': self.snn_params,
            'ed_params': self.ed_hyperparams
        }
        
    def summary(self):
        """
        TensorFlowã‚¹ã‚¿ã‚¤ãƒ«ã®ãƒ¢ãƒ‡ãƒ«æ§‹æˆè¡¨ç¤º
        """
        print("\n" + "="*70)
        print("              ED-Spiking Neural Network Summary")
        print("="*70)
        
        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åŸºæœ¬æƒ…å ±
        print(f"Network Structure: {self.network_structure}")
        print(f"Simulation Time: {self.simulation_time}ms (dt={self.dt}ms)")
        print(f"Total Neurons: {self.excitatory_count + self.inhibitory_count}")
        print(f"E/I Ratio: {self.excitatory_count}E / {self.inhibitory_count}I")
        print("-"*70)
        
        # å±¤åˆ¥è©³ç´°æƒ…å ±
        print(f"{'Layer Type':<15} {'Neurons':<10} {'E/I Composition':<20} {'Parameters':<15}")
        print("-"*70)
        
        # å…¥åŠ›å±¤
        input_e = sum(1 for nt in self.input_layer.neuron_types if nt == 'excitatory')
        input_i = len(self.input_layer) - input_e
        print(f"{'Input Layer':<15} {len(self.input_layer):<10} "
              f"{input_e}E + {input_i}I{'':<8} {'Paired E/I':<15}")
        
        # éš ã‚Œå±¤
        hidden_e = sum(1 for nt in self.hidden_layer.neuron_types if nt == 'excitatory')
        hidden_i = len(self.hidden_layer) - hidden_e
        print(f"{'Hidden Layer':<15} {len(self.hidden_layer):<10} "
              f"{hidden_e}E + {hidden_i}I{'':<8} {'Mixed 80/20':<15}")
        
        # å‡ºåŠ›å±¤
        output_e = sum(1 for nt in self.output_layer.neuron_types if nt == 'excitatory')
        output_i = len(self.output_layer) - output_e
        print(f"{'Output Layer':<15} {len(self.output_layer):<10} "
              f"{output_e}E + {output_i}I{'':<8} {'Excitatory':<15}")
        
        print("-"*70)
        
        # EDæ³•æƒ…å ±
        ed_info = self.ed_core.get_network_info()
        print("ED Learning Parameters:")
        print(f"  Learning Rate: {self.ed_hyperparams['learning_rate']}")
        print(f"  Sigmoid Threshold: {self.ed_hyperparams['sigmoid_threshold']}")
        print(f"  Initial Amine: {self.ed_hyperparams['initial_amine']}")
        print(f"  Weight Array Shape: {ed_info['weight_shape']}")
        
        # SNN ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æƒ…å ±
        print("\nLIF Neuron Parameters:")
        print(f"  Membrane Time Constant: {self.snn_params['tau_m']}ms")
        print(f"  Threshold Voltage: {self.snn_params['v_threshold']}mV")
        print(f"  Reset Voltage: {self.snn_params['v_reset']}mV")
        print(f"  Refractory Period: {self.snn_params['tau_ref']}ms")
        
        print("="*70)
        
        # æ¥ç¶šçµ±è¨ˆ
        total_possible_connections = (
            len(self.input_layer) * len(self.hidden_layer) +
            len(self.hidden_layer) * len(self.output_layer)
        )
        
        print(f"\nConnection Statistics:")
        print(f"  Input â†’ Hidden: {len(self.input_layer)} Ã— {len(self.hidden_layer)} = "
              f"{len(self.input_layer) * len(self.hidden_layer):,} connections")
        print(f"  Hidden â†’ Output: {len(self.hidden_layer)} Ã— {len(self.output_layer)} = "
              f"{len(self.hidden_layer) * len(self.output_layer):,} connections")
        print(f"  Total Connections: {total_possible_connections:,}")
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¨å®š
        weight_memory = ed_info['weight_shape'][0] * ed_info['weight_shape'][1] * ed_info['weight_shape'][2] * 8  # float64
        neuron_memory = (len(self.input_layer) + len(self.hidden_layer) + len(self.output_layer)) * 64  # æ¨å®š
        
        print(f"\nMemory Estimation:")
        print(f"  Weight Arrays: {weight_memory / 1024 / 1024:.2f} MB")
        print(f"  Neuron States: {neuron_memory / 1024:.2f} KB")
        print(f"  Total Estimated: {(weight_memory + neuron_memory) / 1024 / 1024:.2f} MB")
        
        print("="*70)

    def __repr__(self) -> str:
        return (f"EDSpikingNeuralNetwork("
                f"structure={self.network_structure}, "
                f"neurons={self.excitatory_count}E+{self.inhibitory_count}I, "
                f"sim_time={self.simulation_time}ms)")