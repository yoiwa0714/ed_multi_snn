#!/usr/bin/env python3
"""
ed_multi_lif_snn_simple.py
ãƒãƒ¼ã‚¸ãƒ§ãƒ³: 1.0.0

ã‚¹ãƒ‘ã‚¤ã‚­ãƒ³ã‚°ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ãŸã‚ã®Error-Diffusion (ED)æ³•å®Ÿè£…
æ•™è‚²ç”¨ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰

ä½¿ã„æ–¹:
  python ed_multi_lif_snn_simple.py --mnist --train 1000 --test 100

ã‚ªãƒ—ã‚·ãƒ§ãƒ³æŒ‡å®šä¾‹:
  python ed_multi_lif_snn_simple.py --mnist --train 1000 --test 100 --viz --heatmap
"""

# TensorFlowã®è­¦å‘Šãƒ»æƒ…å ±ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’éè¡¨ç¤ºã«ã™ã‚‹
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # ERRORä»¥å¤–ã‚’éè¡¨ç¤º
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'  # oneDNNãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’éè¡¨ç¤º

import numpy as np
import time
import argparse
import tensorflow as tf
from datetime import datetime
from tqdm import tqdm
import matplotlib
import matplotlib.pyplot as plt
from matplotlib import rcParams
import matplotlib.font_manager as fm
import warnings
import threading
from modules.accuracy_loss_verifier import AccuracyLossVerifier

# GPUè¨ˆç®—æ”¯æ´ï¼ˆCuPyå¯¾å¿œï¼‰- ed_multi_snn.prompt.mdæº–æ‹ 
try:
    import cupy as cp
    xp = cp  # NumPyäº’æ›ã®é…åˆ—ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
    GPU_AVAILABLE = True
    print("ğŸš€ GPUï¼ˆCuPyï¼‰ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
    print(f"   ãƒ‡ãƒã‚¤ã‚¹: {cp.cuda.Device().compute_capability}")
except ImportError:
    import numpy as np
    xp = np  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: NumPyã‚’ä½¿ç”¨
    GPU_AVAILABLE = False
    print("â„¹ï¸  GPUæœªæ¤œå‡ºã€‚CPUï¼ˆNumPyï¼‰ã§å®Ÿè¡Œã—ã¾ã™")
except Exception as e:
    import numpy as np
    xp = np
    GPU_AVAILABLE = False
    print(f"âš ï¸  GPUåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼ã€‚CPUï¼ˆNumPyï¼‰ã§å®Ÿè¡Œã—ã¾ã™: {e}")

# TensorFlowã®ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’è¨­å®šï¼ˆè¿½åŠ ã®ä¿é™ºï¼‰
tf.get_logger().setLevel('ERROR')

# ãƒŸãƒ‹ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
from modules.data_loader import MiniBatchDataLoader
# ========== HyperParamsã‚¯ãƒ©ã‚¹ (ed_v032_simple.pyæº–æ‹ ) ==========

class HyperParams:
    """
    ED-SNN ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç®¡ç†ã‚¯ãƒ©ã‚¹
    ed_v032_simple.pyæº–æ‹ : ed_multi_snn.prompt.mdæº–æ‹ ç‰ˆ
    """
    
    def __init__(self):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤è¨­å®šï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æœ€é©åŒ–å€¤ä½¿ç”¨ï¼‰"""
        # === EDæ³•ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ===
        self.learning_rate = 0.1      # å­¦ç¿’ç‡ (alpha) - ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æœ€é©åŒ–
        self.initial_amine = 0.25     # åˆæœŸã‚¢ãƒŸãƒ³æ¿ƒåº¦ (beta) - ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æœ€é©åŒ–
        self.diffusion_rate = 0.5     # ã‚¢ãƒŸãƒ³æ‹¡æ•£ä¿‚æ•° (u1)
        self.sigmoid_threshold = 1.2  # ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¾å€¤ (u0) - ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æœ€é©åŒ–
        self.initial_weight_1 = 0.3   # é‡ã¿åˆæœŸå€¤1
        self.initial_weight_2 = 0.5   # é‡ã¿åˆæœŸå€¤2
        
        # === LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆv570æº–æ‹ ã€æ–°è¦è¿½åŠ ï¼‰ ===
        self.v_rest = -65.0           # é™æ­¢è†œé›»ä½ (mV)
        self.v_threshold = -60.0      # ç™ºç«é–¾å€¤ (mV)
        self.v_reset = -70.0          # ãƒªã‚»ãƒƒãƒˆé›»ä½ (mV)
        self.tau_m = 20.0             # è†œæ™‚å®šæ•° (ms)
        self.tau_ref = 2.0            # ä¸å¿œæœŸ (ms)
        self.dt = 1.0                 # æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ— (ms)
        self.R_m = 10.0               # è†œæŠµæŠ— (MÎ©)
        self.simulation_time = 50.0   # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ™‚é–“ (ms)
        
        # === LIFçµ±åˆåˆ¶å¾¡ï¼ˆv019 Phase 4è¿½åŠ ï¼‰ ===
        self.enable_lif = True        # LIFå±¤ã‚’ä½¿ç”¨ã™ã‚‹ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: æœ‰åŠ¹ - 85%é”æˆè¨­å®šï¼‰
        
        # === Step 3a: å…¥åŠ›å±¤LIFåŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆv025è¿½åŠ ï¼‰ ===
        self.use_input_lif = True        # å…¥åŠ›å±¤LIFä½¿ç”¨ãƒ•ãƒ©ã‚°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: æœ‰åŠ¹ - 85%é”æˆè¨­å®šï¼‰
        self.spike_encoding_method = 'poisson'  # ã‚¹ãƒ‘ã‚¤ã‚¯ç¬¦å·åŒ–æ–¹æ³• ('poisson', 'rate', 'temporal')
        self.spike_max_rate = 150.0      # æœ€å¤§ç™ºç«ç‡ (Hz) - 85%é”æˆè¨­å®š
        self.spike_simulation_time = 50.0  # ã‚¹ãƒ‘ã‚¤ã‚¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ™‚é–“ (ms)
        self.spike_dt = 1.0               # ã‚¹ãƒ‘ã‚¤ã‚¯æ™‚é–“åˆ»ã¿ (ms)
        
        # === å®Ÿè¡Œæ™‚è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ===
        self.train_samples = 512      # è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ•° - ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æœ€é©åŒ–
        self.test_samples = 512       # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æ•° - ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æœ€é©åŒ–
        self.epochs = 10              # ã‚¨ãƒãƒƒã‚¯æ•° - ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æœ€é©åŒ–
        self.hidden_layers = [128]    # éš ã‚Œå±¤æ§‹é€  - ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æœ€é©åŒ–
        self.batch_size = 128         # ãƒŸãƒ‹ãƒãƒƒãƒã‚µã‚¤ã‚º - ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æœ€é©åŒ–
        self.random_seed = None       # ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰
        self.enable_visualization = False  # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–
        self.enable_heatmap = False        # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—å¯è¦–åŒ–
        self.verbose = False          # è©³ç´°è¡¨ç¤º
        self.quiet_mode = False       # ç°¡æ½”å‡ºåŠ›ãƒ¢ãƒ¼ãƒ‰ [SNNæœªå®Ÿè£…]
        self.enable_profiling = False # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚° [SNNæœªå®Ÿè£…]
        self.force_cpu = False        # CPUå¼·åˆ¶å®Ÿè¡Œ [SNNæœªå®Ÿè£…]
        self.fashion_mnist = True     # Fashion-MNISTä½¿ç”¨ - ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æœ€é©åŒ–
        self.mnist = False            # MNISTä½¿ç”¨
        self.save_fig = None          # å›³è¡¨ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãä¿å­˜ï¼‰
        self.no_shuffle = False       # ãƒ‡ãƒ¼ã‚¿ã‚·ãƒ£ãƒƒãƒ•ãƒ«ç„¡åŠ¹åŒ–ï¼ˆed_snnç‹¬è‡ªï¼‰
        self.verify_acc_loss = False  # ç²¾åº¦ãƒ»èª¤å·®æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º
        
    def __post_init__(self):
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåã¨å‡ºåŠ›ã‚µã‚¤ã‚ºã®è‡ªå‹•è¨­å®š"""
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé¸æŠã®å„ªå…ˆé †ä½: Fashion-MNIST > MNIST
        if self.fashion_mnist:
            self.dataset_name = 'fashion_mnist'
            self.output_size = 10   # Fashion-MNIST: 10ã‚¯ãƒ©ã‚¹
        elif self.mnist:
            self.dataset_name = 'mnist'
            self.output_size = 10   # MNIST: 10ã‚¯ãƒ©ã‚¹
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: MNIST
            self.dataset_name = 'mnist'
            self.output_size = 10
    
    def parse_args(self, args=None):
        """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°è§£æï¼ˆed_v032_simple.pyæº–æ‹ ï¼‰"""
        import argparse
        
        parser = argparse.ArgumentParser(
            description='ED-SNN v015 HyperParamsçµ±ä¸€ç‰ˆ - ed_v032_simpleæº–æ‹ ',
            formatter_class=argparse.RawDescriptionHelpFormatter,
            epilog="""
EDæ³•ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¬æ˜:
  å­¦ç¿’ç‡(alpha): ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®å­¦ç¿’å¼·åº¦ã‚’åˆ¶å¾¡
  ã‚¢ãƒŸãƒ³æ¿ƒåº¦(beta): åˆæœŸèª¤å·®ä¿¡å·ã®å¼·åº¦ [SNNæœªå®Ÿè£…]
  æ‹¡æ•£ä¿‚æ•°(u1): ã‚¢ãƒŸãƒ³ï¼ˆèª¤å·®ä¿¡å·ï¼‰ã®æ‹¡æ•£ç‡ [SNNæœªå®Ÿè£…]
  ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¾å€¤(u0): æ´»æ€§åŒ–é–¢æ•°ã®æ„Ÿåº¦ [SNNæœªå®Ÿè£…]
  
[SNNæœªå®Ÿè£…]ãƒãƒ¼ã‚¯ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:
  å°†æ¥ã®å®Ÿè£…ã®ãŸã‚ã®ãƒ€ãƒŸãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã™ã€‚
  ç¾åœ¨ã¯æŒ‡å®šã—ã¦ã‚‚åŠ¹æœã¯ã‚ã‚Šã¾ã›ã‚“ãŒã€ed_v032_simpleã¨ã®
  ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³äº’æ›æ€§ã‚’ä¿ã¤ãŸã‚ã«ç”¨æ„ã•ã‚Œã¦ã„ã¾ã™ã€‚

Original Algorithm: é‡‘å­å‹‡ (1999)
Implementation: ed_multi_snn.prompt.mdæº–æ‹ 
            """
        )
        
        # === EDæ³•ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ===
        ed_group = parser.add_argument_group('EDæ³•ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿')
        ed_group.add_argument('--learning_rate', '--lr', type=float, default=self.learning_rate,
                             help=f'å­¦ç¿’ç‡ alpha (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {self.learning_rate})')
        ed_group.add_argument('--amine', '--ami', type=float, default=self.initial_amine,
                             help=f'åˆæœŸã‚¢ãƒŸãƒ³æ¿ƒåº¦ beta (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {self.initial_amine}) [å¤šå±¤å­¦ç¿’ã§é‡è¦]')
        ed_group.add_argument('--diffusion', '--dif', type=float, default=self.diffusion_rate,
                             help=f'ã‚¢ãƒŸãƒ³æ‹¡æ•£ä¿‚æ•° u1 (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {self.diffusion_rate}) [å¤šå±¤å­¦ç¿’ã§é‡è¦]')
        ed_group.add_argument('--sigmoid', '--sig', type=float, default=self.sigmoid_threshold,
                             help=f'ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¾å€¤ u0 (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {self.sigmoid_threshold}) [å¤šå±¤å­¦ç¿’ã§é‡è¦]')
        ed_group.add_argument('--weight1', '--w1', type=float, default=self.initial_weight_1,
                             help=f'é‡ã¿åˆæœŸå€¤1 (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {self.initial_weight_1}) [èˆˆå¥®æ€§ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³]')
        ed_group.add_argument('--weight2', '--w2', type=float, default=self.initial_weight_2,
                             help=f'é‡ã¿åˆæœŸå€¤2 (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {self.initial_weight_2}) [æŠ‘åˆ¶æ€§ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³]')
        
        # === LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆv570æº–æ‹ ã€æ–°è¦è¿½åŠ ï¼‰ ===
        lif_group = parser.add_argument_group('LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆv019æ–°è¦è¿½åŠ ï¼‰')
        lif_group.add_argument('--v_rest', type=float, default=self.v_rest,
                              help=f'é™æ­¢è†œé›»ä½ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {self.v_rest} mV) [LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³]')
        lif_group.add_argument('--v_threshold', '--v_thresh', type=float, default=self.v_threshold,
                              help=f'ç™ºç«é–¾å€¤ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {self.v_threshold} mV) [LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³]')
        lif_group.add_argument('--v_reset', type=float, default=self.v_reset,
                              help=f'ãƒªã‚»ãƒƒãƒˆé›»ä½ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {self.v_reset} mV) [LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³]')
        lif_group.add_argument('--tau_m', '--tau_mem', type=float, default=self.tau_m,
                              help=f'è†œæ™‚å®šæ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {self.tau_m} ms) [LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³]')
        lif_group.add_argument('--tau_ref', '--tau_refractory', type=float, default=self.tau_ref,
                              help=f'ä¸å¿œæœŸ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {self.tau_ref} ms) [LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³]')
        lif_group.add_argument('--dt', type=float, default=self.dt,
                              help=f'æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ— (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {self.dt} ms) [LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³]')
        lif_group.add_argument('--R_m', '--membrane_resistance', type=float, default=self.R_m,
                              help=f'è†œæŠµæŠ— (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {self.R_m} MÎ©) [LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³]')
        lif_group.add_argument('--sim_time', '--simulation_time', type=float, default=self.simulation_time,
                              help=f'ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ™‚é–“ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {self.simulation_time} ms) [LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³]')
        lif_group.add_argument('--enable_lif', action='store_true',
                              help='LIFå±¤ã‚’æœ‰åŠ¹åŒ–ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ç„¡åŠ¹ï¼‰ [v019 Phase 4æ–°æ©Ÿèƒ½]')
        
        # === Step 3a: å…¥åŠ›å±¤LIFçµ±åˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆv025æ–°è¦è¿½åŠ ï¼‰ ===
        lif_group.add_argument('--use_input_lif', action='store_true',
                              help='å…¥åŠ›å±¤LIFã‚’æœ‰åŠ¹åŒ–ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ç„¡åŠ¹ï¼‰ [v025 Step 3aæ–°æ©Ÿèƒ½]')
        lif_group.add_argument('--spike_encoding', '--encoding', type=str, 
                              default=self.spike_encoding_method,
                              choices=['poisson', 'rate', 'temporal'],
                              help=f'ã‚¹ãƒ‘ã‚¤ã‚¯ç¬¦å·åŒ–æ–¹æ³• (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {self.spike_encoding_method}) [v025 Step 3a]')
        lif_group.add_argument('--spike_max_rate', '--max_rate', type=float, 
                              default=self.spike_max_rate,
                              help=f'æœ€å¤§ç™ºç«ç‡ Hz (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {self.spike_max_rate}) [v025 Step 3a]')
        lif_group.add_argument('--spike_sim_time', type=float, 
                              default=self.spike_simulation_time,
                              help=f'ã‚¹ãƒ‘ã‚¤ã‚¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ™‚é–“ ms (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {self.spike_simulation_time}) [v025 Step 3a]')
        lif_group.add_argument('--spike_dt', type=float, 
                              default=self.spike_dt,
                              help=f'ã‚¹ãƒ‘ã‚¤ã‚¯æ™‚é–“åˆ»ã¿ ms (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {self.spike_dt}) [v025 Step 3a]')
        
        # === å®Ÿè¡Œæ™‚è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ===
        exec_group = parser.add_argument_group('å®Ÿè¡Œæ™‚è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿')
        exec_group.add_argument('--train_samples', '--train', type=int, default=self.train_samples,
                               help=f'è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {self.train_samples})')
        exec_group.add_argument('--test_samples', '--test', type=int, default=self.test_samples,
                               help=f'ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {self.test_samples})')
        exec_group.add_argument('--epochs', '--epo', type=int, default=self.epochs,
                               help=f'ã‚¨ãƒãƒƒã‚¯æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {self.epochs})')
        exec_group.add_argument('--hidden', '--hid', type=str, default=','.join(map(str, self.hidden_layers)),
                               help=f'éš ã‚Œå±¤æ§‹é€  (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {",".join(map(str, self.hidden_layers))}) - ã‚«ãƒ³ãƒåŒºåˆ‡ã‚ŠæŒ‡å®š (ä¾‹: 256,128,64)')
        exec_group.add_argument('--batch_size', '--batch', type=int, default=self.batch_size,
                               help=f'ãƒŸãƒ‹ãƒãƒƒãƒã‚µã‚¤ã‚º (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {self.batch_size})')
        exec_group.add_argument('--seed', type=int, default=self.random_seed,
                               help='ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ãƒ©ãƒ³ãƒ€ãƒ )')
        exec_group.add_argument('--viz', action='store_true', default=self.enable_visualization,
                               help='ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–ã‚’æœ‰åŠ¹åŒ– (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ç„¡åŠ¹)')
        exec_group.add_argument('--heatmap', action='store_true', default=False,
                               help='ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—å¯è¦–åŒ–ã‚’æœ‰åŠ¹åŒ– (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ç„¡åŠ¹)')
        exec_group.add_argument('--verbose', '--v', action='store_true', default=self.verbose,
                               help='è©³ç´°è¡¨ç¤ºã‚’æœ‰åŠ¹åŒ– (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ç„¡åŠ¹)')
        exec_group.add_argument('--quiet', '--q', action='store_true', default=False,
                               help='ç°¡æ½”å‡ºåŠ›ãƒ¢ãƒ¼ãƒ‰ - ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒç”¨ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ç„¡åŠ¹) [SNNæœªå®Ÿè£…]')
        exec_group.add_argument('--cpu', action='store_true', default=self.force_cpu,
                               help='CPUå¼·åˆ¶å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰: GPUç’°å¢ƒã§ã‚‚CPUï¼ˆNumPyï¼‰ã§å®Ÿè¡Œã€‚'
                                    'ãƒ‡ãƒãƒƒã‚°ã€æ€§èƒ½æ¯”è¼ƒã€GPUæœªæ­è¼‰ç’°å¢ƒã§ã®å‹•ä½œç¢ºèªã«ä½¿ç”¨ã€‚'
                                    'ed_multi_snn.prompt.mdæ‹¡å¼µæ©Ÿèƒ½7æº–æ‹  (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: GPUè‡ªå‹•æ¤œå‡º)')
        exec_group.add_argument('--fashion', action='store_true', default=self.fashion_mnist,
                               help='Fashion-MNISTãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½¿ç”¨ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: æœ‰åŠ¹)')
        exec_group.add_argument('--mnist', action='store_true',
                               help='é€šå¸¸MNISTãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½¿ç”¨ (--fashionã®åå¯¾)')
        exec_group.add_argument('--save_fig', nargs='?', const='images', default=None,
                               help='å›³è¡¨ä¿å­˜ã‚’æœ‰åŠ¹åŒ– (å¼•æ•°ãªã—: ./images, å¼•æ•°ã‚ã‚Š: æŒ‡å®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª) ãƒ•ã‚¡ã‚¤ãƒ«å: realtime_viz_result_YYYYMMDD_HHMMSS.png')
        exec_group.add_argument('--verify_acc_loss', action='store_true', default=False,
                               help='ç²¾åº¦ãƒ»èª¤å·®ã®æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆã‚’è¡¨ç¤º (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ç„¡åŠ¹)')
        exec_group.add_argument('--no_shuffle', action='store_true',
                               help='ãƒ‡ãƒ¼ã‚¿ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã‚’ç„¡åŠ¹åŒ– (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: æœ‰åŠ¹)')
        
        # å¼•æ•°è§£æ
        parsed_args = parser.parse_args(args)
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å€¤ã®æ›´æ–°
        self.learning_rate = parsed_args.learning_rate
        self.initial_amine = parsed_args.amine
        self.diffusion_rate = parsed_args.diffusion
        self.sigmoid_threshold = parsed_args.sigmoid
        self.initial_weight_1 = parsed_args.weight1
        self.initial_weight_2 = parsed_args.weight2
        
        # LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆv019æ–°è¦è¿½åŠ ï¼‰
        self.v_rest = parsed_args.v_rest
        self.v_threshold = parsed_args.v_threshold
        self.v_reset = parsed_args.v_reset
        self.tau_m = parsed_args.tau_m
        self.tau_ref = parsed_args.tau_ref
        self.dt = parsed_args.dt
        self.R_m = parsed_args.R_m
        self.simulation_time = parsed_args.sim_time
        self.enable_lif = parsed_args.enable_lif  # v019 Phase 4è¿½åŠ 
        
        # Step 3a: å…¥åŠ›å±¤LIFçµ±åˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆv025æ–°è¦è¿½åŠ ï¼‰
        self.use_input_lif = parsed_args.use_input_lif
        self.spike_encoding_method = parsed_args.spike_encoding
        self.spike_max_rate = parsed_args.spike_max_rate
        self.spike_simulation_time = parsed_args.spike_sim_time
        self.spike_dt = parsed_args.spike_dt
        
        # å®Ÿè¡Œæ™‚è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.train_samples = parsed_args.train_samples
        self.test_samples = parsed_args.test_samples
        self.epochs = parsed_args.epochs
        
        # éš ã‚Œå±¤æ§‹é€ ã®è§£æ
        if isinstance(parsed_args.hidden, str):
            try:
                self.hidden_layers = [int(x.strip()) for x in parsed_args.hidden.split(',') if x.strip()]
                if not self.hidden_layers:
                    raise ValueError("éš ã‚Œå±¤æ§‹é€ ãŒç©ºã§ã™")
                if any(layer <= 0 for layer in self.hidden_layers):
                    raise ValueError("éš ã‚Œå±¤ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ•°ã¯æ­£ã®æ•´æ•°ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
            except ValueError as e:
                raise ValueError(f"--hidden ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®å½¢å¼ãŒä¸æ­£ã§ã™: {e}")
        else:
            self.hidden_layers = [parsed_args.hidden]
        
        self.batch_size = parsed_args.batch_size
        self.random_seed = parsed_args.seed
        self.enable_visualization = parsed_args.viz
        self.enable_heatmap = parsed_args.heatmap
        self.verbose = parsed_args.verbose
        self.quiet_mode = parsed_args.quiet
        self.force_cpu = parsed_args.cpu
        self.verify_acc_loss = parsed_args.verify_acc_loss  # æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé¸æŠãƒ•ãƒ©ã‚°å‡¦ç†ï¼ˆå„ªå…ˆé †ä½: MNIST > Fashion-MNISTï¼‰
        if hasattr(parsed_args, 'mnist') and parsed_args.mnist:
            self.mnist = True
            self.fashion_mnist = False
        else:
            self.mnist = False
            self.fashion_mnist = parsed_args.fashion
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåã¨å‡ºåŠ›ã‚µã‚¤ã‚ºã®è¨­å®š
        self.__post_init__()
        
        self.save_fig = getattr(parsed_args, 'save_fig', None)
        self.no_shuffle = parsed_args.no_shuffle
        
        # é‡ã¿ç®¡ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        return parsed_args


# matplotlib ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰è¨­å®šï¼ˆed_v032_simple.pyæº–æ‹ ï¼‰
try:
    if matplotlib.get_backend() == 'agg':
        try:
            matplotlib.use('Qt5Agg', force=True)
        except Exception:
            try:
                matplotlib.use('TkAgg', force=True)
            except Exception:
                pass
except Exception:
    pass

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆed_v032_simple.pyæº–æ‹ ï¼‰
def setup_japanese_font():
    """
    åˆ©ç”¨å¯èƒ½ãªæ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’è‡ªå‹•æ¤œå‡ºã—ã¦è¨­å®š
    ed_genuine.prompt.mdä»•æ§˜: æ—¥æœ¬èªåŒ–Linuxã®æ¨™æº–ãƒ•ã‚©ãƒ³ãƒˆä½¿ç”¨
    """
    try:
        # ã‚·ã‚¹ãƒ†ãƒ å†…ã®åˆ©ç”¨å¯èƒ½ãƒ•ã‚©ãƒ³ãƒˆä¸€è¦§ã‚’å–å¾—
        available_fonts = set([f.name for f in fm.fontManager.ttflist])
        
        # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆå€™è£œï¼ˆå„ªå…ˆåº¦é †ï¼‰
        japanese_font_candidates = [
            'Noto Sans CJK JP',   # Ubuntu/Debianæ¨™æº–
            'Noto Sans JP',       # Ubuntu/Debianä»£æ›¿
            'DejaVu Sans',        # ä¸€èˆ¬çš„ãªLinux
            'Liberation Sans',    # Red Hatç³»æ¨™æº–
            'TakaoGothic',        # CentOS/RHELï¼ˆå­˜åœ¨æ™‚ã®ã¿ï¼‰
            'VL Gothic',          # ãã®ä»–æ—¥æœ¬èªï¼ˆå­˜åœ¨æ™‚ã®ã¿ï¼‰
        ]
        
        # å®Ÿéš›ã«åˆ©ç”¨å¯èƒ½ãªæ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’é¸æŠ
        selected_font = None
        for font in japanese_font_candidates:
            if font in available_fonts:
                selected_font = font
                break
        
        # ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆå­˜åœ¨ã™ã‚‹ãƒ•ã‚©ãƒ³ãƒˆã®ã¿ï¼‰
        if selected_font:
            rcParams['font.family'] = [selected_font, 'sans-serif']
            print(f"âœ… æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆæ¤œå‡ºãƒ»è¨­å®šå®Œäº†: {selected_font}")
        else:
            rcParams['font.family'] = ['sans-serif']
            print("âš ï¸ æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆæœªæ¤œå‡º: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚©ãƒ³ãƒˆä½¿ç”¨")
        
        rcParams['axes.unicode_minus'] = False
        
        # matplotlibè­¦å‘Šã‚’æœ€å°åŒ–
        warnings.filterwarnings("ignore", category=UserWarning, module="matplotlib.font_manager")
        
    except Exception as e:
        print(f"âš ï¸ æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
        rcParams['font.family'] = ['sans-serif']
        rcParams['axes.unicode_minus'] = False

def wait_for_keypress_or_timeout(timeout_seconds=5):
    """
    ã‚­ãƒ¼æŠ¼ä¸‹ã¾ãŸã¯æŒ‡å®šç§’æ•°å¾…æ©Ÿã™ã‚‹é–¢æ•°
    Args:
        timeout_seconds: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç§’æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ5ç§’ï¼‰
    Returns:
        bool: ã‚­ãƒ¼ãŒæŠ¼ã•ã‚ŒãŸå ´åˆTrueã€ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã®å ´åˆFalse
    """
    import sys
    import select
    
    print(f"\nâ±ï¸  {timeout_seconds}ç§’å¾Œã«è‡ªå‹•ã‚¯ãƒ­ãƒ¼ã‚ºã—ã¾ã™ï¼ˆä»»æ„ã®ã‚­ãƒ¼ã§å³åº§ã«ã‚¯ãƒ­ãƒ¼ã‚ºï¼‰")
    
    # Windowsã®å ´åˆã¯msvcrtã‚’ä½¿ç”¨
    if sys.platform == 'win32':
        import msvcrt
        start_time = time.time()
        while time.time() - start_time < timeout_seconds:
            if msvcrt.kbhit():
                msvcrt.getch()  # ã‚­ãƒ¼ã‚’æ¶ˆè²»
                print("ğŸ”‘ ã‚­ãƒ¼æŠ¼ä¸‹ã‚’æ¤œçŸ¥ã—ã¾ã—ãŸ")
                return True
            time.sleep(0.1)
        print("â° ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã«ã‚ˆã‚‹è‡ªå‹•ã‚¯ãƒ­ãƒ¼ã‚º")
        return False
    
    # Linux/Macï¼ˆWSLå«ã‚€ï¼‰ã®å ´åˆ
    else:
        # æ¨™æº–å…¥åŠ›ãŒã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ãªã„å ´åˆã¯ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã®ã¿
        if not sys.stdin.isatty():
            time.sleep(timeout_seconds)
            print("â° ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã«ã‚ˆã‚‹è‡ªå‹•ã‚¯ãƒ­ãƒ¼ã‚º")
            return False
        
        # selectã‚’ä½¿ã£ã¦ã‚­ãƒ¼å…¥åŠ›ã‚’å¾…æ©Ÿ
        import termios
        import tty
        
        old_settings = None
        try:
            old_settings = termios.tcgetattr(sys.stdin)
            tty.setcbreak(sys.stdin.fileno())
            
            rlist, _, _ = select.select([sys.stdin], [], [], timeout_seconds)
            
            if rlist:
                sys.stdin.read(1)  # ã‚­ãƒ¼ã‚’æ¶ˆè²»
                print("ğŸ”‘ ã‚­ãƒ¼æŠ¼ä¸‹ã‚’æ¤œçŸ¥ã—ã¾ã—ãŸ")
                return True
            else:
                print("â° ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã«ã‚ˆã‚‹è‡ªå‹•ã‚¯ãƒ­ãƒ¼ã‚º")
                return False
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã®ã¿
            time.sleep(timeout_seconds)
            print("â° ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã«ã‚ˆã‚‹è‡ªå‹•ã‚¯ãƒ­ãƒ¼ã‚º")
            return False
        finally:
            if old_settings:
                try:
                    termios.tcsetattr(sys.stdin, termios.TCSADRAIN, old_settings)
                except:
                    pass

class RealtimeLearningVisualizer:
    """
    ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å­¦ç¿’å¯è¦–åŒ–ã‚¯ãƒ©ã‚¹ï¼ˆed_v032_simple.pyç§»æ¤ç‰ˆï¼‰
    ed_multi_snn.prompt.mdæ‹¡å¼µæ©Ÿèƒ½5æº–æ‹ 
    """
    
    def __init__(self, max_epochs, window_size=(1000, 640), 
                 learning_rate=0.1, initial_amine=0.25, diffusion_rate=0.5,
                 sigmoid_threshold=1.2, initial_weight_1=0.3, initial_weight_2=0.5,
                 dataset_name='MNIST',
                 train_samples=None, test_samples=None, hidden_layers=None, batch_size=None,
                 v_rest=-65.0, v_threshold=-60.0, v_reset=-70.0, tau_m=20.0,
                 tau_ref=2.0, dt=1.0, R_m=10.0, simulation_time=50.0,
                 random_seed=None, verbose=False):
        """
        å¯è¦–åŒ–ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åˆæœŸåŒ–ï¼ˆ2x2ã‚°ãƒªãƒƒãƒ‰ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ - ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—æº–æ‹ ï¼‰
        Args:
            max_epochs: æœ€å¤§ã‚¨ãƒãƒƒã‚¯æ•°
            window_size: ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º (width, height)
            learning_rate: å­¦ç¿’ç‡ï¼ˆEDæ³•ã®alphaï¼‰
            initial_amine: åˆæœŸã‚¢ãƒŸãƒ³æ¿ƒåº¦ï¼ˆEDæ³•ã®betaï¼‰
            diffusion_rate: ã‚¢ãƒŸãƒ³æ‹¡æ•£ä¿‚æ•°ï¼ˆEDæ³•ã®u1ï¼‰
            sigmoid_threshold: ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¾å€¤ï¼ˆEDæ³•ã®u0ï¼‰
            initial_weight_1: é‡ã¿åˆæœŸå€¤1ï¼ˆèˆˆå¥®æ€§ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ï¼‰
            initial_weight_2: é‡ã¿åˆæœŸå€¤2ï¼ˆæŠ‘åˆ¶æ€§ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ï¼‰
            dataset_name: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå
            train_samples: å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«æ•°
            test_samples: ãƒ†ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«æ•°
            hidden_layers: éš ã‚Œå±¤æ§‹é€ 
            batch_size: ãƒŸãƒ‹ãƒãƒƒãƒã‚µã‚¤ã‚º
            random_seed: ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ï¼ˆv021 Phase 1è¿½åŠ ï¼‰
            verbose: è©³ç´°è¡¨ç¤ºï¼ˆv021 Phase 1è¿½åŠ ï¼‰
        """
        self.max_epochs = max_epochs
        self.window_size = window_size
        # EDæ³•ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆed_multi_snn.prompt.mdæº–æ‹ ï¼‰
        self.learning_rate = learning_rate
        self.initial_amine = initial_amine
        self.diffusion_rate = diffusion_rate
        self.sigmoid_threshold = sigmoid_threshold
        self.initial_weight_1 = initial_weight_1
        self.initial_weight_2 = initial_weight_2
        # LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆv019 Phase 3è¿½åŠ ï¼‰
        self.v_rest = v_rest
        self.v_threshold = v_threshold
        self.v_reset = v_reset
        self.tau_m = tau_m
        self.tau_ref = tau_ref
        self.dt = dt
        self.R_m = R_m
        self.simulation_time = simulation_time
        # å®Ÿè¡Œæ™‚è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.dataset_name = dataset_name
        self.train_samples = train_samples
        self.test_samples = test_samples
        self.hidden_layers = hidden_layers
        self.batch_size = batch_size
        self.random_seed = random_seed  # v021 Phase 1è¿½åŠ 
        self.verbose = verbose          # v021 Phase 1è¿½åŠ 
        
        # ãƒ‡ãƒ¼ã‚¿ä¿å­˜ç”¨
        self.epochs = []
        self.train_accuracies = []
        self.test_accuracies = []
        self.train_error_rates = []  # è¨“ç·´ã‚¨ãƒ©ãƒ¼ç‡ (100 - accuracy)
        self.test_error_rates = []   # ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ç‡ (100 - accuracy)
        
        # ã‚°ãƒ©ãƒ•åˆæœŸåŒ–
        self.fig = None
        self.ax_params_ed = None      # å·¦ä¸Š: EDãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.ax_params_lif = None     # ä¸­ä¸Š: LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆæ–°è¦è¿½åŠ ï¼‰
        self.ax_params_exec = None    # å³ä¸Š: å®Ÿè¡Œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.ax_acc = None             # å·¦ä¸‹: ç²¾åº¦ã‚°ãƒ©ãƒ•
        self.ax_err = None             # å³ä¸‹: ã‚¨ãƒ©ãƒ¼ç‡ã‚°ãƒ©ãƒ•
        self.lines = {}
        
    def setup_plots(self):
        """ã‚°ãƒ©ãƒ•ã®åˆæœŸè¨­å®š - 3ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒœãƒƒã‚¯ã‚¹ + 2ã‚°ãƒ©ãƒ•ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼ˆed_multi_snn.prompt.mdæº–æ‹ ï¼‰"""
        dpi = 100
        figsize = (self.window_size[0]/dpi, self.window_size[1]/dpi)
        
        # ãƒ•ã‚£ã‚®ãƒ¥ã‚¢ä½œæˆ
        self.fig = plt.figure(figsize=figsize, dpi=dpi)
        
        # GridSpecä½œæˆ: 2è¡ŒÃ—3åˆ—ï¼ˆä¸Šæ®µ: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒœãƒƒã‚¯ã‚¹Ã—3ã€ä¸‹æ®µ: ã‚°ãƒ©ãƒ•Ã—2ï¼‰
        import matplotlib.gridspec as gridspec
        gs = gridspec.GridSpec(2, 3, figure=self.fig, hspace=0.4, wspace=0.3,
                               height_ratios=[1, 2])  # ä¸Šæ®µ1:ä¸‹æ®µ2ã®é«˜ã•æ¯”
        
        # ä¸Šæ®µ: 3ã¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒœãƒƒã‚¯ã‚¹ï¼ˆæ¨ªä¸¦ã³ï¼‰
        self.ax_params_ed = self.fig.add_subplot(gs[0, 0])     # å·¦ä¸Š: EDãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.ax_params_lif = self.fig.add_subplot(gs[0, 1])    # ä¸­ä¸Š: LIFãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.ax_params_exec = self.fig.add_subplot(gs[0, 2])   # å³ä¸Š: å®Ÿè¡Œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        
        # ä¸‹æ®µ: 2ã¤ã®ã‚°ãƒ©ãƒ•ï¼ˆå·¦å³ï¼‰
        self.ax_acc = self.fig.add_subplot(gs[1, 0:2])         # å·¦ä¸‹ï½ä¸­ä¸‹: ç²¾åº¦ã‚°ãƒ©ãƒ•ï¼ˆå¹…åºƒï¼‰
        self.ax_err = self.fig.add_subplot(gs[1, 2])           # å³ä¸‹: ã‚¨ãƒ©ãƒ¼ç‡ã‚°ãƒ©ãƒ•
        
        # ãƒ¡ã‚¤ãƒ³ã‚¿ã‚¤ãƒˆãƒ«è¨­å®šï¼ˆãƒãƒ¼ã‚¸ãƒ§ãƒ³ç•ªå·å‰Šé™¤ï¼‰
        self.fig.suptitle("ED-SNN å­¦ç¿’é€²æ— - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º", 
                          fontsize=14, fontweight='bold')
        
        # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚¿ã‚¤ãƒˆãƒ«è¨­å®šï¼ˆãƒãƒ¼ã‚¸ãƒ§ãƒ³ç•ªå·å‰Šé™¤ï¼‰
        try:
            if self.fig.canvas.manager:
                self.fig.canvas.manager.set_window_title("ED-SNN å­¦ç¿’é€²æ— - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º")
        except:
            pass
        
        # === å·¦ä¸Š: EDæ³•ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šï¼ˆed_multi_snn.prompt.mdæº–æ‹ ï¼‰ ===
        self.ax_params_ed.axis('off')
        ed_text = "EDæ³•ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š\n"
        ed_text += f"å­¦ç¿’ç‡(alpha): {self.learning_rate:.3f}\n"
        ed_text += f"åˆæœŸã‚¢ãƒŸãƒ³(beta): {self.initial_amine:.3f}\n"
        ed_text += f"ã‚¢ãƒŸãƒ³æ‹¡æ•£(u1): {self.diffusion_rate:.3f}\n"
        ed_text += f"ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¾å€¤(u0): {self.sigmoid_threshold:.3f}\n"
        ed_text += f"é‡ã¿åˆæœŸå€¤1: {self.initial_weight_1:.3f}\n"
        ed_text += f"é‡ã¿åˆæœŸå€¤2: {self.initial_weight_2:.3f}"
        
        # v021 Phase 2ä¿®æ­£: å·¦å¯„ã›ã«å¤‰æ›´ï¼ˆãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—æº–æ‹ ï¼‰
        self.ax_params_ed.text(0.05, 0.95, ed_text,
                               ha='left', va='top', fontsize=9,
                               bbox=dict(boxstyle="round,pad=0.5", 
                                       facecolor='lightgreen', 
                                       edgecolor='black',
                                       linewidth=2,
                                       alpha=0.8))
        
        # === ä¸­ä¸Š: LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šï¼ˆæ–°è¦è¿½åŠ ï¼‰ ===
        self.ax_params_lif.axis('off')
        lif_text = "LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š\n"
        lif_text += f"é™æ­¢è†œé›»ä½: {self.v_rest:.1f} mV\n"
        lif_text += f"ç™ºç«é–¾å€¤: {self.v_threshold:.1f} mV\n"
        lif_text += f"ãƒªã‚»ãƒƒãƒˆé›»ä½: {self.v_reset:.1f} mV\n"
        lif_text += f"è†œæ™‚å®šæ•°: {self.tau_m:.1f} ms\n"
        lif_text += f"ä¸å¿œæœŸ: {self.tau_ref:.1f} ms\n"
        lif_text += f"æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—: {self.dt:.1f} ms\n"
        lif_text += f"è†œæŠµæŠ—: {self.R_m:.1f} MÎ©\n"
        lif_text += f"ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ™‚é–“: {self.simulation_time:.1f} ms"
        
        # v021 Phase 2ä¿®æ­£: å·¦å¯„ã›ã«å¤‰æ›´ï¼ˆãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—æº–æ‹ ï¼‰
        self.ax_params_lif.text(0.05, 0.95, lif_text,
                                ha='left', va='top', fontsize=9,
                                bbox=dict(boxstyle="round,pad=0.5", 
                                        facecolor='lightgreen', 
                                        edgecolor='black',
                                        linewidth=2,
                                        alpha=0.8))
        
        # === å³ä¸Š: å®Ÿè¡Œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šï¼ˆãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—æº–æ‹ ï¼‰ ===
        self.ax_params_exec.axis('off')
        exec_text = "å®Ÿè¡Œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š\n"
        exec_text += f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {self.dataset_name}\n"
        exec_text += f"ã‚¨ãƒãƒƒã‚¯æ•°: {self.max_epochs}\n"
        if self.train_samples:
            exec_text += f"å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«: {self.train_samples}\n"
        if self.test_samples:
            exec_text += f"ãƒ†ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«: {self.test_samples}\n"
        if self.hidden_layers:
            exec_text += f"éš ã‚Œå±¤æ§‹é€ : {self.hidden_layers}\n"
        if self.batch_size:
            exec_text += f"ãƒŸãƒ‹ãƒãƒƒãƒã‚µã‚¤ã‚º: {self.batch_size}\n"
        # v021 Phase 1è¿½åŠ : ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ã¨è©³ç´°è¡¨ç¤º
        seed_str = str(self.random_seed) if self.random_seed is not None else "ãƒ©ãƒ³ãƒ€ãƒ "
        exec_text += f"ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰: {seed_str}\n"
        verbose_str = "ON" if self.verbose else "OFF"
        exec_text += f"è©³ç´°è¡¨ç¤º: {verbose_str}"
        
        # v021 Phase 1ä¿®æ­£: å·¦å¯„ã›ã«å¤‰æ›´ï¼ˆãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—æº–æ‹ ï¼‰
        self.ax_params_exec.text(0.05, 0.95, exec_text,
                                 ha='left', va='top', fontsize=9,
                                 bbox=dict(boxstyle="round,pad=0.5", 
                                         facecolor='lightgreen', 
                                         edgecolor='black',
                                         linewidth=2,
                                         alpha=0.6))
        
        # === å·¦ä¸‹ï½ä¸­ä¸‹: è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆæ­£ç­”ç‡ï¼ˆå¹…åºƒï¼‰ ===
        self.ax_acc.set_title("è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆæ­£ç­”ç‡", fontweight='bold')
        self.ax_acc.set_xlabel("ã‚¨ãƒãƒƒã‚¯æ•°")
        self.ax_acc.set_ylabel("ç²¾åº¦ (%)")
        self.ax_acc.set_xlim(1, max(2, self.max_epochs))
        self.ax_acc.set_ylim(0, 100)
        self.ax_acc.grid(True, alpha=0.3)
        
        # === å³ä¸‹: è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ç‡ ===
        self.ax_err.set_title("è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ç‡", fontweight='bold')
        self.ax_err.set_xlabel("ã‚¨ãƒãƒƒã‚¯æ•°")
        self.ax_err.set_ylabel("ã‚¨ãƒ©ãƒ¼ç‡ (%)")
        self.ax_err.set_xlim(1, max(2, self.max_epochs))
        self.ax_err.set_ylim(0, 100)  # ã‚¨ãƒ©ãƒ¼ç‡: 0-100%
        self.ax_err.grid(True, alpha=0.3)
        
        # ç·šã®åˆæœŸåŒ–ï¼ˆã‚¨ãƒ©ãƒ¼ç‡ = 100% - ç²¾åº¦ï¼‰
        self.lines['train_acc'], = self.ax_acc.plot([], [], 'b-', label='è¨“ç·´æ­£ç­”ç‡', linewidth=2)
        self.lines['test_acc'], = self.ax_acc.plot([], [], 'r-', label='ãƒ†ã‚¹ãƒˆæ­£ç­”ç‡', linewidth=2)
        self.lines['train_err'], = self.ax_err.plot([], [], 'b-', label='è¨“ç·´ã‚¨ãƒ©ãƒ¼ç‡', linewidth=2)
        self.lines['test_err'], = self.ax_err.plot([], [], 'r-', label='ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ç‡', linewidth=2)
        
        # å‡¡ä¾‹è¨­å®š
        self.ax_acc.legend(loc='lower right', fontsize=10, framealpha=0.9)
        self.ax_err.legend(loc='upper right', fontsize=10, framealpha=0.9)
        
        # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ç”¨ã®ã‚¹ãƒšãƒ¼ã‚¹ç¢ºä¿ï¼‰
        plt.tight_layout(rect=[0, 0, 1, 0.96])
        
        # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰æœ‰åŠ¹åŒ–ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºã®éµï¼‰
        backend = matplotlib.get_backend()
        print(f"ï¿½ matplotlib backend: {backend}")
        
        plt.ion()
        is_interactive = plt.isinteractive()
        print(f"ğŸ“Š ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰: {'æœ‰åŠ¹' if is_interactive else 'ç„¡åŠ¹'}")
        
        if backend.lower() == 'agg':
            print("âš ï¸  è­¦å‘Š: éè¡¨ç¤ºãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰(agg)ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
            print("    ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºã«ã¯å¯¾è©±çš„ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰(Qt5Agg/TkAgg)ãŒå¿…è¦ã§ã™")
            print("    ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã®ã¿å®Ÿè¡Œã•ã‚Œã¾ã™")
        
        # éãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°è¡¨ç¤º
        with warnings.catch_warnings():
            warnings.simplefilter("ignore", UserWarning)
            plt.show(block=False)
        
        # åˆæœŸæç”»ã‚’å¼·åˆ¶å®Ÿè¡Œ
        if hasattr(self.fig, 'canvas') and self.fig.canvas:
            self.fig.canvas.draw()
            self.fig.canvas.flush_events()
            
            # ç¢ºå®Ÿãªè¡¨ç¤ºã®ãŸã‚å°‘ã—é•·ã‚ã®å¾…æ©Ÿ
            with warnings.catch_warnings():
                warnings.simplefilter("ignore", UserWarning)
                plt.pause(0.1)  # 0.1ç§’å¾…æ©Ÿ
        
        if is_interactive and backend.lower() != 'agg':
            print("âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’è¡¨ç¤ºä¸­ï¼ˆå­¦ç¿’åˆæœŸã‹ã‚‰æ›´æ–°ã•ã‚Œã¾ã™ï¼‰")
    
    def update(self, epoch, train_acc, test_acc, train_err_rate, test_err_rate):
        """
        ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿æ›´æ–° - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º
        Args:
            epoch: ç¾åœ¨ã®ã‚¨ãƒãƒƒã‚¯
            train_acc: è¨“ç·´æ­£ç­”ç‡ (%)
            test_acc: ãƒ†ã‚¹ãƒˆæ­£ç­”ç‡ (%)
            train_err_rate: è¨“ç·´ã‚¨ãƒ©ãƒ¼ç‡ (%) = 100 - train_acc
            test_err_rate: ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ç‡ (%) = 100 - test_acc
        """
        # ãƒ‡ãƒ¼ã‚¿è¿½åŠ 
        self.epochs.append(epoch + 1)  # ã‚¨ãƒãƒƒã‚¯ã¯1ã‹ã‚‰é–‹å§‹
        self.train_accuracies.append(train_acc)
        self.test_accuracies.append(test_acc)
        self.train_error_rates.append(train_err_rate)  # ã‚¨ãƒ©ãƒ¼ç‡: 0-100%
        self.test_error_rates.append(test_err_rate)    # ã‚¨ãƒ©ãƒ¼ç‡: 0-100%
        
        # ç·šãƒ‡ãƒ¼ã‚¿æ›´æ–°
        self.lines['train_acc'].set_data(self.epochs, self.train_accuracies)
        self.lines['test_acc'].set_data(self.epochs, self.test_accuracies)
        self.lines['train_err'].set_data(self.epochs, self.train_error_rates)
        self.lines['test_err'].set_data(self.epochs, self.test_error_rates)
        
        # ã‚¨ãƒ©ãƒ¼ç‡ã‚°ãƒ©ãƒ•ã®ç¸¦è»¸ã¯0-100%å›ºå®šï¼ˆã‚¨ãƒ©ãƒ¼ç‡ã®å®šç¾©ä¸Šï¼‰
        # å‹•çš„ã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´ã¯ä¸è¦ï¼ˆå¸¸ã«0-100%ã®ç¯„å›²å†…ï¼‰
        
        # ã‚°ãƒ©ãƒ•å†æç”»ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°ã®éµï¼‰
        try:
            self.ax_acc.relim()
            self.ax_acc.autoscale_view()
            self.ax_err.relim()
            self.ax_err.autoscale_view()
            
            self.fig.canvas.draw()
            self.fig.canvas.flush_events()
            
            # çŸ­æ™‚é–“ã®ä¸€æ™‚åœæ­¢ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º
            with warnings.catch_warnings():
                warnings.simplefilter("ignore", UserWarning)
                plt.pause(0.05)  # 0.05ç§’å¾…æ©Ÿï¼ˆç¢ºå®Ÿãªè¡¨ç¤ºæ›´æ–°ï¼‰
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼ãŒã‚ã£ã¦ã‚‚å‡¦ç†ç¶™ç¶šï¼ˆéè¡¨ç¤ºãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã§ã‚‚å‹•ä½œï¼‰
            pass
    
    def close(self):
        """å¯è¦–åŒ–ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’é–‰ã˜ã‚‹"""
        if self.fig:
            try:
                with warnings.catch_warnings():
                    warnings.simplefilter("ignore", UserWarning)
                    plt.close(self.fig)
            except Exception:
                plt.close(self.fig)
    
    def save_figure(self, save_dir=None):
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å­¦ç¿’ã‚°ãƒ©ãƒ•ã‚’ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ•ã‚¡ã‚¤ãƒ«åã§ä¿å­˜ã™ã‚‹
        
        Args:
            save_dir: ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (Noneã®å ´åˆã¯ä¿å­˜ã—ãªã„)
        """
        if not self.fig or save_dir is None:
            return
        
        # ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        os.makedirs(save_dir, exist_ok=True)
        
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ•ã‚¡ã‚¤ãƒ«åã®ç”Ÿæˆ
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f'realtime_viz_result_{timestamp}.png'
        filepath = os.path.join(save_dir, filename)
        
        try:
            self.fig.savefig(filepath, dpi=150, bbox_inches='tight')
            print(f"âœ… å­¦ç¿’æ›²ç·šä¿å­˜: {filepath}")
        except Exception as e:
            print(f"âŒ ã‚°ãƒ©ãƒ•ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

def convert_ed_outputs_to_spike_activities(ed_core, inputs, original_image_shape=(28, 28)):
    """
    EDå‡ºåŠ›ã‚’ã‚¹ãƒ‘ã‚¤ã‚¯æ´»å‹•ã«å¤‰æ›ï¼ˆãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”¨ï¼‰
    
    Args:
        ed_core: ED Coreã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        inputs: E/Iãƒšã‚¢åŒ–ã•ã‚ŒãŸå…¥åŠ›ï¼ˆshape: [paired_input_size]ï¼‰
        original_image_shape: å…ƒã®ç”»åƒå½¢çŠ¶ï¼ˆ(28, 28), (32, 32, 3)ãªã©ï¼‰
    """
    spike_activities = []
    
    try:
        # å…ƒã®ç”»åƒã®ãƒ”ã‚¯ã‚»ãƒ«æ•°ã‚’è¨ˆç®—
        base_size = np.prod(original_image_shape)
        
        # å…¥åŠ›å±¤ï¼ˆå…ƒã®ç”»åƒå½¢çŠ¶ã§å¾©å…ƒï¼‰
        # E/Iãƒšã‚¢åŒ–ã•ã‚ŒãŸå…¥åŠ›ã‹ã‚‰èˆˆå¥®æ€§ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®å€¤ã‚’æŠ½å‡º
        if len(inputs) >= base_size * 2:
            # GPUé…åˆ—ã®å ´åˆã¯.get()ã§CPUã«è»¢é€
            if hasattr(inputs, 'get'):
                inputs_cpu = inputs.get()
            else:
                inputs_cpu = np.asarray(inputs)
            
            input_excitatory = inputs_cpu[0::2][:base_size]
            input_layer = input_excitatory.reshape(original_image_shape)
            # ã‚«ãƒ©ãƒ¼ç”»åƒã®å ´åˆã¯ãã®ã¾ã¾ã€ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ã®å ´åˆã¯flattenã—ã¦è¿½åŠ 
            if len(original_image_shape) == 3:
                # ã‚«ãƒ©ãƒ¼ç”»åƒ: (H, W, 3) ã®å½¢çŠ¶ã‚’ä¿æŒ
                spike_activities.append(input_layer)
            else:
                # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«: (H, W) â†’ flatten ã—ã¦ (H*W,)
                spike_activities.append(input_layer.flatten())
        else:
            spike_activities.append(np.random.random(base_size))
        
        # éš ã‚Œå±¤
        if hasattr(ed_core, 'layer_outputs') and len(ed_core.layer_outputs) > 0:
            output_neuron_layers = ed_core.layer_outputs[0]
            for layer_output in output_neuron_layers[:-1]:
                # GPUé…åˆ—ã®å ´åˆã¯.get()ã§CPUã«è»¢é€
                if hasattr(layer_output, 'get'):
                    spike_activities.append(layer_output.get())
                else:
                    spike_activities.append(np.asarray(layer_output))
        else:
            spike_activities.append(np.random.random(64))
        
        # å‡ºåŠ›å±¤
        if hasattr(ed_core, 'layer_outputs') and len(ed_core.layer_outputs) > 0:
            output_activities = []
            for n in range(ed_core.output_units):
                if len(ed_core.layer_outputs[n]) > 0:
                    output_value = ed_core.layer_outputs[n][-1][0]
                    # GPUé…åˆ—ã®å ´åˆã¯.get()ã§CPUã«è»¢é€
                    if hasattr(output_value, 'get'):
                        output_activities.append(float(output_value.get()))
                    else:
                        output_activities.append(float(output_value))
            
            if output_activities:
                output_activity = np.array(output_activities)
            else:
                output_activity = np.random.random(ed_core.output_units) * 0.5
        else:
            output_activity = np.random.random(ed_core.output_units) * 0.5
        spike_activities.append(output_activity)
        
    except Exception as e:
        print(f"âš ï¸ ã‚¹ãƒ‘ã‚¤ã‚¯æ´»å‹•å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
        base_size = np.prod(original_image_shape)
        spike_activities = [
            np.random.random(base_size),
            np.random.random(64),
            np.random.random(ed_core.output_units)
        ]
    
    return spike_activities

class PureEDPreprocessor:
    """
    EDæ³•ç´”ç²‹ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†å™¨ï¼ˆed_multi_snn.prompt.mdæº–æ‹ ï¼‰
    """
    
    @staticmethod
    def pure_ed_preprocess(images, labels, input_size):
        """ç´”ç²‹EDæ³•å‰å‡¦ç†"""
        batch_size = len(images)
        
        # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–
        images_flat = images.reshape(batch_size, -1)
        images_normalized = images_flat / 255.0
        
        # å…¥åŠ›ã‚µã‚¤ã‚ºèª¿æ•´
        if images_normalized.shape[1] != input_size:
            if images_normalized.shape[1] > input_size:
                images_resized = images_normalized[:, :input_size]
            else:
                images_resized = np.zeros((batch_size, input_size))
                images_resized[:, :images_normalized.shape[1]] = images_normalized
        else:
            images_resized = images_normalized
            
        # ============================================================================
        # èˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãƒšã‚¢ (E/I pair)
        # ============================================================================
        # WHY: å…¥åŠ›ã®æ­£è² ä¸¡æ–¹ã®æƒ…å ±ã‚’ä¿æŒã™ã‚‹ãŸã‚
        # WHY: å„ãƒ”ã‚¯ã‚»ãƒ«å€¤ã‚’èˆˆå¥®æ€§ï¼ˆ+ï¼‰ã¨æŠ‘åˆ¶æ€§ï¼ˆ-ï¼‰ã®2ã¤ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã§è¡¨ç¾
        # WHY: å®Ÿéš›ã®è„³ã®èˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§ã®ãƒãƒ©ãƒ³ã‚¹ã‚’å†ç¾
        # EDæ³•èˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§ãƒšã‚¢æ§‹é€ ï¼ˆed_multi_snn.prompt.mdæº–æ‹ ï¼‰
        ed_paired_input = np.zeros((batch_size, input_size * 2))
        ed_paired_input[:, 0::2] = images_resized  # èˆˆå¥®æ€§
        ed_paired_input[:, 1::2] = images_resized  # æŠ‘åˆ¶æ€§
        
        return ed_paired_input, labels


def convert_to_lif_input(image_data: np.ndarray, scale_factor: float = 10.0) -> np.ndarray:
    """
    ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’LIFå±¤ã¸ã®å…¥åŠ›é›»æµã«å¤‰æ›ï¼ˆv019 Phase 11ä¿®æ­£ï¼‰
    
    Parameters
    ----------
    image_data : np.ndarray
        æ­£è¦åŒ–æ¸ˆã¿ç”»åƒãƒ‡ãƒ¼ã‚¿ (0-1)
        784å€‹ï¼ˆMNISTï¼‰ã¾ãŸã¯1568å€‹ï¼ˆæ—¢ã«E/Iãƒšã‚¢åŒ–æ¸ˆã¿ï¼‰
    scale_factor : float
        é›»æµã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10.0 nAï¼‰
        
    Returns
    -------
    np.ndarray
        é›»æµãƒ‘ã‚¿ãƒ¼ãƒ³ (nAå˜ä½)
        **Phase 11**: 1568å€‹ï¼ˆèˆˆå¥®æ€§784å€‹+æŠ‘åˆ¶æ€§784å€‹ï¼‰
        
    Note
    ----
    v019 Phase 11ä¿®æ­£: EDæ³•ä»•æ§˜ã«å®Œå…¨æº–æ‹ 
    - é‡‘å­å‹‡æ°ã®ã‚ªãƒªã‚¸ãƒŠãƒ«EDæ³•ã§ã¯å…¥åŠ›å±¤ã¯èˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§ãƒšã‚¢æ§‹æˆãŒå¿…é ˆ
    - ç‰©ç†çš„ã«1568å€‹ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ï¼ˆèˆˆå¥®æ€§784å€‹+æŠ‘åˆ¶æ€§784å€‹ï¼‰ã§æ§‹æˆ
    - å…¥åŠ›ãŒ784å€‹ã®å ´åˆ: 1568å€‹ã«å¤‰æ›
    - å…¥åŠ›ãŒ1568å€‹ã®å ´åˆ: ãã®ã¾ã¾å‡¦ç†ï¼ˆæ—¢ã«ãƒšã‚¢åŒ–æ¸ˆã¿ï¼‰
    
    ç°¡æ˜“ç‰ˆå®Ÿè£…: ç”»åƒå¼·åº¦ Ã— ã‚¹ã‚±ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼
    0-1 â†’ 0-10 nA ã®ç¯„å›²ã«å¤‰æ›
    
    å°†æ¥æ‹¡å¼µ:
    - ãƒã‚¢ã‚½ãƒ³ã‚¹ãƒ‘ã‚¤ã‚¯åˆ—ç”Ÿæˆ
    - æ™‚é–“çš„ãƒ‘ã‚¿ãƒ¼ãƒ³å¤‰æ›
    - ãƒ¬ãƒ¼ãƒˆç¬¦å·åŒ–/æ™‚é–“ç¬¦å·åŒ–åˆ‡ã‚Šæ›¿ãˆ
    """
    # v019 Phase 11: EDæ³•ä»•æ§˜æº–æ‹ ã®å®Ÿè£…
    
    # å…¥åŠ›ãŒæ—¢ã«1568å€‹ï¼ˆE/Iãƒšã‚¢åŒ–æ¸ˆã¿ï¼‰ã®å ´åˆ
    if len(image_data) == 1568:
        # ãã®ã¾ã¾é›»æµã«å¤‰æ›
        current_pattern = image_data * scale_factor
        min_activation = 0.01
        current_pattern = current_pattern + min_activation
        return current_pattern
    
    # å…¥åŠ›ãŒ784å€‹ã®å ´åˆ: 1568å€‹ã«å¤‰æ›
    current_pattern = image_data * scale_factor
    
    # æœ€å°æ´»æ€§åŒ–å€¤ã‚’è¿½åŠ ï¼ˆå®Œå…¨ãªã‚¼ãƒ­ã‚’é¿ã‘ã‚‹ï¼‰
    min_activation = 0.01
    current_pattern = current_pattern + min_activation
    
    # èˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§ãƒšã‚¢ã«å¤‰æ›
    # [pixel0, pixel1, ...] â†’ [exc0, inh0, exc1, inh1, ...]
    paired_pattern = np.zeros(len(current_pattern) * 2)
    for i in range(len(current_pattern)):
        paired_pattern[2*i] = current_pattern[i]      # èˆˆå¥®æ€§ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³
        paired_pattern[2*i + 1] = current_pattern[i]  # æŠ‘åˆ¶æ€§ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ï¼ˆåŒã˜å€¤ï¼‰
    
    return paired_pattern  # 1568å€‹ã‚’è¿”ã™


class MultiLayerEDCore:
    """
    çœŸã®å¤šå±¤å¯¾å¿œç´”ç²‹Error-Diffusionå­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆv012/v013ç‰ˆï¼‰
    ed_multi_snn.prompt.mdæ‹¡å¼µæ©Ÿèƒ½1å®Œå…¨æº–æ‹ 
    """
    
    def __init__(self, input_size, hidden_sizes, output_size, learning_rate=0.8,
                 initial_amine=0.25, diffusion_rate=0.5, sigmoid_threshold=1.2,
                 initial_weight_1=0.3, initial_weight_2=0.5, snn=None, hp=None):
        """çœŸã®å¤šå±¤EDæ³•åˆæœŸåŒ–ï¼ˆed_multi_snn.prompt.mdæº–æ‹ ï¼‰
        
        Args:
            snn: SpikingNeuralNetwork instance (v019 Phase 5è¿½åŠ )
            hp: HyperParams instance (v019 Phase 5è¿½åŠ )
        """
        self.input_size = input_size
        self.hidden_sizes = hidden_sizes if hidden_sizes else [64]
        self.output_size = output_size
        self.learning_rate = learning_rate
        
        # v019 Phase 5: LIFçµ±åˆç”¨
        self.snn = snn
        self.hp = hp
        self.lif_stats = {'firing_rates': [], 'total_spikes': 0, 'avg_voltage': 0.0}  # LIFçµ±è¨ˆæƒ…å ±
        
        # éš ã‚Œå±¤ã‚µã‚¤ã‚ºã‚’å¶æ•°ã«èª¿æ•´
        self.hidden_sizes = [size + (size % 2) for size in self.hidden_sizes]
        
        # v019 Phase 14ä¿®æ­£: å…¥åŠ›ãƒ¦ãƒ‹ãƒƒãƒˆæ•°ã¯å¸¸ã«1568å€‹
        # é‡‘å­å‹‡æ°ã®ã‚ªãƒªã‚¸ãƒŠãƒ«å®Ÿè£…è§£æã«ã‚ˆã‚Šåˆ¤æ˜:
        # - å…¨1568å€‹ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ï¼ˆèˆˆå¥®æ€§784å€‹+æŠ‘åˆ¶æ€§784å€‹ï¼‰ãŒæ¬¡å±¤ã«æ¥ç¶š
        # - LIFä½¿ç”¨/ä¸ä½¿ç”¨ã¯é–¢ä¿‚ãªãã€å¸¸ã«1568å€‹
        # - Phase 12ã®æ¡ä»¶åˆ†å²ã¯èª¤ã‚Šã§ã—ãŸ
        self.input_units = input_size  # å¸¸ã«1568å€‹ï¼ˆE/Iãƒšã‚¢æ§‹é€ ï¼‰
        self.output_units = output_size
        
        # EDæ³•ã‚³ã‚¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆed_multi_snn.prompt.mdæº–æ‹ ï¼‰
        self.initial_amine = initial_amine          # Î²: åˆæœŸã‚¢ãƒŸãƒ³æ¿ƒåº¦
        self.diffusion_rate = diffusion_rate        # u1: ã‚¢ãƒŸãƒ³æ‹¡æ•£ä¿‚æ•°
        self.sigmoid_threshold = sigmoid_threshold  # u0: ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¾å€¤
        self.initial_weight_1 = initial_weight_1    # é‡ã¿åˆæœŸå€¤1ï¼ˆèˆˆå¥®æ€§ï¼‰
        self.initial_weight_2 = initial_weight_2    # é‡ã¿åˆæœŸå€¤2ï¼ˆæŠ‘åˆ¶æ€§ï¼‰
        self.time_loops = 2  # è¤‡æ•°å›ã®ãƒ«ãƒ¼ãƒ—ã§å®‰å®šã—ãŸå¿œç­”ã‚’å¾—ã‚‹
        
        # GPUå¯¾å¿œï¼ˆed_multi_snn.prompt.md æ‹¡å¼µæ©Ÿèƒ½7æº–æ‹  + --cpuã‚ªãƒ—ã‚·ãƒ§ãƒ³å¯¾å¿œï¼‰
        self.use_gpu = GPU_AVAILABLE and not (hp.force_cpu if hp else False)
        self.xp = np if (hp and hp.force_cpu) else xp
        if self.use_gpu:
            print("ğŸš€ EDæ³•ã‚³ã‚¢: GPUï¼ˆCuPyï¼‰ã§åˆæœŸåŒ–")
        elif hp and hp.force_cpu and GPU_AVAILABLE:
            print("ğŸ”§ EDæ³•ã‚³ã‚¢: CPUå¼·åˆ¶å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ï¼ˆ--cpuã‚ªãƒ—ã‚·ãƒ§ãƒ³æŒ‡å®šï¼‰")
        
        # å±¤ã”ã¨ã®é‡ã¿è¡Œåˆ—ï¼ˆed_multi_snn.prompt.mdæº–æ‹ ã®åˆæœŸå€¤ä½¿ç”¨ï¼‰
        # GPUå¯¾å¿œ: é‡ã¿è¡Œåˆ—ã‚’GPUä¸Šã«ä¿æŒ
        self.layer_weights = []
        for n in range(self.output_units):
            neuron_weights = []
            
            # Input â†’ Hidden1
            # èˆˆå¥®æ€§ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³: initial_weight_1, æŠ‘åˆ¶æ€§: initial_weight_2
            w_input_h1 = np.random.uniform(self.initial_weight_1, self.initial_weight_2, 
                                          (self.hidden_sizes[0], self.input_units))
            if self.use_gpu:
                w_input_h1 = self.xp.asarray(w_input_h1)
            neuron_weights.append(w_input_h1)
            
            # Hidden_i â†’ Hidden_{i+1}
            for i in range(len(self.hidden_sizes) - 1):
                w_h_h = np.random.uniform(self.initial_weight_1, self.initial_weight_2, 
                                         (self.hidden_sizes[i+1], self.hidden_sizes[i]))
                if self.use_gpu:
                    w_h_h = self.xp.asarray(w_h_h)
                neuron_weights.append(w_h_h)
            
            # Hidden_last â†’ Output
            w_h_output = np.random.uniform(self.initial_weight_1, self.initial_weight_2, 
                                          (1, self.hidden_sizes[-1]))
            if self.use_gpu:
                w_h_output = self.xp.asarray(w_h_output)
            neuron_weights.append(w_h_output)
            
            self.layer_weights.append(neuron_weights)
        
        # ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚¿ã‚¤ãƒ—åˆæœŸåŒ–
        self._initialize_neuron_types()
        
        # ============================================================================
        # Dale's Principleï¼ˆãƒ‡ãƒ¼ãƒ«ã®åŸç†ï¼‰
        # ============================================================================
        # WHY: å®Ÿéš›ã®è„³ã§ã¯1ã¤ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯èˆˆå¥®æ€§ã¾ãŸã¯æŠ‘åˆ¶æ€§ã®ã©ã¡ã‚‰ã‹ä¸€æ–¹ã®ã¿
        # WHY: é‡ã¿ç¬¦å·ã‚’ä¿æŒã™ã‚‹ã“ã¨ã§ç”Ÿç‰©å­¦çš„å¦¥å½“æ€§ã‚’ç¢ºä¿
        # WHY: èˆˆå¥®æ€§ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³â†’æ­£ã®é‡ã¿ã®ã¿ã€æŠ‘åˆ¶æ€§ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³â†’è² ã®é‡ã¿ã®ã¿
        # Dale's Principleé©ç”¨
        self._apply_dales_principle()
        
        # ã‚¢ãƒŸãƒ³æ¿ƒåº¦é…åˆ—
        self.layer_amine_concentrations = []
        for n in range(self.output_units):
            layer_amines = []
            for size in self.hidden_sizes:
                layer_amines.append(np.zeros((size, 2)))
            layer_amines.append(np.zeros((1, 2)))
            self.layer_amine_concentrations.append(layer_amines)
        
        # å±¤å‡ºåŠ›ä¿å­˜ç”¨
        self.layer_outputs = []
        for n in range(self.output_units):
            layer_outs = [np.zeros(size) for size in self.hidden_sizes]
            layer_outs.append(np.zeros(1))
            self.layer_outputs.append(layer_outs)
        
        # å­¦ç¿’çµ±è¨ˆ
        self.error = 0.0
        self.error_count = 0
        
        print(f"âœ… çœŸã®å¤šå±¤EDæ³•åˆæœŸåŒ–å®Œäº†ï¼ˆå±¤æ•°: {len(self.hidden_sizes) + 1}ï¼‰")
    
    def _initialize_neuron_types(self):
        """ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚¿ã‚¤ãƒ—åˆæœŸåŒ–ï¼ˆPhase 12: ã‚ªãƒªã‚¸ãƒŠãƒ«Cã‚³ãƒ¼ãƒ‰æº–æ‹ ï¼‰
        
        é‡‘å­å‹‡æ°ã®Cã‚³ãƒ¼ãƒ‰: ow[k] = ((k+1) % 2) * 2 - 1
        - ow[0] = 1 (èˆˆå¥®æ€§)
        - ow[1] = -1 (æŠ‘åˆ¶æ€§)
        - ow[2] = 1 (èˆˆå¥®æ€§)
        - ow[3] = -1 (æŠ‘åˆ¶æ€§)
        ...
        
        Phase 12ä¿®æ­£: å…¥åŠ›å±¤ã¯1568å€‹ã®ç‰©ç†çš„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³
        """
        # å…¥åŠ›å±¤: 1568å€‹ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚¿ã‚¤ãƒ—ï¼ˆèˆˆå¥®æ€§/æŠ‘åˆ¶æ€§äº¤äº’ï¼‰
        # ã‚ªãƒªã‚¸ãƒŠãƒ«Cã‚³ãƒ¼ãƒ‰ã¨å®Œå…¨ã«åŒã˜ãƒ­ã‚¸ãƒƒã‚¯
        self.input_neuron_types = np.ones(self.input_units)
        for i in range(1, self.input_units, 2):
            self.input_neuron_types[i] = -1
        
        # éš ã‚Œå±¤: æ—¢å­˜ã®å®Ÿè£…ã‚’ç¶­æŒï¼ˆãƒãƒ«ãƒã‚¯ãƒ©ã‚¹æ‹¡å¼µæ©Ÿèƒ½ï¼‰
        self.hidden_neuron_types = []
        for size in self.hidden_sizes:
            types = np.ones(size)
            for i in range(1, size, 2):
                types[i] = -1
            self.hidden_neuron_types.append(types)
        
        # å‡ºåŠ›å±¤: å…¨ã¦èˆˆå¥®æ€§ï¼ˆãƒãƒ«ãƒã‚¯ãƒ©ã‚¹æ‹¡å¼µæ©Ÿèƒ½ï¼‰
        self.output_neuron_types = np.ones(self.output_units)
    
    def _apply_dales_principle(self):
        """Dale's Principleé©ç”¨ï¼ˆPhase 12: ã‚ªãƒªã‚¸ãƒŠãƒ«Cã‚³ãƒ¼ãƒ‰æº–æ‹  + GPUå¯¾å¿œï¼‰
        
        é‡‘å­å‹‡æ°ã®Cã‚³ãƒ¼ãƒ‰: w_ot_ot[n][k][l] *= ow[l] * ow[k]
        - åŒç¨®ã®ç´°èƒé–“ï¼ˆEâ†’Eã€Iâ†’Iï¼‰: ow[l] * ow[k] = 1 â†’ æ­£ã®é‡ã¿
        - ç•°ç¨®ã®ç´°èƒé–“ï¼ˆEâ†’Iã€Iâ†’Eï¼‰: ow[l] * ow[k] = -1 â†’ è² ã®é‡ã¿
        
        Phase 12ä¿®æ­£: 1568å€‹ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚¿ã‚¤ãƒ—é…åˆ—ã‚’ä½¿ç”¨
        GPUæœ€é©åŒ–: ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸãƒã‚¹ã‚¯æ¼”ç®—ã‚’ä½¿ç”¨
        """
        for n in range(self.output_units):
            # Input â†’ Hidden1ï¼ˆ1568å€‹ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚¿ã‚¤ãƒ—é…åˆ—ã‚’ä½¿ç”¨ï¼‰
            # GPUæœ€é©åŒ–: ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            if self.use_gpu:
                # GPUä¸Šã§ãƒ™ã‚¯ãƒˆãƒ«åŒ–æ¼”ç®—
                src_types = self.xp.asarray(self.input_neuron_types).reshape(1, -1)
                dst_types = self.xp.asarray(self.hidden_neuron_types[0]).reshape(-1, 1)
                mask = src_types * dst_types
                self.layer_weights[n][0] *= mask
            else:
                for i in range(self.hidden_sizes[0]):
                    dst_type = self.hidden_neuron_types[0][i]
                    for j in range(self.input_units):
                        src_type = self.input_neuron_types[j]
                        # ã‚ªãƒªã‚¸ãƒŠãƒ«Cã‚³ãƒ¼ãƒ‰ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯: w *= ow[l] * ow[k]
                        self.layer_weights[n][0][i, j] *= src_type * dst_type
            
            # Hiddenå±¤é–“ï¼ˆãƒãƒ«ãƒã‚¯ãƒ©ã‚¹æ‹¡å¼µæ©Ÿèƒ½ã‚’ç¶­æŒ + GPUæœ€é©åŒ–ï¼‰
            for layer_idx in range(len(self.hidden_sizes) - 1):
                if self.use_gpu:
                    # GPUä¸Šã§ãƒ™ã‚¯ãƒˆãƒ«åŒ–æ¼”ç®—
                    src_types = self.xp.asarray(self.hidden_neuron_types[layer_idx]).reshape(1, -1)
                    dst_types = self.xp.asarray(self.hidden_neuron_types[layer_idx + 1]).reshape(-1, 1)
                    mask = src_types * dst_types
                    self.layer_weights[n][layer_idx + 1] *= mask
                else:
                    src_types = self.hidden_neuron_types[layer_idx]
                    dst_types = self.hidden_neuron_types[layer_idx + 1]
                    for i in range(self.hidden_sizes[layer_idx + 1]):
                        dst_type = dst_types[i]
                        for j in range(self.hidden_sizes[layer_idx]):
                            src_type = src_types[j]
                            self.layer_weights[n][layer_idx + 1][i, j] *= src_type * dst_type
            
            # Hidden_last â†’ Outputï¼ˆãƒãƒ«ãƒã‚¯ãƒ©ã‚¹æ‹¡å¼µæ©Ÿèƒ½ã‚’ç¶­æŒ + GPUæœ€é©åŒ–ï¼‰
            last_layer_idx = len(self.hidden_sizes)
            if self.use_gpu:
                # GPUä¸Šã§ãƒ™ã‚¯ãƒˆãƒ«åŒ–æ¼”ç®—
                src_types = self.xp.asarray(self.hidden_neuron_types[-1]).reshape(1, -1)
                output_type = self.output_neuron_types[n]
                mask = src_types * output_type
                self.layer_weights[n][last_layer_idx] *= mask
            else:
                last_hidden_types = self.hidden_neuron_types[-1]
                output_type = self.output_neuron_types[n]
                for j in range(self.hidden_sizes[-1]):
                    src_type = last_hidden_types[j]
                    # ã‚ªãƒªã‚¸ãƒŠãƒ«Cã‚³ãƒ¼ãƒ‰ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯: w *= ow[l] * ow[k]
                    self.layer_weights[n][last_layer_idx][0, j] *= src_type * output_type
    
    def sigmoid(self, x):
        """ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¢æ•°"""
        safe_x = -2.0 * x / self.sigmoid_threshold
        safe_x = np.clip(safe_x, -500, 500)
        return 1.0 / (1.0 + np.exp(safe_x))
    
    def _sigmoid_vectorized(self, x):
        """ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¢æ•°ï¼ˆGPUå¯¾å¿œï¼‰"""
        safe_x = -2.0 * x / self.sigmoid_threshold
        safe_x = self.xp.clip(safe_x, -500, 500)
        return 1.0 / (1.0 + self.xp.exp(safe_x))
    
    # ========================================
    # Step 3a: ã‚¹ãƒ‘ã‚¤ã‚¯ç¬¦å·åŒ–ãƒ¡ã‚½ãƒƒãƒ‰
    # ========================================
    
    def _poisson_encode(self, pixel_values, max_rate=100.0, simulation_time=50.0, dt=1.0):
        """ãƒã‚¢ã‚½ãƒ³ç¬¦å·åŒ–ï¼ˆæ¨å¥¨ï¼‰- GPUæœ€é©åŒ–ç‰ˆ
        
        ç”Ÿç‰©å­¦çš„å¦¥å½“æ€§ãŒæœ€ã‚‚é«˜ã„ã‚¹ãƒ‘ã‚¤ã‚¯ç¬¦å·åŒ–æ‰‹æ³•ã€‚
        ç”»ç´ å€¤ã«æ¯”ä¾‹ã—ãŸç™ºç«ç‡ã§ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚¹ãƒ‘ã‚¤ã‚¯ã‚’ç”Ÿæˆã€‚
        
        ã€Step 4-3 GPUæœ€é©åŒ–ã€‘:
        - ãƒ™ã‚¯ãƒˆãƒ«åŒ–: ãƒ«ãƒ¼ãƒ—ã‚’å®Œå…¨ã«ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼ˆn_timesteps Ã— n_neuronsä¸€æ‹¬ç”Ÿæˆï¼‰
        - ãƒ¡ãƒ¢ãƒªåŠ¹ç‡: ä¸­é–“é…åˆ—ã‚’å‰Šæ¸›
        - GPUä¸¦åˆ—åŒ–: ä¹±æ•°ç”Ÿæˆã¨ã‚¹ãƒ‘ã‚¤ã‚¯åˆ¤å®šã‚’ä¸¦åˆ—å®Ÿè¡Œ
        
        Args:
            pixel_values: ç”»ç´ å€¤é…åˆ— [784] (æ­£è¦åŒ–æ¸ˆã¿ [0,1])
            max_rate: æœ€å¤§ç™ºç«ç‡ (Hz)
            simulation_time: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ™‚é–“ (ms)
            dt: æ™‚é–“åˆ»ã¿ (ms)
        
        Returns:
            spike_trains: ã‚¹ãƒ‘ã‚¤ã‚¯åˆ— [n_timesteps, n_neurons] (bool)
        
        å‚è€ƒæ–‡çŒ®:
            - Diehl & Cook (2015) "Unsupervised learning of digit recognition using spike-timing-dependent plasticity"
            - å±±æœ¬æ‹“éƒ½ã€ŒNumPyã§ä½œã£ã¦è©¦ã™SNNã€p.87, Jittered MNISTå®Ÿè£…
        """
        n_neurons = len(pixel_values)
        n_timesteps = int(simulation_time / dt)
        
        # GPUå¯¾å¿œ - å®Œå…¨ãƒ™ã‚¯ãƒˆãƒ«åŒ–ç‰ˆï¼ˆStep 4-3æœ€é©åŒ–ï¼‰
        if self.use_gpu:
            # ç™ºç«ç‡ã‚’è¨ˆç®— [n_neurons]
            rates = self.xp.asarray(pixel_values) * max_rate
            
            # ç™ºç«ç¢ºç‡ã‚’è¨ˆç®— [n_neurons]
            probs = rates * dt / 1000.0  # Hz â†’ ç¢ºç‡å¤‰æ›
            
            # ä¹±æ•°ç”Ÿæˆ [n_timesteps, n_neurons] - ä¸€æ‹¬ç”Ÿæˆã§é«˜é€ŸåŒ–
            random_vals = self.xp.random.random((n_timesteps, n_neurons))
            
            # ã‚¹ãƒ‘ã‚¤ã‚¯åˆ¤å®š [n_timesteps, n_neurons] - ãƒ™ã‚¯ãƒˆãƒ«åŒ–æ¯”è¼ƒ
            spike_trains = random_vals < probs[self.xp.newaxis, :]
            
        else:
            # CPUç‰ˆ - åŒæ§˜ã«ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            rates = pixel_values * max_rate
            probs = rates * dt / 1000.0
            random_vals = np.random.random((n_timesteps, n_neurons))
            spike_trains = random_vals < probs[np.newaxis, :]
        
        return spike_trains
    
    def _rate_encode(self, pixel_values, max_rate=100.0, simulation_time=50.0, dt=1.0):
        """ãƒ¬ãƒ¼ãƒˆç¬¦å·åŒ–ï¼ˆæ±ºå®šè«–çš„ï¼‰
        
        ç”»ç´ å€¤ã«æ¯”ä¾‹ã—ãŸä¸€å®šç™ºç«ç‡ã§è¦å‰‡çš„ã«ã‚¹ãƒ‘ã‚¤ã‚¯ã‚’ç”Ÿæˆã€‚
        
        Args:
            pixel_values: ç”»ç´ å€¤é…åˆ— [784] (æ­£è¦åŒ–æ¸ˆã¿ [0,1])
            max_rate: æœ€å¤§ç™ºç«ç‡ (Hz)
            simulation_time: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ™‚é–“ (ms)
            dt: æ™‚é–“åˆ»ã¿ (ms)
        
        Returns:
            spike_trains: ã‚¹ãƒ‘ã‚¤ã‚¯åˆ— [n_timesteps, n_neurons] (bool)
        """
        n_neurons = len(pixel_values)
        n_timesteps = int(simulation_time / dt)
        
        # GPUå¯¾å¿œ
        if self.use_gpu:
            spike_trains = self.xp.zeros((n_timesteps, n_neurons), dtype=bool)
            rates = self.xp.asarray(pixel_values) * max_rate
            intervals = self.xp.where(rates > 0, 1000.0 / rates, self.xp.inf)  # ms
            
            for i in range(n_neurons):
                if rates[i] > 0:
                    interval = float(intervals[i])
                    spike_times = self.xp.arange(interval, simulation_time, interval)
                    spike_indices = (spike_times / dt).astype(int)
                    spike_indices = spike_indices[spike_indices < n_timesteps]
                    spike_trains[spike_indices, i] = True
        else:
            spike_trains = np.zeros((n_timesteps, n_neurons), dtype=bool)
            rates = pixel_values * max_rate
            intervals = np.where(rates > 0, 1000.0 / rates, np.inf)
            
            for i in range(n_neurons):
                if rates[i] > 0:
                    interval = intervals[i]
                    spike_times = np.arange(interval, simulation_time, interval)
                    spike_indices = (spike_times / dt).astype(int)
                    spike_indices = spike_indices[spike_indices < n_timesteps]
                    spike_trains[spike_indices, i] = True
        
        return spike_trains
    
    def _temporal_encode(self, pixel_values, simulation_time=50.0, dt=1.0):
        """ãƒ†ãƒ³ãƒãƒ©ãƒ«ç¬¦å·åŒ–ï¼ˆæ™‚é–“ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼‰
        
        ç”»ç´ å€¤ãŒå¤§ãã„ã»ã©æ—©ãç™ºç«ã€‚å„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯1å›ã®ã¿ç™ºç«ã€‚
        
        Args:
            pixel_values: ç”»ç´ å€¤é…åˆ— [784] (æ­£è¦åŒ–æ¸ˆã¿ [0,1])
            simulation_time: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ™‚é–“ (ms)
            dt: æ™‚é–“åˆ»ã¿ (ms)
        
        Returns:
            spike_trains: ã‚¹ãƒ‘ã‚¤ã‚¯åˆ— [n_timesteps, n_neurons] (bool)
        """
        n_neurons = len(pixel_values)
        n_timesteps = int(simulation_time / dt)
        
        # GPUå¯¾å¿œ
        if self.use_gpu:
            spike_trains = self.xp.zeros((n_timesteps, n_neurons), dtype=bool)
            # ç”»ç´ å€¤ãŒå¤§ãã„ã»ã©æ—©ãç™ºç«ï¼ˆé€†æ¯”ä¾‹ï¼‰
            # å€¤ãŒ0ã®å ´åˆã¯ç™ºç«ã—ãªã„
            spike_times_ms = self.xp.where(
                self.xp.asarray(pixel_values) > 0,
                simulation_time * (1.0 - self.xp.asarray(pixel_values)),
                self.xp.inf
            )
            spike_indices = (spike_times_ms / dt).astype(int)
            
            for i in range(n_neurons):
                if spike_indices[i] < n_timesteps:
                    spike_trains[int(spike_indices[i]), i] = True
        else:
            spike_trains = np.zeros((n_timesteps, n_neurons), dtype=bool)
            spike_times_ms = np.where(
                pixel_values > 0,
                simulation_time * (1.0 - pixel_values),
                np.inf
            )
            spike_indices = (spike_times_ms / dt).astype(int)
            
            for i in range(n_neurons):
                if spike_indices[i] < n_timesteps:
                    spike_trains[int(spike_indices[i]), i] = True
        
        return spike_trains
    
    def _spike_encode(self, pixel_values, method='poisson', max_rate=100.0, 
                     simulation_time=50.0, dt=1.0):
        """ã‚¹ãƒ‘ã‚¤ã‚¯ç¬¦å·åŒ–ï¼ˆãƒ¡ã‚½ãƒƒãƒ‰é¸æŠ + E/Iãƒšã‚¢åŒ–ï¼‰- GPUæœ€é©åŒ–ç‰ˆ
        # ============================================================================
        # ã‚¹ãƒ‘ã‚¤ã‚¯ç¬¦å·åŒ–ï¼ˆãƒã‚¢ã‚½ãƒ³ç¬¦å·åŒ–ï¼‰
        # ============================================================================
        # WHY: å®Ÿéš›ã®ç¥çµŒç´°èƒã¯ã‚¢ãƒŠãƒ­ã‚°å€¤ã§ã¯ãªãã‚¹ãƒ‘ã‚¤ã‚¯åˆ—ã§æƒ…å ±ã‚’è¡¨ç¾
        # WHY: ãƒã‚¢ã‚½ãƒ³éç¨‹ã«ã‚ˆã‚Šã€å…¥åŠ›å¼·åº¦ã‚’ç¢ºç‡çš„ãªç™ºç«ç‡ã«å¤‰æ›
        # WHY: ç”Ÿç‰©å­¦çš„å¦¥å½“æ€§ãŒæœ€ã‚‚é«˜ãã€ãƒã‚¤ã‚ºãƒ­ãƒã‚¹ãƒˆæ€§ã‚‚å„ªã‚Œã¦ã„ã‚‹
        
        ç”»ç´ å€¤ã‚’ã‚¹ãƒ‘ã‚¤ã‚¯åˆ—ã«å¤‰æ›ã—ã€E/Iãƒšã‚¢æ§‹é€ ã‚’é©ç”¨ã€‚
        
        ã€Step 4-3 GPUæœ€é©åŒ–ã€‘:
        - E/Iãƒšã‚¢åŒ–ã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–: ãƒ«ãƒ¼ãƒ—ã‚’å®Œå…¨å‰Šé™¤
        - repeat()ã¨reshape()ã«ã‚ˆã‚‹é«˜é€Ÿãƒšã‚¢åŒ–
        - ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–: ä¸­é–“é…åˆ—ã‚’å‰Šæ¸›
        
        Args:
            pixel_values: ç”»ç´ å€¤é…åˆ— [784] (æ­£è¦åŒ–æ¸ˆã¿ [0,1])
            method: ç¬¦å·åŒ–æ–¹æ³• ('poisson', 'rate', 'temporal')
            max_rate: æœ€å¤§ç™ºç«ç‡ (Hz) - poisson/rateã®ã¿
            simulation_time: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ™‚é–“ (ms)
            dt: æ™‚é–“åˆ»ã¿ (ms)
        
        Returns:
            spike_trains_paired: E/Iãƒšã‚¢åŒ–ã•ã‚ŒãŸã‚¹ãƒ‘ã‚¤ã‚¯åˆ— [n_timesteps, 1568] (bool)
        """
        # Step 1: ç”»ç´ å€¤ [784] â†’ ã‚¹ãƒ‘ã‚¤ã‚¯åˆ— [n_timesteps, 784]
        if method == 'poisson':
            spike_trains_raw = self._poisson_encode(pixel_values, max_rate, simulation_time, dt)
        elif method == 'rate':
            spike_trains_raw = self._rate_encode(pixel_values, max_rate, simulation_time, dt)
        elif method == 'temporal':
            spike_trains_raw = self._temporal_encode(pixel_values, simulation_time, dt)
        else:
            raise ValueError(f"Unknown encoding method: {method}")
        
        # Step 2: E/Iãƒšã‚¢åŒ– [n_timesteps, 784] â†’ [n_timesteps, 1568]
        # GPUæœ€é©åŒ–ç‰ˆï¼ˆStep 4-4ï¼‰: stack()ã«ã‚ˆã‚‹é«˜é€Ÿãƒšã‚¢åŒ–ï¼ˆ1.27å€é«˜é€Ÿï¼‰
        n_timesteps, n_pixels = spike_trains_raw.shape
        
        if self.use_gpu:
            # stack()ã«ã‚ˆã‚‹é«˜é€Ÿãƒšã‚¢åŒ–
            # [n_timesteps, 784] â†’ [n_timesteps, 784, 2] â†’ [n_timesteps, 1568]
            spike_trains_paired = self.xp.stack([spike_trains_raw, spike_trains_raw], axis=2)
            spike_trains_paired = spike_trains_paired.reshape(n_timesteps, n_pixels * 2)
        else:
            # CPUç‰ˆã‚‚åŒæ§˜ã«stack()ã‚’ä½¿ç”¨
            spike_trains_paired = np.stack([spike_trains_raw, spike_trains_raw], axis=2)
            spike_trains_paired = spike_trains_paired.reshape(n_timesteps, n_pixels * 2)
        
        return spike_trains_paired

    
    # ========================================
    # Step 1: LIFæ´»æ€§åŒ–ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆéš ã‚Œå±¤ãƒ»å‡ºåŠ›å±¤ç”¨ï¼‰
    # ========================================
    
    def _lif_activation(self, inputs, layer_size, neuron_types, 
                       simulation_time=50.0, dt=1.0):
        """LIFæ´»æ€§åŒ–é–¢æ•°ï¼ˆã‚·ã‚°ãƒ¢ã‚¤ãƒ‰ã®ä»£æ›¿ã€Step 1ï¼‰
        # ============================================================================
        # LIF (Leaky Integrate-and-Fire) ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³
        # ============================================================================
        # WHY: å®Ÿéš›ã®ç¥çµŒç´°èƒã®è†œé›»ä½ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã‚’æ¨¡å€£
        # WHY: è†œé›»ä½ã®æ™‚é–“çš„çµ±åˆã«ã‚ˆã‚Šã€ã‚¹ãƒ‘ã‚¤ã‚¯ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’è€ƒæ…®ã—ãŸè¨ˆç®—ãŒå¯èƒ½
        # WHY: ç™ºç«é–¾å€¤ã‚’è¶…ãˆãŸæ™‚ã®ã¿ã‚¹ãƒ‘ã‚¤ã‚¯ã‚’ç™ºç”Ÿã•ã›ã‚‹é›¢æ•£çš„ãªæƒ…å ±å‡¦ç†
        
        éš ã‚Œå±¤ãƒ»å‡ºåŠ›å±¤ã§ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰ã®ä»£ã‚ã‚Šã«ä½¿ç”¨ã™ã‚‹LIFæ´»æ€§åŒ–é–¢æ•°ã€‚
        é€£ç¶šå€¤å…¥åŠ›ã‚’é›»æµã«å¤‰æ›ã—ã€LIFã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã€‚
        
        Args:
            inputs: é€£ç¶šå€¤å…¥åŠ› [layer_size] (ä»»æ„ã®ç¯„å›²)
            layer_size: å±¤ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ•°
            neuron_types: ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚¿ã‚¤ãƒ—é…åˆ— [layer_size] (+1: èˆˆå¥®æ€§, -1: æŠ‘åˆ¶æ€§)
            simulation_time: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ™‚é–“ (ms)
            dt: æ™‚é–“åˆ»ã¿ (ms)
        
        Returns:
            firing_rates: ç™ºç«ç‡ [layer_size] (0-1ã®ç¯„å›²ã«æ­£è¦åŒ–)
        """
        from modules.snn.lif_neuron import LIFNeuronLayer
        
        # GPUé…åˆ—ã‚’NumPyã«å¤‰æ›
        if self.use_gpu and hasattr(inputs, 'get'):
            inputs_cpu = inputs.get()
        else:
            inputs_cpu = np.asarray(inputs)
        
        # ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚¿ã‚¤ãƒ—é…åˆ—ã‚’å¤‰æ› (+1 â†’ 'excitatory', -1 â†’ 'inhibitory')
        neuron_type_names = ['excitatory' if t == 1 else 'inhibitory' for t in neuron_types]
        
        # LIFå±¤åˆæœŸåŒ–
        neuron_params = {
            'v_rest': -65.0,
            'v_threshold': -40.0,
            'v_reset': -70.0,
            'tau_m': 12.0,
            'tau_ref': 1.0,
            'dt': dt,
            'r_m': 35.0
        }
        
        lif_layer = LIFNeuronLayer(
            n_neurons=layer_size,
            neuron_params=neuron_params,
            neuron_types=neuron_type_names
        )
        
        # é€£ç¶šå€¤å…¥åŠ›ã‚’é›»æµã«å¤‰æ›
        # å…¥åŠ›ç¯„å›²ã‚’é©åˆ‡ã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆã‚·ã‚°ãƒ¢ã‚¤ãƒ‰å‡ºåŠ›[0,1]ã‚’æƒ³å®šï¼‰
        # é›»æµç¯„å›²: 0-20 pAï¼ˆLIFãŒé©åˆ‡ã«ç™ºç«ã™ã‚‹ç¯„å›²ï¼‰
        input_currents = inputs_cpu * 20.0
        
        # LIFã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        n_timesteps = int(simulation_time / dt)
        spike_counts = np.zeros(layer_size)
        
        for t in range(n_timesteps):
            # å„æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—ã§åŒã˜é›»æµã‚’æ³¨å…¥ï¼ˆå®šå¸¸å…¥åŠ›ï¼‰
            spikes = lif_layer.update(input_currents)
            spike_counts += spikes
        
        # ç™ºç«ç‡è¨ˆç®—ï¼ˆã‚¹ãƒ‘ã‚¤ã‚¯æ•° / æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—æ•°ï¼‰
        firing_rates = spike_counts / n_timesteps
        
        # [0, 1]ç¯„å›²ã«æ­£è¦åŒ–
        firing_rates = np.clip(firing_rates, 0.0, 1.0)
        
        # GPUé…åˆ—ã«å¤‰æ›ï¼ˆå¾Œç¶šå‡¦ç†ç”¨ï¼‰
        if self.use_gpu:
            firing_rates = self.xp.asarray(firing_rates)
        
        return firing_rates
    
    # ========================================
    # Step 3a: LIFæ´»æ€§åŒ–ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆå…¥åŠ›å±¤å°‚ç”¨ï¼‰
    # ========================================
    
    def _lif_activation_input_layer(self, spike_trains, neuron_types, 
                                    simulation_time=50.0, dt=1.0):
        """å…¥åŠ›å±¤LIFæ´»æ€§åŒ–é–¢æ•°ï¼ˆã‚¹ãƒ‘ã‚¤ã‚¯åˆ— â†’ ç™ºç«ç‡ï¼‰
        
        å…¥åŠ›å±¤å°‚ç”¨ã®LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€‚
        ã‚¹ãƒ‘ã‚¤ã‚¯åˆ—ã‚’å…¥åŠ›ã—ã€LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®ç™ºç«ç‡ã‚’å‡ºåŠ›ã€‚
        
        Args:
            spike_trains: ã‚¹ãƒ‘ã‚¤ã‚¯åˆ— [n_timesteps, n_neurons] (bool)
            neuron_types: ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚¿ã‚¤ãƒ—é…åˆ— [n_neurons] (+1: èˆˆå¥®æ€§, -1: æŠ‘åˆ¶æ€§)
            simulation_time: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ™‚é–“ (ms)
            dt: æ™‚é–“åˆ»ã¿ (ms)
        
        Returns:
            firing_rates: ç™ºç«ç‡ [n_neurons] (0-1ã®ç¯„å›²ã«æ­£è¦åŒ–)
        """
        n_timesteps, n_neurons = spike_trains.shape
        
        # modules/snn/lif_neuron.pyã®LIFNeuronLayerã‚’ä½¿ç”¨
        from modules.snn.lif_neuron import LIFNeuronLayer
        
        # ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚¿ã‚¤ãƒ—é…åˆ—ã‚’å¤‰æ› (+1 â†’ 'excitatory', -1 â†’ 'inhibitory')
        neuron_type_names = ['excitatory' if t == 1 else 'inhibitory' for t in neuron_types]
        
        # å…¥åŠ›å±¤LIFåˆæœŸåŒ–ï¼ˆE/Iãƒšã‚¢æ§‹é€ ï¼‰
        # v_rest=-65.0, v_threshold=-40.0, tau_m=12.0, tau_ref=1.0ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        neuron_params = {
            'v_rest': -65.0,
            'v_threshold': -40.0,
            'v_reset': -70.0,
            'tau_m': 12.0,
            'tau_ref': 1.0,
            'dt': dt,
            'r_m': 35.0
        }
        
        input_lif_layer = LIFNeuronLayer(
            n_neurons=n_neurons,
            neuron_params=neuron_params,
            neuron_types=neuron_type_names
        )
        
        # LIFã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        spike_counts = np.zeros(n_neurons)
        
        for t in range(n_timesteps):
            # ã‚¹ãƒ‘ã‚¤ã‚¯ â†’ é›»æµå¤‰æ›ï¼ˆã‚¹ãƒ‘ã‚¤ã‚¯ãŒã‚ã‚Œã°10.0 pAã®é›»æµã‚’æ³¨å…¥ï¼‰
            # GPUé…åˆ—ã‚’NumPyã«å¤‰æ›
            if self.use_gpu:
                current_spikes = self.xp.asnumpy(spike_trains[t]) if hasattr(spike_trains[t], 'get') else np.array(spike_trains[t])
            else:
                current_spikes = spike_trains[t].astype(float)
            
            input_currents = current_spikes * 10.0  # pA
            
            # LIFæ›´æ–°
            output_spikes = input_lif_layer.update(input_currents)
            spike_counts += output_spikes
        
        # ç™ºç«ç‡è¨ˆç®—ï¼ˆã‚¹ãƒ‘ã‚¤ã‚¯æ•° / æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—æ•°ï¼‰
        firing_rates = spike_counts / n_timesteps
        
        # [0, 1]ç¯„å›²ã«æ­£è¦åŒ–ï¼ˆæœ€å¤§ç™ºç«ç‡ã§å‰²ã‚‹ï¼‰
        # LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®æœ€å¤§ç™ºç«ç‡ã¯ç´„100Hzï¼ˆä¸å¿œæœŸ1ms â†’ 1000Hzç†è«–å€¤ã€å®Ÿéš›ã¯100Hzç¨‹åº¦ï¼‰
        max_possible_rate = 1.0  # æ—¢ã«æ­£è¦åŒ–æ¸ˆã¿ï¼ˆå…¨æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—ã§ç™ºç«ã—ãŸå ´åˆ=1.0ï¼‰
        firing_rates = np.clip(firing_rates, 0.0, max_possible_rate)
        
        # GPUé…åˆ—ã«å¤‰æ›ï¼ˆå¾Œç¶šå‡¦ç†ç”¨ï¼‰
        if self.use_gpu:
            firing_rates = self.xp.asarray(firing_rates)
        
        return firing_rates
    
    def forward_pass(self, inputs):
        """çœŸã®å¤šå±¤é †ä¼æ’­å‡¦ç†ï¼ˆv025 Step 3a: å…¥åŠ›å±¤LIFçµ±åˆå¯¾å¿œï¼‰"""
        # Phase 12ä¿®æ­£: input_unitsã‚’ä½¿ç”¨ï¼ˆLIFä½¿ç”¨æ™‚ã¯1568ã€ä¸ä½¿ç”¨æ™‚ã¯784ï¼‰
        if len(inputs) != self.input_units:
            adjusted = np.zeros(self.input_units)
            min_len = min(len(inputs), self.input_units)
            adjusted[:min_len] = inputs[:min_len]
            inputs = adjusted
        
        outputs = np.zeros(self.output_units)
        
        # ========================================
        # v025 Step 3a: å…¥åŠ›å±¤LIFçµ±åˆ
        # ========================================
        if self.hp is not None and self.hp.use_input_lif:
            # Step 3a: ç”Ÿç‰©å­¦çš„å¦¥å½“æ€§ã®é«˜ã„å…¥åŠ›å±¤LIFå‡¦ç†
            # ç”»ç´ å€¤ [784] â†’ ã‚¹ãƒ‘ã‚¤ã‚¯åˆ— [n_timesteps, 784] â†’ E/Iãƒšã‚¢ [n_timesteps, 1568] 
            #   â†’ å…¥åŠ›å±¤LIF â†’ ç™ºç«ç‡ [1568] â†’ éš ã‚Œå±¤ä¼æ’­
            
            # Step 1: ç”»ç´ å€¤ [1568] ã‹ã‚‰å…ƒã®ç”»ç´ å€¤ [784] ã‚’æŠ½å‡º
            # inputs ã¯ E/Iãƒšã‚¢åŒ–æ¸ˆã¿ [1568]ã€å¶æ•°ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒå…ƒã®ç”»ç´ å€¤
            original_pixels = inputs[0::2]  # [784]
            
            # Step 2: ã‚¹ãƒ‘ã‚¤ã‚¯ç¬¦å·åŒ–ï¼ˆE/Iãƒšã‚¢åŒ–ã‚’å«ã‚€ï¼‰
            # [784] â†’ [n_timesteps, 1568]
            spike_trains = self._spike_encode(
                pixel_values=original_pixels,
                method=self.hp.spike_encoding_method,
                max_rate=self.hp.spike_max_rate,
                simulation_time=self.hp.spike_simulation_time,
                dt=self.hp.spike_dt
            )
            
            # Step 3: å…¥åŠ›å±¤LIFæ´»æ€§åŒ–
            # ã‚¹ãƒ‘ã‚¤ã‚¯åˆ— [n_timesteps, 1568] â†’ ç™ºç«ç‡ [1568]
            input_activity = self._lif_activation_input_layer(
                spike_trains=spike_trains,
                neuron_types=self.input_neuron_types,
                simulation_time=self.hp.spike_simulation_time,
                dt=self.hp.spike_dt
            )
            
            # Step 4: ç™ºç«ç‡ã‚’éš ã‚Œå±¤ã«ä¼æ’­ï¼ˆå¾“æ¥ã®ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰å‡¦ç†ï¼‰
            # GPUå¯¾å¿œ: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’GPUã«è»¢é€ï¼ˆ1å›ã®ã¿ï¼‰
            if self.use_gpu:
                inputs_gpu = input_activity  # æ—¢ã«GPUé…åˆ—
            else:
                inputs_gpu = input_activity
            
            for n in range(self.output_units):
                for t in range(self.time_loops):
                    layer_outputs = []
                    current_layer_output = inputs_gpu.copy() if self.use_gpu else input_activity.copy()
                    
                    for layer_idx, layer_weight in enumerate(self.layer_weights[n]):
                        # GPUæœ€é©åŒ–: é‡ã¿è¡Œåˆ—ã¯æ—¢ã«GPUä¸Šã«ã‚ã‚‹ã®ã§è»¢é€ä¸è¦
                        linear_out = layer_weight @ current_layer_output
                        activated = self._sigmoid_vectorized(linear_out)
                        
                        # GPUâ†’CPUã«æˆ»ã™ï¼ˆlayer_outputsã¯NumPyé…åˆ—ã¨ã—ã¦ä¿å­˜ï¼‰
                        if self.use_gpu:
                            layer_outputs.append(np.array(activated) if not hasattr(activated, 'get') else activated.get())
                        else:
                            layer_outputs.append(activated)
                        
                        current_layer_output = activated
                    
                    if t == self.time_loops - 1:
                        self.layer_outputs[n] = layer_outputs
                
                outputs[n] = self.layer_outputs[n][-1][0]
            
            return outputs
        
        # v019 Phase 12: LIFå±¤ä½¿ç”¨æ™‚ã®æ¡ä»¶åˆ†å²ï¼ˆhp.enable_lifã®ã¿ã§åˆ¤å®šï¼‰
        # v025 Step 2a/2b: éš ã‚Œå±¤ãƒ»å‡ºåŠ›å±¤LIFåŒ–
        elif self.hp is not None and self.hp.enable_lif:
            # ========================================
            # Step 2a/2b: éš ã‚Œå±¤ãƒ»å‡ºåŠ›å±¤LIFåŒ–å‡¦ç†
            # ========================================
            
            # å…¥åŠ›å±¤ã¯å¾“æ¥é€šã‚Šï¼ˆE/Iãƒšã‚¢åŒ–æ¸ˆã¿ç”»ç´ å€¤ [1568]ï¼‰
            # éš ã‚Œå±¤ãƒ»å‡ºåŠ›å±¤ã§LIFæ´»æ€§åŒ–é–¢æ•°ã‚’ä½¿ç”¨ï¼ˆã‚·ã‚°ãƒ¢ã‚¤ãƒ‰ã®ä»£æ›¿ï¼‰
            
            # GPUå¯¾å¿œ: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’GPUã«è»¢é€ï¼ˆ1å›ã®ã¿ï¼‰
            if self.use_gpu:
                inputs_gpu = self.xp.asarray(inputs)
            else:
                inputs_gpu = inputs
            
            for n in range(self.output_units):
                for t in range(self.time_loops):
                    layer_outputs = []
                    current_layer_output = inputs_gpu.copy() if self.use_gpu else inputs.copy()
                    
                    for layer_idx, layer_weight in enumerate(self.layer_weights[n]):
                        # é‡ã¿è¡Œåˆ—ç©
                        linear_out = layer_weight @ current_layer_output
                        
                        # â˜…Step 2a/2b: LIFæ´»æ€§åŒ–é–¢æ•°ã‚’ä½¿ç”¨ï¼ˆã‚·ã‚°ãƒ¢ã‚¤ãƒ‰ã®ä»£æ›¿ï¼‰
                        # éš ã‚Œå±¤ãƒ»å‡ºåŠ›å±¤ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚¿ã‚¤ãƒ—ã‚’å–å¾—
                        if layer_idx < len(self.hidden_neuron_types):
                            # éš ã‚Œå±¤
                            neuron_types = self.hidden_neuron_types[layer_idx]
                            layer_size = self.hidden_sizes[layer_idx]
                        else:
                            # å‡ºåŠ›å±¤
                            neuron_types = np.array([self.output_neuron_types[n]])
                            layer_size = 1
                        
                        # LIFæ´»æ€§åŒ–ï¼ˆStep 1ãƒ¡ã‚½ãƒƒãƒ‰ä½¿ç”¨ï¼‰
                        activated = self._lif_activation(
                            inputs=linear_out,
                            layer_size=layer_size,
                            neuron_types=neuron_types,
                            simulation_time=self.hp.simulation_time,
                            dt=self.hp.dt
                        )
                        
                        # GPUâ†’CPUã«æˆ»ã™ï¼ˆlayer_outputsã¯NumPyé…åˆ—ã¨ã—ã¦ä¿å­˜ï¼‰
                        if self.use_gpu:
                            layer_outputs.append(np.array(activated) if not hasattr(activated, 'get') else activated.get())
                        else:
                            layer_outputs.append(activated)
                        
                        current_layer_output = activated
                    
                    if t == self.time_loops - 1:
                        self.layer_outputs[n] = layer_outputs
                
                outputs[n] = self.layer_outputs[n][-1][0]
            
            return outputs
        
        else:
            # ========================================
            # å¾“æ¥ã®ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰ãƒ™ãƒ¼ã‚¹é †ä¼æ’­å‡¦ç†ï¼ˆPhase 13ä¿®æ­£ + GPUæœ€é©åŒ–ï¼‰
            # ========================================
            
            # GPUå¯¾å¿œ: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’GPUã«è»¢é€ï¼ˆ1å›ã®ã¿ï¼‰
            if self.use_gpu:
                inputs_gpu = self.xp.asarray(inputs)
            else:
                inputs_gpu = inputs
            
            for n in range(self.output_units):
                for t in range(self.time_loops):
                    layer_outputs = []
                    
                    # Phase 13ä¿®æ­£: input_unitsãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã®ã§ã€
                    # inputs[0::2]ã«ã‚ˆã‚‹æŠ½å‡ºã¯ä¸è¦ã€‚inputsã‚’ãã®ã¾ã¾ä½¿ç”¨ã€‚
                    current_layer_output = inputs_gpu.copy() if self.use_gpu else inputs.copy()
                    
                    for layer_idx, layer_weight in enumerate(self.layer_weights[n]):
                        # GPUæœ€é©åŒ–: é‡ã¿è¡Œåˆ—ã¯æ—¢ã«GPUä¸Šã«ã‚ã‚‹ã®ã§è»¢é€ä¸è¦
                        linear_out = layer_weight @ current_layer_output
                        activated = self._sigmoid_vectorized(linear_out)
                        
                        # GPUâ†’CPUã«æˆ»ã™ï¼ˆlayer_outputsã¯NumPyé…åˆ—ã¨ã—ã¦ä¿å­˜ï¼‰
                        if self.use_gpu:
                            layer_outputs.append(self.xp.asnumpy(activated))
                        else:
                            layer_outputs.append(activated)
                        
                        current_layer_output = activated
                    
                    if t == self.time_loops - 1:
                        self.layer_outputs[n] = layer_outputs
                
                outputs[n] = self.layer_outputs[n][-1][0]
        
        return outputs
    
    def pure_ed_learning_step(self, inputs, targets, outputs):
        """çœŸã®å¤šå±¤EDå­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆPhase 13ä¿®æ­£ï¼‰
        
        Phase 13ä¿®æ­£:
        - input_unitsãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã®ã§ã€inputs[0::2]ã«ã‚ˆã‚‹æŠ½å‡ºã¯ä¸è¦
        - inputsã‚’ãã®ã¾ã¾ä½¿ç”¨
        
        v019 Phase 11ä¿®æ­£ï¼ˆPhase 13ã§æ”¹å–„ï¼‰:
        - LIFä½¿ç”¨æ™‚: inputs ã¯1568å€‹ï¼ˆE/Iãƒšã‚¢æ§‹é€ ï¼‰ã®ã¾ã¾ä½¿ç”¨
        - LIFä¸ä½¿ç”¨æ™‚: inputs ã¯784å€‹ï¼ˆinput_unitsã‚µã‚¤ã‚ºï¼‰ã®ã¾ã¾ä½¿ç”¨
        """
        # Phase 13ä¿®æ­£: æ¡ä»¶åˆ†å²ã‚’å‰Šé™¤ã—ã€inputsã‚’ãã®ã¾ã¾ä½¿ç”¨
        input_for_learning = inputs.copy()
        
        self.error = 0.0
        
        for n in range(self.output_units):
            error = targets[n] - outputs[n]
            self.error += abs(error)
            
            if abs(error) > 0.5:
                self.error_count += 1
            
            # å‡ºåŠ›å±¤ã‚¢ãƒŸãƒ³æ¿ƒåº¦è¨­å®š
            if error > 0:
                self.layer_amine_concentrations[n][-1][0, 0] = error
                self.layer_amine_concentrations[n][-1][0, 1] = 0
            else:
                self.layer_amine_concentrations[n][-1][0, 0] = 0
                self.layer_amine_concentrations[n][-1][0, 1] = -error
            
            # ============================================================================
            # EDæ³•ã®æ ¸å¿ƒ: ã‚¢ãƒŸãƒ³æ‹¡æ•£ãƒ¡ã‚«ãƒ‹ã‚ºãƒ 
            # ============================================================================
            # WHY: ç”Ÿç‰©å­¦çš„ãªç¥çµŒä¼é”ç‰©è³ªï¼ˆãƒ‰ãƒ¼ãƒ‘ãƒŸãƒ³ã€ã‚»ãƒ­ãƒˆãƒ‹ãƒ³ï¼‰ã®æ‹¡æ•£ã‚’æ¨¡å€£
            # WHY: èª¤å·®é€†ä¼æ’­æ³•ã®ã€Œå¾®åˆ†ã®é€£é–å¾‹ã€ã‚’ä½¿ã‚ãšã«å­¦ç¿’ã‚’å®Ÿç¾
            # WHY: å‡ºåŠ›å±¤ã®èª¤å·®ã‚’ã€Œã‚¢ãƒŸãƒ³æ¿ƒåº¦ã€ã¨ã—ã¦éš ã‚Œå±¤ã«æ‹¡æ•£ã•ã›ã‚‹ã“ã¨ã§å­¦ç¿’ä¿¡å·ã‚’ä¼ãˆã‚‹

            # ============================================================================
            # EDæ³•ã®æ ¸å¿ƒ: ã‚¢ãƒŸãƒ³æ‹¡æ•£ãƒ¡ã‚«ãƒ‹ã‚ºãƒ 
            # ============================================================================
            # WHY: ç”Ÿç‰©å­¦çš„ãªç¥çµŒä¼é”ç‰©è³ªï¼ˆãƒ‰ãƒ¼ãƒ‘ãƒŸãƒ³ã€ã‚»ãƒ­ãƒˆãƒ‹ãƒ³ï¼‰ã®æ‹¡æ•£ã‚’æ¨¡å€£
            # WHY: èª¤å·®é€†ä¼æ’­æ³•ã®ã€Œå¾®åˆ†ã®é€£é–å¾‹ã€ã‚’ä½¿ã‚ãšã«å­¦ç¿’ã‚’å®Ÿç¾
            # WHY: å‡ºåŠ›å±¤ã®èª¤å·®ã‚’ã€Œã‚¢ãƒŸãƒ³æ¿ƒåº¦ã€ã¨ã—ã¦éš ã‚Œå±¤ã«æ‹¡æ•£ã•ã›ã‚‹ã“ã¨ã§å­¦ç¿’ä¿¡å·ã‚’ä¼ãˆã‚‹
            # éš ã‚Œå±¤ã¸ã®ã‚¢ãƒŸãƒ³æ‹¡æ•£
            for layer_idx in range(len(self.hidden_sizes) - 1, -1, -1):
                if layer_idx == len(self.hidden_sizes) - 1:
                    pos_amine = self.layer_amine_concentrations[n][-1][0, 0]
                    neg_amine = self.layer_amine_concentrations[n][-1][0, 1]
                else:
                    pos_amine = np.mean(self.layer_amine_concentrations[n][layer_idx + 1][:, 0])
                    neg_amine = np.mean(self.layer_amine_concentrations[n][layer_idx + 1][:, 1])
                
                self.layer_amine_concentrations[n][layer_idx][:, 0] = pos_amine * self.diffusion_rate
                self.layer_amine_concentrations[n][layer_idx][:, 1] = neg_amine * self.diffusion_rate
        
        # é‡ã¿æ›´æ–°
        self._neuro_weight_calc_multilayer(input_for_learning)
    
    def _neuro_weight_calc_multilayer(self, input_data):
        """çœŸã®å¤šå±¤é‡ã¿æ›´æ–°ï¼ˆGPUæœ€é©åŒ–ç‰ˆï¼‰
        
        Args:
            input_data: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
                - LIFä½¿ç”¨æ™‚: 1568å€‹ï¼ˆE/Iãƒšã‚¢æ§‹é€ ï¼‰
                - LIFä¸ä½¿ç”¨æ™‚: 784å€‹ï¼ˆèˆˆå¥®æ€§ã®ã¿ï¼‰
        
        GPUæœ€é©åŒ–æˆ¦ç•¥:
            - é‡ã¿è¡Œåˆ—ã¯GPUä¸Šã«å¸¸é§
            - è»¢é€å›æ•°ã‚’æœ€å°åŒ–
            - GPUä¸Šã§å…¨è¨ˆç®—ã‚’å®Œçµ
        """
        # GPUå¯¾å¿œ: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’GPUã«è»¢é€ï¼ˆ1å›ã®ã¿ï¼‰
        if self.use_gpu:
            input_data_gpu = self.xp.asarray(input_data)
            input_neuron_types_gpu = self.xp.asarray(self.input_neuron_types)
        else:
            input_data_gpu = input_data
            input_neuron_types_gpu = self.input_neuron_types
        
        for n in range(self.output_units):
            for layer_idx in range(len(self.layer_weights[n])):
                if layer_idx == 0:
                    src_output = input_data_gpu
                    src_types = input_neuron_types_gpu
                else:
                    # layer_outputsã¯CPUé…åˆ—ãªã®ã§ã€GPUä½¿ç”¨æ™‚ã¯è»¢é€
                    src_output_cpu = self.layer_outputs[n][layer_idx - 1]
                    src_output = self.xp.asarray(src_output_cpu) if self.use_gpu else src_output_cpu
                    
                    hidden_types = self.hidden_neuron_types[layer_idx - 1]
                    src_types = self.xp.asarray(hidden_types) if self.use_gpu else hidden_types
                
                # layer_outputsã¯CPUé…åˆ—ãªã®ã§ã€GPUä½¿ç”¨æ™‚ã¯è»¢é€
                dst_output_cpu = self.layer_outputs[n][layer_idx]
                dst_output = self.xp.asarray(dst_output_cpu) if self.use_gpu else dst_output_cpu
                
                # ã‚¢ãƒŸãƒ³æ¿ƒåº¦ã‚‚GPUã«è»¢é€
                amine_data_cpu = self.layer_amine_concentrations[n][layer_idx]
                if self.use_gpu:
                    amine_data = self.xp.asarray(amine_data_cpu)
                    amine_pos = amine_data[:, 0]
                    amine_neg = amine_data[:, 1]
                else:
                    amine_pos = amine_data_cpu[:, 0]
                    amine_neg = amine_data_cpu[:, 1]
                
                dst_size = self.layer_weights[n][layer_idx].shape[0]
                src_size = self.layer_weights[n][layer_idx].shape[1]
                
                src_out_reshaped = src_output.reshape(1, -1)
                dst_out_reshaped = dst_output.reshape(-1, 1)
                
                delta = self.learning_rate * src_out_reshaped
                delta = delta * self.xp.abs(dst_out_reshaped)
                delta = delta * (1 - self.xp.abs(dst_out_reshaped))
                
                excitatory_mask = (src_types > 0).reshape(1, -1)
                amine_pos_reshaped = amine_pos.reshape(-1, 1)
                
                if layer_idx == len(self.layer_weights[n]) - 1:
                    dst_types = self.xp.ones(dst_size)
                else:
                    hidden_types = self.hidden_neuron_types[layer_idx]
                    dst_types = self.xp.asarray(hidden_types) if self.use_gpu else hidden_types
                
                src_types_reshaped = src_types.reshape(1, -1)
                dst_types_reshaped = dst_types.reshape(-1, 1)
                
                # èˆˆå¥®æ€§ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‹ã‚‰ã®é‡ã¿æ›´æ–°ï¼ˆGPUä¸Šã§å®Œçµï¼‰
                weight_update_exc = delta * amine_pos_reshaped * dst_types_reshaped * src_types_reshaped
                weight_update_exc *= excitatory_mask
                
                # æŠ‘åˆ¶æ€§ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‹ã‚‰ã®é‡ã¿æ›´æ–°ï¼ˆGPUä¸Šã§å®Œçµï¼‰
                inhibitory_mask = (src_types < 0).reshape(1, -1)
                amine_neg_reshaped = amine_neg.reshape(-1, 1)
                
                weight_update_inh = delta * amine_neg_reshaped * dst_types_reshaped * src_types_reshaped
                weight_update_inh *= inhibitory_mask
                
                # é‡ã¿æ›´æ–°ï¼ˆGPUä¸Šã§ç›´æ¥æ›´æ–°ã€è»¢é€ãªã—ï¼‰
                weight_update_total = weight_update_exc + weight_update_inh
                self.layer_weights[n][layer_idx] += weight_update_total

def load_dataset(dataset_name, train_samples=None, test_samples=None):
    """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿ï¼ˆed_multi_snn.prompt.mdæº–æ‹ ãƒ»æ”¹è‰¯ç‰ˆï¼‰
    
    æ”¹è‰¯ç‰ˆã®å‹•ä½œ:
    - train_samples > 0: æŒ‡å®šã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’ä½¿ç”¨ï¼ˆå®Ÿé¨“ãƒ»ãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
      ãŸã ã—ã€å…¨ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãŠãã€ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«ç•°ãªã‚‹ã‚µãƒ³ãƒ—ãƒ«ã‚’æŠ½å‡ºï¼ˆéå­¦ç¿’é˜²æ­¢ï¼‰
    - train_samples = 0 or None: å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼ˆæœ¬æ ¼çš„ãªå­¦ç¿’ç”¨ï¼‰
    
    éå­¦ç¿’é˜²æ­¢ã®ä»•çµ„ã¿:
    - å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒã—ã€è¨“ç·´ãƒ«ãƒ¼ãƒ—å†…ã§ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    - ã“ã‚Œã«ã‚ˆã‚Šã€å°‘æ•°ã‚µãƒ³ãƒ—ãƒ«æŒ‡å®šæ™‚ã‚‚ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’
    
    Args:
        dataset_name: 'mnist', 'fashion_mnist'
        train_samples: è¨“ç·´ã‚µãƒ³ãƒ—ãƒ«æ•°ï¼ˆ0ã¾ãŸã¯Noneã§å…¨ãƒ‡ãƒ¼ã‚¿ï¼‰
        test_samples: ãƒ†ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«æ•°ï¼ˆ0ã¾ãŸã¯Noneã§å…¨ãƒ‡ãƒ¼ã‚¿ï¼‰
    
    Returns:
        (train_images, train_labels), (test_images, test_labels): å…¨ãƒ‡ãƒ¼ã‚¿
        - MNIST/Fashion-MNIST: (N, 28, 28), ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«, uint8
        â€»ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¯è¨“ç·´ãƒ«ãƒ¼ãƒ—å†…ã§å®Ÿæ–½
    """
    if dataset_name == 'fashion_mnist':
        (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()
    else:  # 'mnist'
        (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()
    
    # ed_multi_snn.prompt.mdæº–æ‹ : ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã‚’è¿”ã™
    # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¯ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«è¨“ç·´ãƒ«ãƒ¼ãƒ—å†…ã§å®Ÿæ–½ï¼ˆéå­¦ç¿’é˜²æ­¢ï¼‰
    return (train_images, train_labels), (test_images, test_labels)

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆæœ€åˆã«å®Ÿè¡Œï¼‰
    setup_japanese_font()
    
    # HyperParamsã«ã‚ˆã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç®¡ç†ï¼ˆed_v032_simple.pyæº–æ‹ ï¼‰
    hp = HyperParams()
    hp.parse_args()
    
    # ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰è¨­å®šï¼ˆed_multi_snn.prompt.mdæº–æ‹ ï¼‰
    # ã‚¨ãƒãƒƒã‚¯ã”ã¨ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã«ã‚‚é©ç”¨ã•ã‚Œã‚‹ã‚ˆã†ã€ã“ã“ã§è¨­å®š
    if hp.random_seed is not None:
        np.random.seed(hp.random_seed)
        print(f"ğŸ² ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰è¨­å®š: {hp.random_seed}")
    
    # éš ã‚Œå±¤è§£æï¼ˆHyperParamsã§æ—¢ã«è§£ææ¸ˆã¿ï¼‰
    hidden_sizes = hp.hidden_layers
    hidden_str = f"{','.join(map(str, hidden_sizes))} ({'å¤šå±¤' if len(hidden_sizes) > 1 else 'å˜å±¤'})"
    
    # ãƒ‡ãƒ¼ã‚¿ã‚·ãƒ£ãƒƒãƒ•ãƒ«è¡¨ç¤ºç”¨
    shuffle_str = "OFF" if hp.no_shuffle else "ON"
    
    # å›³è¡¨ä¿å­˜è¡¨ç¤ºç”¨
    if hp.save_fig:
        save_fig_str = f"ON -> {hp.save_fig}"
    else:
        save_fig_str = "OFF"
    
    # ============================================================
    # EDæ³•å®Ÿè¡Œè¨­å®šè¡¨ç¤ºï¼ˆed_v032_simple.pyæº–æ‹ ï¼‰
    # ============================================================
    print("=" * 60)
    print("EDæ³•å®Ÿè¡Œè¨­å®š")
    print("=" * 60)
    print("ã€EDæ³•ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€‘")
    print(f"  å­¦ç¿’ç‡ (alpha):         {hp.learning_rate:.3f}")
    print(f"  åˆæœŸã‚¢ãƒŸãƒ³æ¿ƒåº¦ (beta):  {hp.initial_amine:.3f}")
    print(f"  ã‚¢ãƒŸãƒ³æ‹¡æ•£ä¿‚æ•° (u1):    {hp.diffusion_rate:.3f}")
    print(f"  ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¾å€¤ (u0):    {hp.sigmoid_threshold:.3f}")
    print(f"  é‡ã¿åˆæœŸå€¤1:            {hp.initial_weight_1:.3f}")
    print(f"  é‡ã¿åˆæœŸå€¤2:            {hp.initial_weight_2:.3f}")
    print()
    print("ã€LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€‘")
    print(f"  é™æ­¢è†œé›»ä½ (v_rest):    {hp.v_rest:.1f} mV")
    print(f"  ç™ºç«é–¾å€¤ (v_threshold): {hp.v_threshold:.1f} mV")
    print(f"  ãƒªã‚»ãƒƒãƒˆé›»ä½ (v_reset): {hp.v_reset:.1f} mV")
    print(f"  è†œæ™‚å®šæ•° (tau_m):       {hp.tau_m:.1f} ms")
    print(f"  ä¸å¿œæœŸ (tau_ref):       {hp.tau_ref:.1f} ms")
    print(f"  æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ— (dt):      {hp.dt:.1f} ms")
    print(f"  è†œæŠµæŠ— (R_m):           {hp.R_m:.1f} MÎ©")
    print(f"  ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ™‚é–“:   {hp.simulation_time:.1f} ms")
    print(f"  LIFå±¤ä½¿ç”¨:              {'æœ‰åŠ¹' if hp.enable_lif else 'ç„¡åŠ¹'} [v019 Phase 4]")
    print()
    print("ã€å®Ÿè¡Œæ™‚è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€‘")
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåã®è¡¨ç¤ºæ”¹å–„
    if hp.fashion_mnist:
        dataset_display = 'Fashion-MNIST'
    else:  # mnist
        dataset_display = 'MNIST'
    print(f"  ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ:           {dataset_display}")
    print(f"  è¨“ç·´ãƒ‡ãƒ¼ã‚¿æ•°:           {hp.train_samples}")
    print(f"  ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æ•°:         {hp.test_samples}")
    print(f"  ã‚¨ãƒãƒƒã‚¯æ•°:             {hp.epochs}")
    print(f"  éš ã‚Œå±¤æ§‹é€ :             {hidden_str}")
    print(f"  ãƒŸãƒ‹ãƒãƒƒãƒã‚µã‚¤ã‚º:       {hp.batch_size} {'(é€æ¬¡å‡¦ç†)' if hp.batch_size == 1 else '(ãƒŸãƒ‹ãƒãƒƒãƒ)'}")
    # ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰è¡¨ç¤º
    seed_str = f"{hp.random_seed}" if hp.random_seed is not None else "ãƒ©ãƒ³ãƒ€ãƒ "
    print(f"  ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰:         {seed_str}")
    print(f"  ãƒ‡ãƒ¼ã‚¿ã‚·ãƒ£ãƒƒãƒ•ãƒ«:       {shuffle_str}")
    print(f"  ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–:     {'ON' if hp.enable_visualization else 'OFF'}")
    print(f"  è©³ç´°è¡¨ç¤º:               {'ON' if hp.verbose else 'OFF'}")
    print(f"  å›³è¡¨ä¿å­˜:               {save_fig_str}")
    print("=" * 60)
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print()
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåã®å–å¾—ï¼ˆHyperParams.__post_init__ã§è¨­å®šæ¸ˆã¿ï¼‰
    dataset_name = hp.dataset_name
    dataset_display = dataset_name.upper().replace('_', '-')
    print(f"ğŸ“š {dataset_display}ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
    (train_images, train_labels), (test_images, test_labels) = load_dataset(
        dataset_name, hp.train_samples, hp.test_samples
    )
    
    # å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿æ•°ã‚’è¡¨ç¤ºï¼ˆed_multi_snn.prompt.mdæº–æ‹ : éå­¦ç¿’é˜²æ­¢ã®ãŸã‚å…¨ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨ï¼‰
    actual_train_samples = len(train_images)
    actual_test_samples = len(test_images)
    print(f"âœ… ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†: è¨“ç·´{actual_train_samples}ä»¶ï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿ï¼‰, ãƒ†ã‚¹ãƒˆ{actual_test_samples}ä»¶ï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿ï¼‰")
    print(f"   â€»éå­¦ç¿’é˜²æ­¢ã®ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã‚’ä½¿ç”¨ã—ã¾ã™")
    
    # ã‚¯ãƒ©ã‚¹åãƒãƒƒãƒ”ãƒ³ã‚°å®šç¾©ï¼ˆãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—è¡¨ç¤ºç”¨ï¼‰
    class_names = None
    if dataset_name == 'fashion_mnist':
        # Fashion-MNISTã‚¯ãƒ©ã‚¹åï¼ˆed_multi_snn.prompt.mdæº–æ‹ ï¼‰
        class_names = {
            0: "T-shirt/top",
            1: "Trouser",
            2: "Pullover",
            3: "Dress",
            4: "Coat",
            5: "Sandal",
            6: "Shirt",
            7: "Sneaker",
            8: "Bag",
            9: "Ankle boot"
        }
        print(f"âœ… Fashion-MNISTã‚¯ãƒ©ã‚¹åãƒãƒƒãƒ”ãƒ³ã‚°è¨­å®šå®Œäº†")
    
    # EDæ³•åˆæœŸåŒ–
    print()
    # å…¥åŠ›ã‚µã‚¤ã‚ºã®å‹•çš„è¨ˆç®—ï¼ˆã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ç”»åƒï¼‰
    image_shape = train_images.shape[1:]  # (28, 28)
    base_input_size = np.prod(image_shape)  # 784
    excitatory_size = base_input_size
    inhibitory_size = base_input_size
    paired_input_size = excitatory_size + inhibitory_size  # 1568ï¼ˆE/Iãƒšã‚¢åŒ–å¾Œï¼‰
    output_size = hp.output_size  # 10
    
    print(f"\nğŸ§  ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ ")
    print(f"   å…¥åŠ›ç”»åƒã‚µã‚¤ã‚º: {image_shape} = {base_input_size}ãƒ”ã‚¯ã‚»ãƒ«")
    print(f"   E/Iãƒšã‚¢åŒ–å¾Œ: {paired_input_size}ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ï¼ˆE: {excitatory_size}, I: {inhibitory_size}ï¼‰")
    print(f"   å‡ºåŠ›å±¤: {output_size}ã‚¯ãƒ©ã‚¹")
    
    # v024 Phase 1: LIFå±¤åˆæœŸåŒ–ï¼ˆå˜ç´”ãªSNNãƒ©ãƒƒãƒ‘ãƒ¼ï¼‰
    snn = None
    if hp.enable_lif:
        print("\nğŸ§  LIFå±¤åˆæœŸåŒ–ä¸­...")
        from modules.snn.lif_neuron import LIFNeuronLayer
        
        # LIFå±¤ã‚µã‚¤ã‚ºï¼ˆå…¥åŠ›å±¤ã€éš ã‚Œå±¤ã€å‡ºåŠ›å±¤ï¼‰
        # v019 Phase 11ä¿®æ­£: EDæ³•ä»•æ§˜ã«å®Œå…¨æº–æ‹ 
        # é‡‘å­å‹‡æ°ã®ã‚ªãƒªã‚¸ãƒŠãƒ«EDæ³•ã§ã¯å…¥åŠ›å±¤ã¯èˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§ãƒšã‚¢æ§‹æˆãŒå¿…é ˆ
        # ç‰©ç†çš„ã«1568å€‹ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ï¼ˆèˆˆå¥®æ€§784å€‹+æŠ‘åˆ¶æ€§784å€‹ï¼‰ã§æ§‹æˆ
        # æ³¨: EDCoreã®å„å‡ºåŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯ç‹¬ç«‹ã—ãŸé‡ã¿è¡Œåˆ—ã‚’æŒã¤ãŸã‚ã€
        # LIFå±¤ã¯1ã¤ã®å‡ºåŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ç”¨ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¨ã—ã¦æ§‹ç¯‰
        lif_input_size = paired_input_size  # 1568ï¼ˆEDæ³•ä»•æ§˜æº–æ‹ ï¼‰
        lif_layer_sizes = [lif_input_size] + hidden_sizes + [1]  # å‡ºåŠ›ã¯1ï¼ˆå˜ä¸€ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ï¼‰
        
        # å˜ç´”ãªSNNãƒ©ãƒƒãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹ã‚’ä½œæˆ
        class SimpleSNN:
            """MultiLayerEDCoreç”¨ã®å˜ç´”ãªSNNãƒ©ãƒƒãƒ‘ãƒ¼"""
            def __init__(self, layer_sizes, lif_params, simulation_time, dt):
                self.layer_sizes = layer_sizes
                self.simulation_time = simulation_time
                self.dt = dt
                self.n_timesteps = int(simulation_time / dt)
                
                # GPUå¯¾å¿œ: CuPy/NumPyè‡ªå‹•åˆ‡ã‚Šæ›¿ãˆ
                try:
                    import cupy as cp
                    self.xp = cp
                    self.use_gpu = True
                except ImportError:
                    self.xp = np
                    self.use_gpu = False
                
                # LIFå±¤ã‚’ä½œæˆï¼ˆèˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§ãƒšã‚¢æ§‹é€ ï¼‰
                self.layers = []
                for i, size in enumerate(layer_sizes):
                    # å…¥åŠ›å±¤ã¯èˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§ãƒšã‚¢
                    if i == 0:
                        neuron_types = ['excitatory'] * (size // 2) + ['inhibitory'] * (size // 2)
                    else:
                        neuron_types = ['excitatory'] * size
                    
                    layer = LIFNeuronLayer(
                        n_neurons=size,
                        neuron_params=lif_params,
                        neuron_types=neuron_types
                    )
                    self.layers.append(layer)
                
                # éš ã‚Œå±¤æ´»å‹•ã‚’ä¿å­˜
                self.hidden_activation = None
                    
            def simulate_with_input(self, input_pattern, weights):
                """
                ã‚¹ãƒ‘ã‚¤ã‚¯ä¼æ’­ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
                
                Parameters:
                -----------
                input_pattern : np.ndarray or cp.ndarray
                    å…¥åŠ›ã‚¹ãƒ‘ã‚¤ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³
                weights : list
                    å„å±¤ã®é‡ã¿è¡Œåˆ—ãƒªã‚¹ãƒˆ
                    
                Returns:
                --------
                output_rates : np.ndarray or cp.ndarray
                    å‡ºåŠ›å±¤ã®ç™ºç«ç‡
                sim_info : dict
                    ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±
                """
                # GPUé…åˆ—ã‚’CPUã«å¤‰æ›ï¼ˆLIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯CPUå°‚ç”¨ï¼‰
                if self.use_gpu and hasattr(input_pattern, 'get'):
                    input_pattern_cpu = input_pattern.get()
                else:
                    input_pattern_cpu = np.asarray(input_pattern)
                
                # å±¤ã”ã¨ã«ã‚¹ãƒ‘ã‚¤ã‚¯ä¼æ’­
                layer_firing_rates = []
                layer_output = input_pattern_cpu
                
                for i, layer in enumerate(self.layers[1:], start=1):  # å…¥åŠ›å±¤ã‚¹ã‚­ãƒƒãƒ—
                    # é‡ã¿è¡Œåˆ—ã§çµåˆ
                    if i-1 < len(weights):
                        W = weights[i-1]  # (prev_size, curr_size)
                        # GPUé…åˆ—ã‚’CPUã«å¤‰æ›
                        if self.use_gpu and hasattr(W, 'get'):
                            W_cpu = W.get()
                        else:
                            W_cpu = np.asarray(W)
                        
                        input_currents = W_cpu.T @ layer_output  # (curr_size,)
                    else:
                        # é‡ã¿ãŒãªã„å ´åˆã¯å¹³å‡æ´»å‹•ã‚’ä¼ãˆã‚‹
                        mean_activity = np.mean(layer_output)
                        input_currents = np.full(layer.n_neurons, mean_activity * 10.0)
                    
                    # å„æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
                    spike_counts = np.zeros(layer.n_neurons)
                    for _ in range(self.n_timesteps):
                        spikes = layer.update(input_currents)
                        spike_counts += spikes
                    
                    layer_output = spike_counts / self.n_timesteps  # ç™ºç«ç‡
                    layer_firing_rates.append(np.mean(layer_output))
                    
                    # æœ€å¾Œã‹ã‚‰2ç•ªç›®ã®å±¤ã‚’éš ã‚Œå±¤ã¨ã—ã¦ä¿å­˜
                    if i == len(self.layers) - 1:
                        self.hidden_activation = layer_output
                
                # GPUé…åˆ—ã«å¤‰æ›ã—ã¦è¿”ã™ï¼ˆEDæ³•ã‚³ã‚¢ã¨ã®äº’æ›æ€§ï¼‰
                if self.use_gpu:
                    layer_output = self.xp.asarray(layer_output)
                    if self.hidden_activation is not None:
                        self.hidden_activation = self.xp.asarray(self.hidden_activation)
                
                # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±
                sim_info = {
                    'layer_firing_rates': layer_firing_rates,
                    'total_spikes': sum(layer_firing_rates),
                    'avg_voltage': -65.0  # ãƒ€ãƒŸãƒ¼å€¤
                }
                
                return layer_output, sim_info
                
            def get_hidden_activation(self):
                """éš ã‚Œå±¤ã®æ´»å‹•ã‚’å–å¾—"""
                if self.hidden_activation is None:
                    result = np.zeros(self.layers[-2].n_neurons if len(self.layers) > 1 else 1)
                    # GPUé…åˆ—ã«å¤‰æ›
                    if self.use_gpu:
                        result = self.xp.asarray(result)
                    return result
                return self.hidden_activation
        
        snn = SimpleSNN(
            layer_sizes=lif_layer_sizes,
            lif_params={
                'v_rest': hp.v_rest,
                'v_threshold': hp.v_threshold,
                'v_reset': hp.v_reset,
                'tau_m': hp.tau_m,
                'tau_ref': hp.tau_ref,
                'dt': hp.dt,
                'r_m': hp.R_m
            },
            simulation_time=hp.simulation_time,
            dt=hp.dt
        )
        print(f"âœ… LIFå±¤åˆæœŸåŒ–å®Œäº†ï¼ˆå±¤æ•°: {len(lif_layer_sizes)}, å…¥åŠ›: {lif_input_size}, å‡ºåŠ›: 1ï¼ˆå˜ä¸€å‡ºåŠ›ç”¨ï¼‰, ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ™‚é–“: {hp.simulation_time}msï¼‰")
    
    print("ğŸ—ï¸  çœŸã®å¤šå±¤EDæ³•åˆæœŸåŒ–ä¸­...")
    ed_core = MultiLayerEDCore(
        input_size=paired_input_size,
        hidden_sizes=hidden_sizes,
        output_size=output_size,
        learning_rate=hp.learning_rate,
        initial_amine=hp.initial_amine,
        diffusion_rate=hp.diffusion_rate,
        sigmoid_threshold=hp.sigmoid_threshold,
        initial_weight_1=hp.initial_weight_1,
        initial_weight_2=hp.initial_weight_2,
        snn=snn,  # v019 Phase 5è¿½åŠ 
        hp=hp     # v019 Phase 5è¿½åŠ 
    )
    
    # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—çµ±åˆåˆæœŸåŒ–
    heatmap_integration = None
    if hp.enable_heatmap:
        try:
            from modules.snn_heatmap_integration import EDSNNHeatmapIntegration
            heatmap_integration = EDSNNHeatmapIntegration(
                hp, ed_core, class_names=class_names, image_shape=image_shape
            )
            print("âœ… ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—çµ±åˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
        except ImportError as e:
            print(f"âš ï¸ ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
        except Exception as e:
            print(f"âš ï¸ ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—çµ±åˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿ã‚’å‰å‡¦ç†ï¼‰
    train_processed_all, train_labels_processed_all = PureEDPreprocessor.pure_ed_preprocess(
        train_images, train_labels, base_input_size
    )
    test_processed_all, test_labels_processed_all = PureEDPreprocessor.pure_ed_preprocess(
        test_images, test_labels, base_input_size
    )
    
    # ã‚µãƒ³ãƒ—ãƒ«æ•°æ±ºå®šï¼ˆed_multi_snn.prompt.mdæº–æ‹ ãƒ»æ”¹è‰¯ç‰ˆï¼‰
    # - hp.train_samples > 0: æŒ‡å®šã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’ä½¿ç”¨ï¼ˆå®Ÿé¨“ãƒ»ãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
    # - hp.train_samples = 0: å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼ˆæœ¬æ ¼çš„ãªå­¦ç¿’ç”¨ï¼‰
    use_train_samples = hp.train_samples if hp.train_samples > 0 else len(train_processed_all)
    use_test_samples = hp.test_samples if hp.test_samples > 0 else len(test_processed_all)
    
    # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æˆ¦ç•¥ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    if hp.train_samples > 0 and hp.train_samples < len(train_processed_all):
        sampling_strategy = f"ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«{use_train_samples}ã‚µãƒ³ãƒ—ãƒ«ã‚’ãƒ©ãƒ³ãƒ€ãƒ æŠ½å‡ºï¼ˆéå­¦ç¿’é˜²æ­¢ï¼‰"
    else:
        sampling_strategy = "å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨"
    
    print("\nğŸš€ ãƒŸãƒ‹ãƒãƒƒãƒå¯¾å¿œEDæ³•å­¦ç¿’é–‹å§‹")
    print("=" * 60)
    print(f"  ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {len(train_processed_all)}ä»¶ï¼ˆè¨“ç·´ï¼‰, {len(test_processed_all)}ä»¶ï¼ˆãƒ†ã‚¹ãƒˆï¼‰")
    print(f"  ä½¿ç”¨ã‚µãƒ³ãƒ—ãƒ«: {use_train_samples}ä»¶ï¼ˆè¨“ç·´ï¼‰, {use_test_samples}ä»¶ï¼ˆãƒ†ã‚¹ãƒˆï¼‰")
    print(f"  ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æˆ¦ç•¥: {sampling_strategy}")
    print(f"  ã‚¨ãƒãƒƒã‚¯æ•°: {hp.epochs}")
    print(f"  ãƒãƒƒãƒã‚µã‚¤ã‚º: {hp.batch_size} {'(é€æ¬¡å‡¦ç†)' if hp.batch_size == 1 else '(ãƒŸãƒ‹ãƒãƒƒãƒ)'}")
    print(f"  ãƒ‡ãƒ¼ã‚¿ã‚·ãƒ£ãƒƒãƒ•ãƒ«: {'ç„¡åŠ¹' if hp.no_shuffle else 'æœ‰åŠ¹'}")
    print(f"  ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º: {'æœ‰åŠ¹ (å­¦ç¿’åˆæœŸã‹ã‚‰è¡¨ç¤º)' if hp.enable_visualization else 'ç„¡åŠ¹'}")
    print("=" * 60)
    
    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–åˆæœŸåŒ–ï¼ˆed_v032_simple.pyæº–æ‹  + 2x2ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼‰
    visualizer = None
    if hp.enable_visualization:
        print("\nğŸ¨ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–åˆæœŸåŒ–ä¸­...")
        
        # éš ã‚Œå±¤æ§‹é€ ã®æ–‡å­—åˆ—åŒ–
        hidden_str = str(hidden_sizes) if hidden_sizes else '[64]'
        
        visualizer = RealtimeLearningVisualizer(
            max_epochs=hp.epochs,
            window_size=(1000, 640),  # 2x2ã‚°ãƒªãƒƒãƒ‰ç”¨ã«ã‚µã‚¤ã‚ºèª¿æ•´ï¼ˆé«˜ã•80%ï¼‰
            learning_rate=hp.learning_rate,
            initial_amine=hp.initial_amine,
            diffusion_rate=hp.diffusion_rate,
            sigmoid_threshold=hp.sigmoid_threshold,
            initial_weight_1=hp.initial_weight_1,
            initial_weight_2=hp.initial_weight_2,
            dataset_name=dataset_name.upper(),
            train_samples=use_train_samples,  # ä¿®æ­£: å®Ÿéš›ã«ä½¿ç”¨ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«æ•°
            test_samples=use_test_samples,    # ä¿®æ­£: å®Ÿéš›ã«ä½¿ç”¨ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«æ•°
            hidden_layers=hidden_str,
            batch_size=hp.batch_size,
            # v019 Phase 3: LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¿½åŠ 
            v_rest=hp.v_rest,
            v_threshold=hp.v_threshold,
            v_reset=hp.v_reset,
            tau_m=hp.tau_m,
            tau_ref=hp.tau_ref,
            dt=hp.dt,
            R_m=hp.R_m,
            simulation_time=hp.simulation_time,
            # v021 Phase 1è¿½åŠ : ã‚·ãƒ¼ãƒ‰ã¨è©³ç´°è¡¨ç¤º
            random_seed=hp.random_seed,
            verbose=hp.verbose
        )
        visualizer.setup_plots()
        print("âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–æº–å‚™å®Œäº†")
    
    # å­¦ç¿’ãƒ«ãƒ¼ãƒ—
    start_time = time.time()
    train_accuracies = []
    test_accuracies = []
    losses = []
    
    # ğŸ” æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ : è¨“ç·´/ãƒ†ã‚¹ãƒˆçµæœä¿æŒç”¨é…åˆ—ï¼ˆed_multi_snn.prompt.mdæº–æ‹ ï¼‰
    # ã‚¨ãƒãƒƒã‚¯Ã—ã‚µãƒ³ãƒ—ãƒ«æ•°ã®2æ¬¡å…ƒé…åˆ—ã§å…¨çµæœã‚’è¨˜éŒ²
    train_results_log = []  # å„ã‚¨ãƒãƒƒã‚¯ã®è¨“ç·´çµæœ: [(data_idx, true_label, pred_label), ...]
    test_results_log = []   # å„ã‚¨ãƒãƒƒã‚¯ã®ãƒ†ã‚¹ãƒˆçµæœ: [(data_idx, true_label, pred_label), ...]
    
    epoch_pbar = tqdm(range(hp.epochs), 
                      desc="",  # ã‚¹ãƒšãƒ¼ã‚¹ç¢ºä¿ã®ãŸã‚å‰Šé™¤
                      unit="epoch",
                      ncols=110,  # è¡¨ç¤ºå´©ã‚Œé˜²æ­¢ã®ãŸã‚èª¿æ•´
                      bar_format='{l_bar}{bar:13}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}{postfix}]')  # bar:13ã§å¹…åˆ¶é™ï¼ˆä½™è£•ç¢ºä¿ï¼‰
    
    for epoch in epoch_pbar:
        epoch_start = time.time()
        correct_train = 0
        total_samples = 0
        
        # ğŸ” æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ : ã“ã®ã‚¨ãƒãƒƒã‚¯ã®è¨“ç·´çµæœè¨˜éŒ²ç”¨
        epoch_train_log = []
        
        # ã‚¨ãƒãƒƒã‚¯ã”ã¨ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆed_multi_snn.prompt.mdæº–æ‹ ãƒ»éå­¦ç¿’é˜²æ­¢ï¼‰
        if use_train_samples < len(train_processed_all):
            # æŒ‡å®šã‚µãƒ³ãƒ—ãƒ«æ•° < å…¨ãƒ‡ãƒ¼ã‚¿: ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            train_indices = np.random.choice(len(train_processed_all), use_train_samples, replace=False)
            train_processed = train_processed_all[train_indices]
            train_labels_processed = train_labels_processed_all[train_indices]
        else:
            # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
            train_processed = train_processed_all
            train_labels_processed = train_labels_processed_all
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚‚åŒæ§˜ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        if use_test_samples < len(test_processed_all):
            test_indices = np.random.choice(len(test_processed_all), use_test_samples, replace=False)
            test_processed = test_processed_all[test_indices]
            test_labels_processed = test_labels_processed_all[test_indices]
        else:
            test_processed = test_processed_all
            test_labels_processed = test_labels_processed_all
        
        # ãƒŸãƒ‹ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆ
        train_loader = MiniBatchDataLoader(
            inputs=train_processed,
            labels=train_labels_processed,
            batch_size=hp.batch_size,
            shuffle=not hp.no_shuffle
        )
        
        # ãƒãƒƒãƒå˜ä½ã§å­¦ç¿’
        for batch_idx, (batch_inputs, batch_labels) in enumerate(train_loader):
            # ãƒãƒƒãƒå†…ã®å„ã‚µãƒ³ãƒ—ãƒ«ã‚’å‡¦ç†
            for i in range(len(batch_inputs)):
                sample = batch_inputs[i]
                label = batch_labels[i]
                
                # EDæ³•å­¦ç¿’å‡¦ç†
                outputs = ed_core.forward_pass(sample)
                
                targets = np.zeros(output_size)
                targets[label] = 1.0
                
                ed_core.pure_ed_learning_step(sample, targets, outputs)
                
                # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—æ›´æ–°ï¼ˆMNIST/Fashion-MNIST: 10ã‚µãƒ³ãƒ—ãƒ«ã”ã¨ï¼‰
                update_interval = 10
                if heatmap_integration and total_samples % update_interval == 0:
                    spike_activities = convert_ed_outputs_to_spike_activities(
                        ed_core, sample, original_image_shape=image_shape
                    )
                    
                    predicted_label = int(np.argmax(outputs))
                    true_label = int(label)
                    
                    heatmap_integration.update_snn_heatmap(
                        spike_activities=spike_activities,
                        epoch=epoch,
                        sample_idx=total_samples,
                        true_label=true_label,
                        predicted_label=predicted_label
                    )
                
                # ç²¾åº¦è¨ˆç®—
                predicted_label = int(np.argmax(outputs))
                true_label = int(label)
                
                if predicted_label == true_label:
                    correct_train += 1
                
                total_samples += 1
                
                # ğŸ” æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ : è¨“ç·´çµæœã‚’è¨˜éŒ²
                epoch_train_log.append({
                    'data_idx': total_samples - 1,
                    'true_label': true_label,
                    'pred_label': predicted_label,
                    'error': np.sum(np.abs(targets - outputs))  # EDæ³•ã®å­¦ç¿’ä¿¡å·ç”¨
                })
        
        # ã‚¨ãƒãƒƒã‚¯çµ‚äº†å‡¦ç†
        epoch_time = time.time() - epoch_start
        train_accuracy = (correct_train / total_samples) * 100
        train_error_rate = 100.0 - train_accuracy  # ã‚¨ãƒ©ãƒ¼ç‡ = 100% - ç²¾åº¦
        
        # ğŸ” æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ : ã‚¨ãƒãƒƒã‚¯ã®è¨“ç·´çµæœã‚’ä¿å­˜
        train_results_log.append(epoch_train_log)
        
        # ãƒ†ã‚¹ãƒˆè©•ä¾¡ï¼ˆå…¨ã‚µãƒ³ãƒ—ãƒ«ã§è©•ä¾¡ï¼‰
        correct_test = 0
        epoch_test_log = []
        
        # ğŸ” ä¿®æ­£: å…¨ãƒ†ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«ã§è©•ä¾¡ï¼ˆ100ã‚µãƒ³ãƒ—ãƒ«åˆ¶é™ã‚’æ’¤å»ƒï¼‰
        test_sample_count = len(test_processed)
        for i in range(test_sample_count):
            outputs = ed_core.forward_pass(test_processed[i])
            predicted_label = int(np.argmax(outputs))
            true_label = int(test_labels_processed[i])
            
            if predicted_label == true_label:
                correct_test += 1
            
            # EDæ³•ã®å­¦ç¿’ä¿¡å·è¨ˆç®—ï¼ˆæ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ ç”¨ï¼‰
            targets = np.zeros(output_size)
            targets[true_label] = 1.0
            sample_error = np.sum(np.abs(targets - outputs))
            
            # ğŸ” æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ : ãƒ†ã‚¹ãƒˆçµæœã‚’è¨˜éŒ²
            epoch_test_log.append({
                'data_idx': i,
                'true_label': true_label,
                'pred_label': predicted_label,
                'error': sample_error  # EDæ³•ã®å­¦ç¿’ä¿¡å·ç”¨
            })
        
        # ğŸ” æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ : ã‚¨ãƒãƒƒã‚¯ã®ãƒ†ã‚¹ãƒˆçµæœã‚’ä¿å­˜
        test_results_log.append(epoch_test_log)
        
        test_accuracy = (correct_test / test_sample_count) * 100
        test_error_rate = 100.0 - test_accuracy  # ã‚¨ãƒ©ãƒ¼ç‡ = 100% - ç²¾åº¦
        
        # è¨˜éŒ²ï¼ˆlossesã¯å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã‚¨ãƒ©ãƒ¼ç‡/100ã‚’æ ¼ç´ï¼‰
        train_accuracies.append(train_accuracy)
        test_accuracies.append(test_accuracy)
        losses.append(train_error_rate / 100.0)  # 0-1ç¯„å›²ã«æ­£è¦åŒ–
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–æ›´æ–°ï¼ˆed_v032_simple.pyæº–æ‹ ï¼‰
        if visualizer:
            visualizer.update(
                epoch=epoch,
                train_acc=train_accuracy,
                test_acc=test_accuracy,
                train_err_rate=train_error_rate,  # è¨“ç·´ã‚¨ãƒ©ãƒ¼ç‡ (100 - train_acc)
                test_err_rate=test_error_rate     # ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ç‡ (100 - test_acc)
            )
        
        # tqdmé€²è¡ŒçŠ¶æ³æ›´æ–°ï¼ˆã‚¨ãƒ©ãƒ¼ç‡ = 100% - ç²¾åº¦ï¼‰
        epoch_pbar.set_postfix({
            'è¨“ç²¾': f'{train_accuracy:.1f}%',      # è¨“ç·´æ­£ç­”ç‡
            'ãƒ†ç²¾': f'{test_accuracy:.1f}%',        # ãƒ†ã‚¹ãƒˆæ­£ç­”ç‡
            'è¨“ã‚¨': f'{train_error_rate:.1f}%',    # è¨“ç·´ã‚¨ãƒ©ãƒ¼ç‡ (100 - è¨“ç·´æ­£ç­”ç‡)
            'ãƒ†ã‚¨': f'{test_error_rate:.1f}%'      # ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ç‡ (100 - ãƒ†ã‚¹ãƒˆæ­£ç­”ç‡)
        })
    
    epoch_pbar.close()
    
    # ğŸ” æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ : --verify_acc_lossæŒ‡å®šæ™‚ã®ã¿è¡¨ç¤º
    if hp.verify_acc_loss:
        verifier = AccuracyLossVerifier()
        verification_results = verifier.verify_and_report(
            train_results_log=train_results_log,
            test_results_log=test_results_log,
            train_accuracies=train_accuracies,
            test_accuracies=test_accuracies,
            losses=losses,
            epochs=hp.epochs,
            show_sample_details=True
        )
        final_verified_train_accuracy = verification_results['final_train_accuracy']
        final_verified_test_accuracy = verification_results['final_test_accuracy']
    else:
        # æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆéè¡¨ç¤ºæ™‚ã¯ç°¡æ˜“è¨ˆç®—ã®ã¿
        train_log = train_results_log[-1]  # æœ€çµ‚ã‚¨ãƒãƒƒã‚¯
        test_log = test_results_log[-1]
        verified_train_correct = sum(1 for r in train_log if r['true_label'] == r['pred_label'])
        verified_test_correct = sum(1 for r in test_log if r['true_label'] == r['pred_label'])
        final_verified_train_accuracy = (verified_train_correct / len(train_log)) * 100
        final_verified_test_accuracy = (verified_test_correct / len(test_log)) * 100
    print("ğŸ¯ æ¤œè¨¼çµè«–:")
    
    # æœ€çµ‚ã‚¨ãƒãƒƒã‚¯ã®æ¤œè¨¼å€¤ã‚’ä½¿ç”¨ï¼ˆãƒ«ãƒ¼ãƒ—å¤–ã§å®šç¾©æ¸ˆã¿ï¼‰
    if hp.epochs > 0:
        final_train_diff = abs(train_accuracies[-1] - final_verified_train_accuracy)
        final_test_diff = abs(test_accuracies[-1] - final_verified_test_accuracy)
        
        if final_train_diff < 0.01 and final_test_diff < 0.01:
            print("  âœ… ç²¾åº¦ãƒ»èª¤å·®ã®è¨ˆç®—ã¯æ­£ç¢ºã§ã™ï¼ˆå·®ç•° < 0.01%ï¼‰")
        elif final_train_diff < 0.1 and final_test_diff < 0.1:
            print("  âš ï¸  è»½å¾®ãªå·®ç•°ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸï¼ˆå·®ç•° < 0.1%ï¼‰")
        else:
            print("  âš ï¸  æœ‰æ„ãªå·®ç•°ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸï¼è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ã®è¦‹ç›´ã—ãŒå¿…è¦ã§ã™")
    print("="*80 + "\n")
    
    # å­¦ç¿’å®Œäº†
    total_time = time.time() - start_time
    
    print("ğŸ‰ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–å¯¾å¿œEDæ³•å­¦ç¿’å®Œäº†!")
    print(f"â±ï¸  ç·æ™‚é–“: {total_time:.2f}ç§’ ({total_time/60:.2f}åˆ†)")
    print(f"âš¡ å‡¦ç†é€Ÿåº¦: {use_train_samples * hp.epochs / total_time:.0f} ã‚µãƒ³ãƒ—ãƒ«/ç§’")
    
    # æœ€çµ‚ãƒ†ã‚¹ãƒˆè©•ä¾¡ï¼ˆæœ€æ–°ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ã‚’ä½¿ç”¨ï¼‰
    print("\nğŸ§ª æœ€çµ‚ãƒ†ã‚¹ãƒˆè©•ä¾¡ä¸­...")
    
    # æœ€çµ‚ã‚¨ãƒãƒƒã‚¯ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    if use_test_samples < len(test_processed_all):
        test_indices = np.random.choice(len(test_processed_all), use_test_samples, replace=False)
        final_test_processed = test_processed_all[test_indices]
        final_test_labels_processed = test_labels_processed_all[test_indices]
    else:
        final_test_processed = test_processed_all
        final_test_labels_processed = test_labels_processed_all
    
    correct = 0
    for i in range(len(final_test_processed)):
        outputs = ed_core.forward_pass(final_test_processed[i])
        if np.argmax(outputs) == final_test_labels_processed[i]:
            correct += 1
    
    final_accuracy = (correct / len(final_test_processed)) * 100
    print(f"âœ… æœ€çµ‚ãƒ†ã‚¹ãƒˆæ­£ç­”ç‡: {final_accuracy:.2f}% ({correct}/{len(final_test_processed)})")
    
    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–çµ‚äº†å‡¦ç†ï¼ˆed_v032_simple.pyæº–æ‹ ï¼‰
    if visualizer:
        # --save_figã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ä¿å­˜
        if hp.save_fig:
            print(f"\nğŸ¨ å­¦ç¿’æ›²ç·šä¿å­˜ä¸­: {hp.save_fig}/")
            visualizer.save_figure(hp.save_fig)
            print("âœ… ä¿å­˜å®Œäº†")
        
        # æœ€çµ‚çš„ãªè¡¨ç¤ºã‚’ç¶­æŒï¼ˆ5ç§’å¾Œã«è‡ªå‹•ã‚¯ãƒ­ãƒ¼ã‚º or ã‚­ãƒ¼æŠ¼ä¸‹ã§å³åº§ã«ã‚¯ãƒ­ãƒ¼ã‚ºï¼‰
        print("ğŸ“Š å­¦ç¿’æ›²ç·šã‚’è¡¨ç¤ºä¸­...")
        try:
            plt.ioff()  # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰ã‚’ç„¡åŠ¹åŒ–
            
            # éãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ã§è¡¨ç¤ºæ›´æ–°
            plt.show(block=False)
            plt.pause(0.1)
            
            # ã‚­ãƒ¼æŠ¼ä¸‹ã¾ãŸã¯5ç§’å¾…æ©Ÿ
            wait_for_keypress_or_timeout(timeout_seconds=5)
            
        except Exception as e:
            print(f"âš ï¸  è¡¨ç¤ºå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            visualizer.close()
            print("âœ… ã‚°ãƒ©ãƒ•ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’ã‚¯ãƒ­ãƒ¼ã‚ºã—ã¾ã—ãŸ")
    
    print("\nâœ… æœ€çµ‚çµæœ:")
    print(f"   å­¦ç¿’ç²¾åº¦: {train_accuracies[-1]:.2f}%")
    print(f"   ãƒ†ã‚¹ãƒˆæ­£ç­”ç‡: {final_accuracy:.2f}%")
    print(f"   ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–: ed_v032_simple.pyæº–æ‹ ")
    print("ğŸ§¬ ç”Ÿç‰©å­¦çš„å¦¥å½“æ€§: å®Œå…¨ä¿æŒï¼ˆèª¤å·®é€†ä¼æ’­ãªã—ï¼‰")
    print("âš–ï¸  å®Ÿè£…ä¸€è‡´æ€§: ed_multi_snn.prompt.mdå®Œå…¨æº–æ‹ ")
    
    # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—çµ‚äº†å‡¦ç†
    if heatmap_integration:
        print("\nğŸ¯ ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—è¡¨ç¤ºä¸­...")
        try:
            # ã‚­ãƒ¼æŠ¼ä¸‹ã¾ãŸã¯5ç§’å¾…æ©Ÿ
            wait_for_keypress_or_timeout(timeout_seconds=5)
        except Exception as e:
            print(f"âš ï¸  å¾…æ©Ÿå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            print("ğŸ¯ ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—çµ‚äº†å‡¦ç†ä¸­...")
            heatmap_integration.stop_snn_heatmap_display()
            print("âœ… ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ çµ‚äº†å®Œäº†")

if __name__ == "__main__":
    main()
