#!/usr/bin/env python3
"""
é«˜é€ŸåŒ–ED-SNNãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çµ±åˆ v2

NumPyæœ€é©åŒ–ã«ã‚ˆã‚‹é«˜é€ŸåŒ–ED-SNNå®Ÿè£…
LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¨EDå­¦ç¿’ã®æœ€é©åŒ–çµ±åˆ

ä½œæˆè€…: ED-SNNé–‹ç™ºãƒãƒ¼ãƒ   
ä½œæˆæ—¥: 2025å¹´9æœˆ28æ—¥
ãƒãƒ¼ã‚¸ãƒ§ãƒ³: v2_fast
"""

import numpy as np
import time
from typing import List, Dict, Any, Optional

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«èª­ã¿è¾¼ã¿
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from .ed_core_fast_v2 import EDCoreFast
from snn.lif_neuron import LIFNeuronLayer

class EDSpikingNeuralNetworkFastV2:
    """é«˜é€ŸåŒ–ED-SNNãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ v2"""
    
    def __init__(self, 
                 network_structure: List[int],
                 simulation_time: float = 20.0,
                 dt: float = 1.0,
                 use_fast_core: bool = True):
        """
        é«˜é€ŸåŒ–ED-SNNãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆæœŸåŒ–
        
        Parameters:
        -----------
        network_structure : List[int]
            [å…¥åŠ›, éš ã‚Œ, å‡ºåŠ›] ã®ãƒªã‚¹ãƒˆ
        simulation_time : float
            ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ™‚é–“ (ms)
        dt : float
            æ™‚é–“åˆ»ã¿ (ms)
        use_fast_core : bool
            é«˜é€ŸåŒ–EDã‚³ã‚¢ä½¿ç”¨ãƒ•ãƒ©ã‚°
        """
        
        print("é«˜é€ŸåŒ–ED-SNNãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆæœŸåŒ–:")
        
        self.network_structure = network_structure
        self.simulation_time = simulation_time
        self.dt = dt
        self.use_fast_core = use_fast_core
        
        # èˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§æ§‹é€ ï¼ˆMNISTå¯¾å¿œï¼‰
        self._setup_excitatory_inhibitory_structure()
        
        # EDå­¦ç¿’ã‚³ã‚¢åˆæœŸåŒ–ï¼ˆé«˜é€Ÿç‰ˆï¼‰
        self._initialize_ed_core()
        
        # LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³å±¤åˆæœŸåŒ–
        self._initialize_lif_layers()
        
        # çµ±è¨ˆæƒ…å ±
        self._initialize_performance_stats()
        
        print(f"é«˜é€ŸåŒ–ED-SNNãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆæœŸåŒ–å®Œäº†:")
        print(f"  æ§‹é€ : {self.network_structure}")
        print(f"  ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ™‚é–“: {self.simulation_time}ms")
        print(f"  é«˜é€ŸåŒ–EDã‚³ã‚¢: {self.use_fast_core}")
        print(f"  èˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§æ§‹é€ : {self.n_excitatory}E / {self.n_inhibitory}I")
        
    def _setup_excitatory_inhibitory_structure(self):
        """èˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ§‹é€ è¨­å®š"""
        input_size = self.network_structure[0]
        
        # èˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§ãƒšã‚¢ï¼ˆMNIST: 784 -> 819E + 791I = 1610ï¼‰
        self.n_excitatory = int(input_size * 1.045)  # ç´„104.5%
        self.n_inhibitory = input_size  # æŠ‘åˆ¶æ€§ã¯å…ƒã®ã‚µã‚¤ã‚º
        
        # EDå­¦ç¿’ç”¨ã®ç·å…¥åŠ›ã‚µã‚¤ã‚º
        self.ed_input_size = self.n_excitatory + self.n_inhibitory + 8  # ãƒãƒƒãƒ•ã‚¡è¿½åŠ 
        
    def _initialize_ed_core(self):
        """EDå­¦ç¿’ã‚³ã‚¢åˆæœŸåŒ–ï¼ˆé«˜é€Ÿç‰ˆï¼‰"""
        
        hidden_size = self.network_structure[1] if len(self.network_structure) > 1 else 0
        output_size = self.network_structure[-1]
        
        # é«˜é€ŸåŒ–EDã‚³ã‚¢ä½¿ç”¨
        if self.use_fast_core:
            self.ed_core = EDCoreFast(
                n_input=self.ed_input_size,
                n_hidden=hidden_size,
                n_output=output_size,
                max_units=self.ed_input_size + hidden_size + output_size + 50
            )
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆé€šå¸¸ç‰ˆï¼‰
            from ed_learning.ed_core import EDCore
            self.ed_core = EDCore(
                n_input=self.ed_input_size,
                n_hidden=hidden_size,
                n_output=output_size
            )
            
    def _initialize_lif_layers(self):
        """LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³å±¤åˆæœŸåŒ–"""
        
        print("LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³å±¤ä½œæˆå®Œäº†:")
        
        # å…¥åŠ›å±¤ï¼ˆèˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§ï¼‰
        self.input_layer = LIFNeuronLayer(
            n_neurons=self.ed_input_size,
            tau_m=20.0,
            v_rest=-70.0,
            v_threshold=-55.0,
            v_reset=-75.0
        )
        print(f"  å…¥åŠ›å±¤: {self.ed_input_size} neurons")
        
        # éš ã‚Œå±¤
        if len(self.network_structure) > 2:
            hidden_size = self.network_structure[1]
            self.hidden_layer = LIFNeuronLayer(
                n_neurons=hidden_size,
                tau_m=20.0,
                v_rest=-70.0,
                v_threshold=-55.0,
                v_reset=-75.0
            )
            print(f"  éš ã‚Œå±¤: {hidden_size} neurons")
        else:
            self.hidden_layer = None
            
        # å‡ºåŠ›å±¤
        output_size = self.network_structure[-1]
        self.output_layer = LIFNeuronLayer(
            n_neurons=output_size,
            tau_m=20.0,
            v_rest=-70.0,
            v_threshold=-55.0,
            v_reset=-75.0
        )
        print(f"  å‡ºåŠ›å±¤: {output_size} neurons")
        
    def _initialize_performance_stats(self):
        """æ€§èƒ½çµ±è¨ˆåˆæœŸåŒ–"""
        self.performance_stats = {
            'total_samples': 0,
            'total_training_time': 0.0,
            'encoding_time': 0.0,
            'simulation_time': 0.0,
            'ed_computation_time': 0.0,
            'accuracy_history': []
        }
        
    def encode_input_fast(self, input_data: np.ndarray, encoding_type: str = 'rate') -> np.ndarray:
        """é«˜é€Ÿå…¥åŠ›ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°"""
        start_time = time.time()
        
        # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–
        if np.max(input_data) > 1.0:
            input_data = input_data / 255.0
            
        if encoding_type == 'rate':
            # ãƒ¬ãƒ¼ãƒˆç¬¦å·åŒ–ï¼ˆé«˜é€ŸåŒ–ï¼‰
            base_rates = input_data * 100.0  # Hz
            
            # èˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
            excitatory_rates = np.zeros(self.n_excitatory)
            inhibitory_rates = np.zeros(self.n_inhibitory)
            
            # åŠ¹ç‡çš„ãªé…åˆ—æ“ä½œ
            excitatory_rates[:len(input_data)] = base_rates
            inhibitory_rates[:len(input_data)] = base_rates * 0.7  # æŠ‘åˆ¶æ€§ã¯70%
            
            # çµ±åˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
            encoded_input = np.concatenate([
                excitatory_rates,
                inhibitory_rates,
                np.zeros(8)  # ãƒãƒƒãƒ•ã‚¡
            ])
            
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: å˜ç´”æ‹¡å¼µ
            encoded_input = np.zeros(self.ed_input_size)
            encoded_input[:len(input_data)] = input_data
            
        self.performance_stats['encoding_time'] += time.time() - start_time
        return encoded_input
        
    def simulate_snn_fast(self, encoded_input: np.ndarray) -> Dict[str, np.ndarray]:
        """é«˜é€ŸSNNã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        start_time = time.time()
        
        n_steps = int(self.simulation_time / self.dt)
        
        # ã‚¹ãƒ‘ã‚¤ã‚¯è¨˜éŒ²
        input_spikes = []
        output_spikes = []
        
        # é«˜é€Ÿã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆã‚¹ãƒ†ãƒƒãƒ—å‰Šæ¸›ï¼‰
        for step in range(0, n_steps, max(1, n_steps // 5)):  # 5ã‚¹ãƒ†ãƒƒãƒ—ã«å‰Šæ¸›
            
            # å…¥åŠ›å±¤æ›´æ–°
            input_current = encoded_input * (step / n_steps)
            input_voltages, input_spike_trains = self.input_layer.update(
                input_current, self.dt
            )
            input_spikes.append(np.sum(input_spike_trains))
            
            # å‡ºåŠ›å±¤æ›´æ–°ï¼ˆç°¡ç•¥åŒ–ï¼‰
            output_current = np.random.normal(0, 0.1, self.network_structure[-1])
            output_voltages, output_spike_trains = self.output_layer.update(
                output_current, self.dt
            )
            output_spikes.append(np.sum(output_spike_trains))
            
        self.performance_stats['simulation_time'] += time.time() - start_time
        
        return {
            'input_spikes': np.array(input_spikes),
            'output_spikes': np.array(output_spikes),
            'final_input_rates': encoded_input
        }
        
    def train_step(self, input_data: np.ndarray, target_data: np.ndarray, 
                   encoding_type: str = 'rate') -> Dict[str, Any]:
        """é«˜é€Ÿå­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—"""
        total_start_time = time.time()
        
        # 1. å…¥åŠ›ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
        encoded_input = self.encode_input_fast(input_data, encoding_type)
        
        # 2. SNNã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³  
        snn_results = self.simulate_snn_fast(encoded_input)
        
        # 3. EDå­¦ç¿’è¨ˆç®—ï¼ˆé«˜é€Ÿç‰ˆï¼‰
        ed_start_time = time.time()
        
        # EDå…¥åŠ›æº–å‚™
        ed_input = snn_results['final_input_rates']
        
        # EDé †ä¼æ’­
        ed_outputs = self.ed_core.neuro_output_calc(ed_input)
        
        # EDæ•™å¸«å­¦ç¿’
        target_list = target_data.tolist() if isinstance(target_data, np.ndarray) else target_data
        self.ed_core.neuro_teach_calc(target_list)
        
        # EDé‡ã¿æ›´æ–°
        self.ed_core.neuro_weight_calc()
        
        self.performance_stats['ed_computation_time'] += time.time() - ed_start_time
        
        # 4. ç²¾åº¦è¨ˆç®—
        predicted_class = np.argmax(ed_outputs)
        true_class = np.argmax(target_data)
        accuracy = float(predicted_class == true_class)
        
        # 5. çµ±è¨ˆæ›´æ–°
        total_time = time.time() - total_start_time
        self.performance_stats['total_samples'] += 1
        self.performance_stats['total_training_time'] += total_time
        self.performance_stats['accuracy_history'].append(accuracy)
        
        return {
            'outputs': ed_outputs,
            'accuracy': accuracy,
            'error': self.ed_core.get_current_error(),
            'training_time': total_time,
            'predicted_class': predicted_class,
            'true_class': true_class
        }
        
    def get_performance_report(self) -> str:
        """æ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆå–å¾—"""
        stats = self.performance_stats
        ed_stats = self.ed_core.get_performance_stats()
        
        total_samples = max(1, stats['total_samples'])
        
        report = f"""
ğŸš€ é«˜é€ŸåŒ–ED-SNNæ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆ
{'='*50}
ğŸ“Š åŸºæœ¬çµ±è¨ˆ:
  å‡¦ç†ã‚µãƒ³ãƒ—ãƒ«æ•°: {total_samples}
  ç·å­¦ç¿’æ™‚é–“: {stats['total_training_time']:.2f}ç§’
  å¹³å‡ã‚µãƒ³ãƒ—ãƒ«æ™‚é–“: {stats['total_training_time']/total_samples:.3f}ç§’
  
â±ï¸ æ™‚é–“å†…è¨³:
  ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°: {stats['encoding_time']:.2f}ç§’ ({stats['encoding_time']/stats['total_training_time']*100:.1f}%)
  SNNã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: {stats['simulation_time']:.2f}ç§’ ({stats['simulation_time']/stats['total_training_time']*100:.1f}%)
  EDè¨ˆç®—: {stats['ed_computation_time']:.2f}ç§’ ({stats['ed_computation_time']/stats['total_training_time']*100:.1f}%)
  
ğŸ¯ å­¦ç¿’æ€§èƒ½:
  æœ€æ–°ç²¾åº¦: {stats['accuracy_history'][-1]*100:.1f}% (æœ€å¾Œã®5ã‚µãƒ³ãƒ—ãƒ«å¹³å‡: {np.mean(stats['accuracy_history'][-5:])*100:.1f}%)
  
ğŸ”§ EDã‚³ã‚¢çµ±è¨ˆ:
  EDå¹³å‡æ™‚é–“: {ed_stats['average_time_per_operation']:.4f}ç§’
  é †ä¼æ’­æ¯”ç‡: {ed_stats['forward_time_ratio']*100:.1f}%
  æ•™å¸«å­¦ç¿’æ¯”ç‡: {ed_stats['backward_time_ratio']*100:.1f}%
  é‡ã¿æ›´æ–°æ¯”ç‡: {ed_stats['weight_update_ratio']*100:.1f}%
  
ğŸ“ˆ æ¨å®šæ€§èƒ½:
  1ã‚¨ãƒãƒƒã‚¯(60,000ã‚µãƒ³ãƒ—ãƒ«): {stats['total_training_time']/total_samples * 60000 / 3600:.1f}æ™‚é–“
  10ã‚¨ãƒãƒƒã‚¯æ¨å®š: {stats['total_training_time']/total_samples * 60000 * 10 / 3600:.1f}æ™‚é–“
        """
        
        return report
        
    def reset_performance_stats(self):
        """æ€§èƒ½çµ±è¨ˆãƒªã‚»ãƒƒãƒˆ"""
        self._initialize_performance_stats()
        self.ed_core.reset_stats()
        
    def summary(self):
        """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¦ç´„è¡¨ç¤º"""
        print("ğŸš€ é«˜é€ŸåŒ–ED-SNNãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¦ç´„")
        print("=" * 60)
        
        print(f"ğŸ“Š ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ :")
        print(f"  å…ƒæ§‹é€ : {self.network_structure}")
        print(f"  EDå…¥åŠ›ã‚µã‚¤ã‚º: {self.ed_input_size}")
        print(f"  èˆˆå¥®æ€§ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³: {self.n_excitatory}")
        print(f"  æŠ‘åˆ¶æ€§ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³: {self.n_inhibitory}")
        
        print(f"\nâš™ï¸ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š:")
        print(f"  æ™‚é–“: {self.simulation_time}ms")
        print(f"  åˆ»ã¿: {self.dt}ms")
        print(f"  é«˜é€ŸåŒ–: {self.use_fast_core}")
        
        print(f"\nğŸ“ˆ ç¾åœ¨ã®æ€§èƒ½:")
        if self.performance_stats['total_samples'] > 0:
            avg_time = self.performance_stats['total_training_time'] / self.performance_stats['total_samples']
            print(f"  å¹³å‡å­¦ç¿’æ™‚é–“: {avg_time:.3f}ç§’/ã‚µãƒ³ãƒ—ãƒ«")
            print(f"  å‡¦ç†æ¸ˆã¿ã‚µãƒ³ãƒ—ãƒ«: {self.performance_stats['total_samples']}")
            if self.performance_stats['accuracy_history']:
                recent_acc = np.mean(self.performance_stats['accuracy_history'][-10:])
                print(f"  æœ€æ–°ç²¾åº¦: {recent_acc*100:.1f}%")
        else:
            print(f"  ã¾ã å­¦ç¿’ã—ã¦ã„ã¾ã›ã‚“")

if __name__ == "__main__":
    # é«˜é€ŸåŒ–ãƒ†ã‚¹ãƒˆ
    print("ğŸš€ é«˜é€ŸåŒ–ED-SNNãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ v2 ãƒ†ã‚¹ãƒˆ")
    
    # å°è¦æ¨¡ãƒ†ã‚¹ãƒˆ
    network = EDSpikingNeuralNetworkFastV2(
        network_structure=[10, 5, 2],
        simulation_time=5.0,  # çŸ­ç¸®
        use_fast_core=True
    )
    
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    network.summary()
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
    test_input = np.random.rand(10) * 0.8
    test_target = np.array([1, 0])
    
    print(f"\nğŸ”„ å­¦ç¿’ãƒ†ã‚¹ãƒˆ:")
    start_time = time.time()
    result = network.train_step(test_input, test_target)
    end_time = time.time()
    
    print(f"  å®Ÿè¡Œæ™‚é–“: {end_time - start_time:.3f}ç§’")
    print(f"  å‡ºåŠ›: {result['outputs']}")
    print(f"  ç²¾åº¦: {result['accuracy']*100:.0f}%")
    print(f"  èª¤å·®: {result['error']:.4f}")
    
    print(f"\nğŸ“Š æ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆ:")
    print(network.get_performance_report())
    
    print(f"\nâœ… é«˜é€ŸåŒ–ED-SNNãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ v2 ãƒ†ã‚¹ãƒˆå®Œäº†")