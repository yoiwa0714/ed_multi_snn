# EDæ³•ã¨SNNå®Ÿè£…ã«ãŠã‘ã‚‹æŠ€è¡“è©³ç´°ã¨ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ è§£èª¬

ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã¯ã€`ed_multi_lif_snn.py`ã®å®Ÿè£…ã«ãŠã‘ã‚‹é‡è¦ãªæŠ€è¡“ãƒã‚¤ãƒ³ãƒˆã‚’ã€å®Ÿéš›ã®ã‚³ãƒ¼ãƒ‰ã‚’å¼•ç”¨ã—ãªãŒã‚‰è©³ç´°ã«è§£èª¬ã—ã¾ã™ã€‚

## ç›®æ¬¡

1. [EDæ³•ï¼ˆError-Diffusionæ³•ï¼‰ã®æ ¸å¿ƒå®Ÿè£…](#1-edæ³•error-diffusionæ³•ã®æ ¸å¿ƒå®Ÿè£…)
2. [LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãƒ¢ãƒ‡ãƒ«ã®å®Ÿè£…](#2-lifãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãƒ¢ãƒ‡ãƒ«ã®å®Ÿè£…)
3. [ã‚¹ãƒ‘ã‚¤ã‚¯ç¬¦å·åŒ–ã‚·ã‚¹ãƒ†ãƒ ](#3-ã‚¹ãƒ‘ã‚¤ã‚¯ç¬¦å·åŒ–ã‚·ã‚¹ãƒ†ãƒ )
4. [E/Iãƒšã‚¢æ§‹é€ ã¨Dale's Principle](#4-eiãƒšã‚¢æ§‹é€ ã¨dales-principle)
5. [ã‚¢ãƒŸãƒ³æ‹¡æ•£ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ](#5-ã‚¢ãƒŸãƒ³æ‹¡æ•£ãƒ¡ã‚«ãƒ‹ã‚ºãƒ )
6. [GPU/CPUæœ€é©åŒ–å®Ÿè£…](#6-gpucpuæœ€é©åŒ–å®Ÿè£…)
7. [å¤šå±¤ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£](#7-å¤šå±¤ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£)

---

## 1. EDæ³•ï¼ˆError-Diffusionæ³•ï¼‰ã®æ ¸å¿ƒå®Ÿè£…

### 1.1 é‡ã¿æ›´æ–°ã®åŸºæœ¬åŸç†

EDæ³•ã®æœ€ã‚‚é‡è¦ãªç‰¹å¾´ã¯ã€**èª¤å·®é€†ä¼æ’­æ³•ï¼ˆé€£é–å¾‹ï¼‰ã‚’ä½¿ç”¨ã—ãªã„**ç”Ÿç‰©å­¦çš„å­¦ç¿’ã§ã™ã€‚

```python
# å®Ÿéš›ã®EDæ³•é‡ã¿æ›´æ–°ã‚³ãƒ¼ãƒ‰ï¼ˆed_multi_lif_snn.py ã‚ˆã‚ŠæŠœç²‹ï¼‰
def update_weights_ed_method(self, layer_idx, amine_concentration, input_activity, output_error):
    """
    EDæ³•ã«ã‚ˆã‚‹é‡ã¿æ›´æ–° - é‡‘å­å‹‡æ°ã‚ªãƒªã‚¸ãƒŠãƒ«ç†è«–å®Œå…¨æº–æ‹ 
    
    ã€é‡è¦ã€‘: èª¤å·®é€†ä¼æ’­æ³•ãƒ»é€£é–å¾‹ã‚’ä¸€åˆ‡ä½¿ç”¨ã—ãªã„
    
    Args:
        amine_concentration: ã‚¢ãƒŸãƒ³æ¿ƒåº¦ï¼ˆèª¤å·®ä¿¡å·å¼·åº¦ï¼‰
        input_activity: å…¥åŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ´»æ€§
        output_error: å‡ºåŠ›èª¤å·®ä¿¡å·
    """
    # EDæ³•ã®æ ¸å¿ƒ: ã‚¢ãƒŸãƒ³æ¿ƒåº¦ Ã— å…¥åŠ›æ´»æ€§ Ã— å‡ºåŠ›èª¤å·®
    delta_w = self.learning_rate * amine_concentration * input_activity * output_error
    
    # Dale's Principleã‚’ç¶­æŒã—ãŸé‡ã¿æ›´æ–°
    self.weights[layer_idx] += delta_w
    
    # é‡ã¿ç¬¦å·åˆ¶ç´„ã®é©ç”¨ï¼ˆç”Ÿç‰©å­¦çš„å¦¥å½“æ€§ä¿æŒï¼‰
    self._apply_dales_principle_constraints(layer_idx)
    
    return delta_w
```

### 1.2 ã‚¢ãƒŸãƒ³æ¿ƒåº¦ã«ã‚ˆã‚‹å­¦ç¿’åˆ¶å¾¡

```python
# ã‚¢ãƒŸãƒ³æ¿ƒåº¦ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ï¼ˆed_multi_lif_snn.py ã‚ˆã‚ŠæŠœç²‹ï¼‰
class HyperParams:
    def __init__(self):
        # EDæ³•ã‚³ã‚¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆé‡‘å­å‹‡æ°ã‚ªãƒªã‚¸ãƒŠãƒ«ä»•æ§˜ï¼‰
        self.learning_rate = 0.1      # Î±: å­¦ç¿’ç‡
        self.initial_amine = 0.25     # Î²: åˆæœŸã‚¢ãƒŸãƒ³æ¿ƒåº¦
        self.diffusion_rate = 0.5     # u1: ã‚¢ãƒŸãƒ³æ‹¡æ•£ä¿‚æ•°
        self.sigmoid_threshold = 1.2  # u0: ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¾å€¤

def calculate_amine_concentration(self, output_error, layer_depth):
    """
    ã‚¢ãƒŸãƒ³æ¿ƒåº¦è¨ˆç®— - ç”Ÿç‰©å­¦çš„ãªèª¤å·®ä¿¡å·ä¼æ’­
    
    ã€é‡è¦ã€‘: å„å±¤ãŒç‹¬ç«‹ã—ã¦ã‚¢ãƒŸãƒ³æ¿ƒåº¦ã«åŸºã¥ãå­¦ç¿’ã‚’å®Ÿè¡Œ
    """
    # åˆæœŸã‚¢ãƒŸãƒ³æ¿ƒåº¦ã‹ã‚‰å±¤ã®æ·±ã•ã«å¿œã˜ã¦æ‹¡æ•£
    amine = self.initial_amine * (self.diffusion_rate ** layer_depth)
    
    # å‡ºåŠ›èª¤å·®ã®å¼·åº¦ã«æ¯”ä¾‹
    amine_concentration = amine * abs(output_error)
    
    return amine_concentration
```

**æŠ€è¡“çš„æ„ç¾©:**
- å„å±¤ãŒ**ç‹¬ç«‹ã—ãŸå­¦ç¿’ä¿¡å·**ã‚’å—ã‘å–ã‚‹
- **ä¸¦åˆ—è¨ˆç®—ãŒå¯èƒ½**ï¼ˆå±¤é–“ã®ä¾å­˜é–¢ä¿‚ãªã—ï¼‰
- **å‹¾é…æ¶ˆå¤±å•é¡ŒãŒç™ºç”Ÿã—ãªã„**ï¼ˆé€£é–å¾‹ä¸ä½¿ç”¨ï¼‰

---

## 2. LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãƒ¢ãƒ‡ãƒ«ã®å®Ÿè£…

### 2.1 è†œé›»ä½ã®æ™‚é–“ç™ºå±•

```python
# LIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®è†œé›»ä½è¨ˆç®—ï¼ˆmodules/snn/lif_neuron.py ã‚ˆã‚ŠæŠœç²‹ï¼‰
def update_membrane_potential(self, v_current, i_syn, dt):
    """
    LIFï¼ˆLeaky Integrate-and-Fireï¼‰ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®è†œé›»ä½æ›´æ–°
    
    å¾®åˆ†æ–¹ç¨‹å¼: dV/dt = (V_rest - V + I_syn) / Ï„_m
    """
    # è†œé›»ä½ã®æ™‚é–“ç™ºå±•ï¼ˆ1æ¬¡ç·šå½¢å¾®åˆ†æ–¹ç¨‹å¼ï¼‰
    dv_dt = (self.v_rest - v_current + i_syn) / self.tau_m
    v_new = v_current + dv_dt * dt
    
    # ç™ºç«åˆ¤å®š
    if v_new >= self.v_threshold:
        # ã‚¹ãƒ‘ã‚¤ã‚¯ç™ºç« â†’ ãƒªã‚»ãƒƒãƒˆé›»ä½ã«è¨­å®š
        v_new = self.v_reset
        spike = True
        # ä¸å¿œæœŸã®é–‹å§‹
        self.refractory_timer = self.tau_ref
    else:
        spike = False
    
    return v_new, spike

# LIFãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ç‰©ç†çš„æ„å‘³
class LIFNeuronParameters:
    def __init__(self):
        self.v_rest = -65.0      # é™æ­¢è†œé›»ä½ (mV) - ç¥çµŒç´°èƒã®åŸºæº–é›»ä½
        self.v_threshold = -60.0 # ç™ºç«é–¾å€¤ (mV) - ã‚¹ãƒ‘ã‚¤ã‚¯ç™ºç”Ÿã®é›»ä½
        self.v_reset = -70.0     # ãƒªã‚»ãƒƒãƒˆé›»ä½ (mV) - ç™ºç«å¾Œã®é›»ä½
        self.tau_m = 20.0        # è†œæ™‚å®šæ•° (ms) - é›»ä½æ¸›è¡°ã®æ™‚å®šæ•°
        self.tau_ref = 2.0       # ä¸å¿œæœŸ (ms) - ç™ºç«ä¸èƒ½æ™‚é–“
        self.R_m = 10.0          # è†œæŠµæŠ— (MÎ©) - é›»æµ-é›»åœ§é–¢ä¿‚
```

### 2.2 å…¨å±¤LIFåŒ–ã®å®Ÿè£…

```python
# å…¨å±¤LIFåŒ–ã‚·ã‚¹ãƒ†ãƒ ï¼ˆed_multi_lif_snn.py ã‚ˆã‚ŠæŠœç²‹ï¼‰
def forward_pass_with_lif(self, input_data):
    """
    å…¨å±¤LIFåŒ–ã«ã‚ˆã‚‹é †ä¼æ’­
    
    ã€é‡è¦ã€‘: å…¥åŠ›å±¤ãƒ»éš ã‚Œå±¤ãƒ»å‡ºåŠ›å±¤ã™ã¹ã¦ãŒLIFãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³
    """
    current_activity = input_data
    
    # å…¥åŠ›å±¤: ãƒã‚¢ã‚½ãƒ³ç¬¦å·åŒ– â†’ LIFã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    if self.use_input_lif:
        spike_trains = self._spike_encode(
            input_data, 
            method=self.spike_encoding_method,
            max_rate=self.spike_max_rate,
            simulation_time=self.spike_simulation_time,
            dt=self.spike_dt
        )
        current_activity = self._lif_activation_input_layer(spike_trains)
    
    # éš ã‚Œå±¤: LIFæ´»æ€§åŒ–é–¢æ•°
    for layer_idx, layer_size in enumerate(self.hidden_sizes):
        # é‡ã¿ä»˜ãå…¥åŠ›è¨ˆç®—
        weighted_input = self.xp.dot(self.weights[layer_idx], current_activity)
        
        # LIFæ´»æ€§åŒ–ï¼ˆã‚·ã‚°ãƒ¢ã‚¤ãƒ‰ã®ä»£æ›¿ï¼‰
        current_activity = self._lif_activation(
            weighted_input, 
            layer_size, 
            self.neuron_types[layer_idx],
            simulation_time=self.simulation_time,
            dt=self.dt
        )
    
    # å‡ºåŠ›å±¤: LIFæ´»æ€§åŒ–
    output_activity = self._lif_activation(
        final_weighted_input,
        self.output_size,
        self.output_neuron_types,
        simulation_time=self.simulation_time,
        dt=self.dt
    )
    
    return output_activity
```

**æŠ€è¡“çš„æ„ç¾©:**
- **å®Œå…¨ãªã‚¹ãƒ‘ã‚¤ã‚­ãƒ³ã‚°ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯**ã®å®Ÿç¾
- **æ™‚é–“çš„ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹**ã®å°å…¥
- **ç”Ÿç‰©å­¦çš„ãƒªã‚¢ãƒªã‚ºãƒ **ã®æœ€å¤§åŒ–

---

## 3. ã‚¹ãƒ‘ã‚¤ã‚¯ç¬¦å·åŒ–ã‚·ã‚¹ãƒ†ãƒ 

### 3.1 ãƒã‚¢ã‚½ãƒ³ç¬¦å·åŒ–ï¼ˆæ¨å¥¨æ‰‹æ³•ï¼‰

```python
# ãƒã‚¢ã‚½ãƒ³ç¬¦å·åŒ–å®Ÿè£…ï¼ˆed_multi_lif_snn.py ã‚ˆã‚ŠæŠœç²‹ï¼‰
def _poisson_encode(self, pixel_values, max_rate=150.0, simulation_time=50.0, dt=1.0):
    """
    ãƒã‚¢ã‚½ãƒ³ç¬¦å·åŒ– - ç”Ÿç‰©å­¦çš„ã«æœ€ã‚‚å¦¥å½“ãªã‚¹ãƒ‘ã‚¤ã‚¯ç¬¦å·åŒ–
    
    ã€åŸç†ã€‘: ç”»ç´ å€¤ã«æ¯”ä¾‹ã—ãŸç™ºç«ç‡ã§ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚¹ãƒ‘ã‚¤ã‚¯ã‚’ç”Ÿæˆ
    ã€åˆ©ç‚¹ã€‘: ãƒã‚¤ã‚ºè€æ€§ã€ç”Ÿç‰©å­¦çš„å¦¥å½“æ€§
    """
    n_neurons = len(pixel_values)
    n_timesteps = int(simulation_time / dt)
    
    # GPUæœ€é©åŒ–: ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸãƒã‚¢ã‚½ãƒ³éç¨‹
    if self.use_gpu:
        # ç™ºç«ç‡è¨ˆç®— [n_neurons]
        rates = self.xp.asarray(pixel_values) * max_rate
        
        # ç™ºç«ç¢ºç‡è¨ˆç®— [n_neurons]
        probs = rates * dt / 1000.0  # Hz â†’ ç¢ºç‡å¤‰æ›
        
        # ä¸€æ‹¬ä¹±æ•°ç”Ÿæˆ [n_timesteps, n_neurons]
        random_vals = self.xp.random.random((n_timesteps, n_neurons))
        
        # ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚¹ãƒ‘ã‚¤ã‚¯åˆ¤å®š
        spike_trains = random_vals < probs[self.xp.newaxis, :]
    
    return spike_trains

# E/Iãƒšã‚¢åŒ–å‡¦ç†
def _apply_ei_pairing(self, spike_trains):
    """
    E/Iãƒšã‚¢æ§‹é€ ã®é©ç”¨
    
    ã€é‡è¦ã€‘: 784ãƒ”ã‚¯ã‚»ãƒ« â†’ 1568ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ï¼ˆèˆˆå¥®æ€§784 + æŠ‘åˆ¶æ€§784ï¼‰
    """
    n_timesteps, n_pixels = spike_trains.shape
    
    # GPUæœ€é©åŒ–: stack()ã«ã‚ˆã‚‹é«˜é€Ÿãƒšã‚¢åŒ–
    spike_trains_paired = self.xp.stack([spike_trains, spike_trains], axis=2)
    spike_trains_paired = spike_trains_paired.reshape(n_timesteps, n_pixels * 2)
    
    return spike_trains_paired  # [n_timesteps, 1568]
```

### 3.2 ãƒ¬ãƒ¼ãƒˆç¬¦å·åŒ–ã¨ãƒ†ãƒ³ãƒãƒ©ãƒ«ç¬¦å·åŒ–

```python
# ãƒ¬ãƒ¼ãƒˆç¬¦å·åŒ–ï¼ˆæ±ºå®šè«–çš„ï¼‰
def _rate_encode(self, pixel_values, max_rate=150.0, simulation_time=50.0, dt=1.0):
    """
    ãƒ¬ãƒ¼ãƒˆç¬¦å·åŒ– - è¦å‰‡çš„ãªã‚¹ãƒ‘ã‚¤ã‚¯ç”Ÿæˆ
    
    ã€ç”¨é€”ã€‘: ãƒ‡ãƒãƒƒã‚°ã€å†ç¾æ€§ãŒå¿…è¦ãªå®Ÿé¨“
    """
    rates = self.xp.asarray(pixel_values) * max_rate
    intervals = self.xp.where(rates > 0, 1000.0 / rates, self.xp.inf)
    
    # è¦å‰‡çš„ãªã‚¹ãƒ‘ã‚¤ã‚¯ç”Ÿæˆ
    for i in range(n_neurons):
        if rates[i] > 0:
            interval = float(intervals[i])
            spike_times = self.xp.arange(interval, simulation_time, interval)
            spike_indices = (spike_times / dt).astype(int)
            spike_trains[spike_indices, i] = True

# ãƒ†ãƒ³ãƒãƒ©ãƒ«ç¬¦å·åŒ–ï¼ˆæ™‚é–“æƒ…å ±åˆ©ç”¨ï¼‰
def _temporal_encode(self, pixel_values, simulation_time=50.0, dt=1.0):
    """
    ãƒ†ãƒ³ãƒãƒ©ãƒ«ç¬¦å·åŒ– - ç”»ç´ å€¤ãŒå¤§ãã„ã»ã©æ—©ãç™ºç«
    
    ã€ç‰¹å¾´ã€‘: æ™‚é–“æƒ…å ±ã‚’åˆ©ç”¨ã€å„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯1å›ã®ã¿ç™ºç«
    """
    # ç™ºç«æ™‚åˆ»è¨ˆç®—ï¼ˆé€†æ¯”ä¾‹ï¼‰
    spike_times_ms = self.xp.where(
        self.xp.asarray(pixel_values) > 0,
        simulation_time * (1.0 - self.xp.asarray(pixel_values)),
        self.xp.inf
    )
    
    return spike_trains
```

**æŠ€è¡“çš„æ„ç¾©:**
- **ã‚¢ãƒŠãƒ­ã‚°â†’ã‚¹ãƒ‘ã‚¤ã‚¯å¤‰æ›**ã®æŸ”è»Ÿæ€§
- **æ™‚é–“æƒ…å ±ã®åŠ¹æœçš„åˆ©ç”¨**
- **ãƒã‚¤ã‚ºè€æ€§**ã®å‘ä¸Š

---

## 4. E/Iãƒšã‚¢æ§‹é€ ã¨Dale's Principle

### 4.1 ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚¿ã‚¤ãƒ—ã®åˆæœŸåŒ–

```python
# Dale's Principleå®Ÿè£…ï¼ˆed_multi_lif_snn.py ã‚ˆã‚ŠæŠœç²‹ï¼‰
def _initialize_neuron_types(self):
    """
    ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚¿ã‚¤ãƒ—åˆæœŸåŒ– - é‡‘å­å‹‡æ°ã®Cã‚³ãƒ¼ãƒ‰å®Œå…¨æº–æ‹ 
    
    Cã‚³ãƒ¼ãƒ‰: ow[k] = ((k+1) % 2) * 2 - 1
    - ow[0] = 1  (èˆˆå¥®æ€§)
    - ow[1] = -1 (æŠ‘åˆ¶æ€§)
    - ow[2] = 1  (èˆˆå¥®æ€§)
    - ow[3] = -1 (æŠ‘åˆ¶æ€§)
    """
    # å…¥åŠ›å±¤: 1568å€‹ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚¿ã‚¤ãƒ—ï¼ˆèˆˆå¥®æ€§/æŠ‘åˆ¶æ€§äº¤äº’ï¼‰
    self.input_neuron_types = np.ones(self.input_units)
    for i in range(1, self.input_units, 2):
        self.input_neuron_types[i] = -1  # æŠ‘åˆ¶æ€§
    
    # éš ã‚Œå±¤: åŒæ§˜ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
    self.hidden_neuron_types = []
    for size in self.hidden_sizes:
        types = np.ones(size)
        for i in range(1, size, 2):
            types[i] = -1
        self.hidden_neuron_types.append(types)

def _apply_dales_principle(self):
    """
    Dale's Principleé©ç”¨ - é‡ã¿ç¬¦å·åˆ¶ç´„
    
    ã€åŸç†ã€‘: w *= ow[source] * ow[target]
    - åŒç¨®é–“çµåˆï¼ˆEâ†’E, Iâ†’Iï¼‰: æ­£ã®é‡ã¿
    - ç•°ç¨®é–“çµåˆï¼ˆEâ†’I, Iâ†’Eï¼‰: è² ã®é‡ã¿
    """
    for n in range(self.output_units):
        # GPUæœ€é©åŒ–: ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸãƒã‚¹ã‚¯æ¼”ç®—
        if self.use_gpu:
            src_types = self.xp.asarray(self.input_neuron_types).reshape(1, -1)
            dst_types = self.xp.asarray(self.hidden_neuron_types[0]).reshape(-1, 1)
            mask = src_types * dst_types
            self.layer_weights[n][0] *= mask
        else:
            # CPUç‰ˆ: æ˜ç¤ºçš„ãƒ«ãƒ¼ãƒ—
            for i in range(self.hidden_sizes[0]):
                dst_type = self.hidden_neuron_types[0][i]
                for j in range(self.input_units):
                    src_type = self.input_neuron_types[j]
                    self.layer_weights[n][0][i, j] *= src_type * dst_type
```

### 4.2 E/Iãƒšã‚¢æ§‹é€ ã®ç‰©ç†çš„æ„å‘³

```python
# E/Iãƒšã‚¢æ§‹é€ ã®æ¦‚å¿µå®Ÿè£…
class EINetwork:
    """
    E/Iãƒšã‚¢æ§‹é€ ã«ã‚ˆã‚‹ç”Ÿç‰©å­¦çš„å¦¥å½“æ€§
    
    ã€ç‰©ç†çš„æ„å‘³ã€‘:
    - å„ç”»ç´ ã«å¯¾ã—ã¦èˆˆå¥®æ€§ãƒ»æŠ‘åˆ¶æ€§ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®ãƒšã‚¢ãŒå­˜åœ¨
    - MNIST: 784ãƒ”ã‚¯ã‚»ãƒ« â†’ 1568ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ï¼ˆ784ãƒšã‚¢ï¼‰
    - èˆˆå¥®æ€§: æ­£ã®ä¿¡å·ä¼é”
    - æŠ‘åˆ¶æ€§: è² ã®ä¿¡å·ä¼é”ï¼ˆæŠ‘åˆ¶åŠ¹æœï¼‰
    """
    
    def create_ei_structure(self, pixel_values):
        """784ãƒ”ã‚¯ã‚»ãƒ« â†’ 1568ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¸ã®å¤‰æ›"""
        n_pixels = len(pixel_values)
        ei_activity = np.zeros(n_pixels * 2)
        
        for i in range(n_pixels):
            # èˆˆå¥®æ€§ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ï¼ˆå¶æ•°ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰
            ei_activity[2*i] = pixel_values[i]
            # æŠ‘åˆ¶æ€§ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ï¼ˆå¥‡æ•°ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰
            ei_activity[2*i + 1] = pixel_values[i]
        
        return ei_activity
    
    def apply_dale_constraint(self, weights, source_types, target_types):
        """Dale's Principleåˆ¶ç´„ã®é©ç”¨"""
        for i in range(len(target_types)):
            for j in range(len(source_types)):
                # é‡ã¿ç¬¦å· = é€ä¿¡å…ƒã‚¿ã‚¤ãƒ— Ã— å—ä¿¡å…ˆã‚¿ã‚¤ãƒ—
                sign_constraint = source_types[j] * target_types[i]
                weights[i, j] *= sign_constraint
        
        return weights
```

**æŠ€è¡“çš„æ„ç¾©:**
- **ç”Ÿç‰©å­¦çš„å¦¥å½“æ€§**ã®ä¿è¨¼
- **èˆˆå¥®ãƒ»æŠ‘åˆ¶ãƒãƒ©ãƒ³ã‚¹**ã®è‡ªç„¶ãªå®Ÿç¾
- **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å®‰å®šæ€§**ã®å‘ä¸Š

---

## 5. ã‚¢ãƒŸãƒ³æ‹¡æ•£ãƒ¡ã‚«ãƒ‹ã‚ºãƒ 

### 5.1 å±¤é–“ã‚¢ãƒŸãƒ³æ‹¡æ•£ã®å®Ÿè£…

```python
# ã‚¢ãƒŸãƒ³æ‹¡æ•£ã‚·ã‚¹ãƒ†ãƒ ï¼ˆed_multi_lif_snn.py ã‚ˆã‚ŠæŠœç²‹ï¼‰
def calculate_layer_amine_concentrations(self, output_errors):
    """
    å±¤é–“ã‚¢ãƒŸãƒ³æ‹¡æ•£è¨ˆç®— - EDæ³•ã®æ ¸å¿ƒãƒ¡ã‚«ãƒ‹ã‚ºãƒ 
    
    ã€é‡è¦ã€‘: å‡ºåŠ›å±¤ã‹ã‚‰å„éš ã‚Œå±¤ã¸ã®æ‹¡æ•£å‹èª¤å·®ä¿¡å·ä¼æ’­
    """
    amine_concentrations = []
    
    # å‡ºåŠ›å±¤ã®ã‚¢ãƒŸãƒ³æ¿ƒåº¦ï¼ˆåˆæœŸå€¤ï¼‰
    output_amine = self.initial_amine * abs(output_errors)
    
    # éš ã‚Œå±¤ã¸ã®æ‹¡æ•£ï¼ˆå±¤ã®æ·±ã•ã«å¿œã˜ã¦æ¸›è¡°ï¼‰
    for layer_depth in range(len(self.hidden_sizes)):
        # æ‹¡æ•£ä¿‚æ•°ã«ã‚ˆã‚‹æ¸›è¡°
        layer_amine = output_amine * (self.diffusion_rate ** (layer_depth + 1))
        amine_concentrations.append(layer_amine)
    
    return amine_concentrations

def update_weights_with_amine_diffusion(self, layer_idx, input_activity, output_error):
    """
    ã‚¢ãƒŸãƒ³æ‹¡æ•£ã«ã‚ˆã‚‹é‡ã¿æ›´æ–°
    
    ã€ç‰¹å¾´ã€‘: å„å±¤ãŒç‹¬ç«‹ã—ãŸå­¦ç¿’ä¿¡å·ã‚’å—ä¿¡
    """
    # ãã®å±¤ã®ã‚¢ãƒŸãƒ³æ¿ƒåº¦ã‚’å–å¾—
    amine_concentration = self.layer_amine_concentrations[layer_idx]
    
    # EDæ³•é‡ã¿æ›´æ–°: Î± Ã— ã‚¢ãƒŸãƒ³ Ã— å…¥åŠ› Ã— èª¤å·®
    delta_w = (self.learning_rate * 
               amine_concentration * 
               input_activity * 
               output_error)
    
    # é‡ã¿æ›´æ–°å®Ÿè¡Œ
    self.weights[layer_idx] += delta_w
    
    return delta_w
```

### 5.2 ç”Ÿç‰©å­¦çš„å­¦ç¿’ã®ä¸¦åˆ—æ€§

```python
# ä¸¦åˆ—å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã®æ¦‚å¿µå®Ÿè£…
class ParallelLearningSystem:
    """
    EDæ³•ã«ã‚ˆã‚‹ä¸¦åˆ—å­¦ç¿’ã®å®Ÿç¾
    
    ã€é‡è¦ã€‘: èª¤å·®é€†ä¼æ’­ã¨ã¯ç•°ãªã‚Šã€å„å±¤ãŒåŒæ™‚ã«å­¦ç¿’å¯èƒ½
    """
    
    def parallel_weight_update(self, all_layer_inputs, all_layer_errors):
        """
        å…¨å±¤åŒæ™‚é‡ã¿æ›´æ–° - EDæ³•ã®æœ€å¤§ã®åˆ©ç‚¹
        
        ã€èª¤å·®é€†ä¼æ’­ã¨ã®é•ã„ã€‘:
        - èª¤å·®é€†ä¼æ’­: å‡ºåŠ›å±¤â†’éš ã‚Œå±¤ã®é †æ¬¡è¨ˆç®—ãŒå¿…è¦
        - EDæ³•: å…¨å±¤ãŒç‹¬ç«‹ã—ãŸã‚¢ãƒŸãƒ³æ¿ƒåº¦ã§åŒæ™‚å­¦ç¿’
        """
        weight_updates = []
        
        # å…¨å±¤ã‚’ä¸¦åˆ—ã§å‡¦ç†ï¼ˆä¾å­˜é–¢ä¿‚ãªã—ï¼‰
        for layer_idx in range(len(self.layers)):
            # å„å±¤ãŒç‹¬ç«‹ã—ã¦ã‚¢ãƒŸãƒ³æ¿ƒåº¦ã‚’æŒã¤
            layer_amine = self.calculate_layer_amine(layer_idx)
            
            # ä¸¦åˆ—ã§é‡ã¿æ›´æ–°ã‚’è¨ˆç®—
            delta_w = self.calculate_weight_update(
                layer_idx, 
                all_layer_inputs[layer_idx],
                all_layer_errors[layer_idx],
                layer_amine
            )
            
            weight_updates.append(delta_w)
        
        # åŒæ™‚ã«å…¨å±¤ã®é‡ã¿ã‚’æ›´æ–°
        self.apply_weight_updates(weight_updates)
        
        return weight_updates
```

**æŠ€è¡“çš„æ„ç¾©:**
- **çœŸã®ä¸¦åˆ—è¨ˆç®—**ãŒå¯èƒ½
- **å‹¾é…æ¶ˆå¤±å•é¡Œã®æ ¹æœ¬çš„è§£æ±º**
- **æ·±ã„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ã®å®‰å®šå­¦ç¿’**

---

## 6. GPU/CPUæœ€é©åŒ–å®Ÿè£…

### 6.1 è‡ªå‹•GPUæ¤œå‡ºã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

```python
# GPU/CPUè‡ªå‹•åˆ‡ã‚Šæ›¿ãˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆed_multi_lif_snn.py ã‚ˆã‚ŠæŠœç²‹ï¼‰
try:
    import cupy as cp
    xp = cp  # NumPyäº’æ›ã®é…åˆ—ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
    GPU_AVAILABLE = True
    print("ğŸš€ GPUï¼ˆCuPyï¼‰ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
    print(f"   ãƒ‡ãƒã‚¤ã‚¹: {cp.cuda.Device().compute_capability}")
except ImportError:
    import numpy as np
    xp = np  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: NumPyã‚’ä½¿ç”¨
    GPU_AVAILABLE = False
    print("â„¹ï¸  GPUæœªæ¤œå‡ºã€‚CPUï¼ˆNumPyï¼‰ã§å®Ÿè¡Œã—ã¾ã™")

class OptimizedEDCore:
    def __init__(self, force_cpu=False):
        """GPU/CPUå®Ÿè¡Œã®é¸æŠ"""
        self.use_gpu = GPU_AVAILABLE and not force_cpu
        self.xp = np if force_cpu else xp
        
        if self.use_gpu:
            print("ğŸš€ EDæ³•ã‚³ã‚¢: GPUï¼ˆCuPyï¼‰ã§åˆæœŸåŒ–")
        elif force_cpu and GPU_AVAILABLE:
            print("ğŸ”§ EDæ³•ã‚³ã‚¢: CPUå¼·åˆ¶å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ï¼ˆ--cpuã‚ªãƒ—ã‚·ãƒ§ãƒ³æŒ‡å®šï¼‰")
        else:
            print("ğŸ’» EDæ³•ã‚³ã‚¢: CPUï¼ˆNumPyï¼‰ã§åˆæœŸåŒ–")
```

### 6.2 ãƒ™ã‚¯ãƒˆãƒ«åŒ–æ¼”ç®—ã®æœ€é©åŒ–

```python
# ãƒ™ã‚¯ãƒˆãƒ«åŒ–æ¼”ç®—å®Ÿè£…ï¼ˆed_multi_lif_snn.py ã‚ˆã‚ŠæŠœç²‹ï¼‰
def vectorized_weight_update(self, inputs, outputs, errors):
    """
    ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã«ã‚ˆã‚‹é«˜é€Ÿé‡ã¿æ›´æ–°
    
    ã€æœ€é©åŒ–ãƒã‚¤ãƒ³ãƒˆã€‘:
    - è¡Œåˆ—æ¼”ç®—ã«ã‚ˆã‚‹ä¸€æ‹¬å‡¦ç†
    - GPUä¸¦åˆ—è¨ˆç®—ã®æ´»ç”¨
    - ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹ã®æœ€é©åŒ–
    """
    if self.use_gpu:
        # GPUä¸Šã§ã®è¡Œåˆ—æ¼”ç®—
        # å…¥åŠ›ã‚’GPUãƒ¡ãƒ¢ãƒªã«è»¢é€
        inputs_gpu = self.xp.asarray(inputs)
        errors_gpu = self.xp.asarray(errors)
        
        # ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸé‡ã¿æ›´æ–°è¨ˆç®—
        # å¤–ç©ã«ã‚ˆã‚‹ä¸€æ‹¬è¨ˆç®—: Î”w = Î± Ã— amine Ã— (error âŠ— input)
        delta_weights = (self.learning_rate * 
                        self.amine_concentration * 
                        self.xp.outer(errors_gpu, inputs_gpu))
        
        # GPUä¸Šã§é‡ã¿æ›´æ–°
        self.weights += delta_weights
        
    else:
        # CPUç‰ˆ: NumPyã®æœ€é©åŒ–ã•ã‚ŒãŸè¡Œåˆ—æ¼”ç®—
        delta_weights = (self.learning_rate * 
                        self.amine_concentration * 
                        np.outer(errors, inputs))
        self.weights += delta_weights

def gpu_memory_management(self):
    """GPU ãƒ¡ãƒ¢ãƒªç®¡ç†"""
    if self.use_gpu:
        # ä¸è¦ãªGPUãƒ¡ãƒ¢ãƒªã®è§£æ”¾
        cp.get_default_memory_pool().free_all_blocks()
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç›£è¦–
        mempool = cp.get_default_memory_pool()
        print(f"GPU Memory: {mempool.used_bytes() / 1024**2:.1f}MB used")
```

### 6.3 CPUå¼·åˆ¶å®Ÿè¡Œã‚ªãƒ—ã‚·ãƒ§ãƒ³

```python
# CPUå¼·åˆ¶å®Ÿè¡Œæ©Ÿèƒ½ï¼ˆed_multi_lif_snn.py ã‚ˆã‚ŠæŠœç²‹ï¼‰
def setup_compute_backend(self, force_cpu=False):
    """
    è¨ˆç®—ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®è¨­å®š
    
    ã€ç”¨é€”ã€‘:
    - ãƒ‡ãƒãƒƒã‚°ï¼ˆCPUçµæœã¨ã®æ¯”è¼ƒï¼‰
    - GPU/CPUæ€§èƒ½æ¯”è¼ƒ
    - ãƒ¡ãƒ¢ãƒªåˆ¶ç´„å›é¿
    """
    if force_cpu:
        # GPUç’°å¢ƒã§ã‚‚CPUå¼·åˆ¶å®Ÿè¡Œ
        self.xp = np
        self.use_gpu = False
        print("ğŸ”§ CPUå¼·åˆ¶å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰: GPUç’°å¢ƒã§ã‚‚NumPyã‚’ä½¿ç”¨")
    elif GPU_AVAILABLE:
        # GPUåˆ©ç”¨å¯èƒ½æ™‚ã¯è‡ªå‹•é¸æŠ
        self.xp = cp
        self.use_gpu = True
        print("ğŸš€ GPUè‡ªå‹•æ¤œå‡º: CuPyã‚’ä½¿ç”¨")
    else:
        # GPUåˆ©ç”¨ä¸å¯æ™‚ã¯CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        self.xp = np
        self.use_gpu = False
        print("ğŸ’» CPUå®Ÿè¡Œ: NumPyã‚’ä½¿ç”¨")

# å®Ÿè¡Œæ™‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ
def benchmark_compute_backends(self):
    """CPU/GPUæ€§èƒ½æ¯”è¼ƒ"""
    # CPUå®Ÿè¡Œæ™‚é–“æ¸¬å®š
    start_time = time.time()
    self.setup_compute_backend(force_cpu=True)
    cpu_result = self.run_training_epoch()
    cpu_time = time.time() - start_time
    
    # GPUå®Ÿè¡Œæ™‚é–“æ¸¬å®šï¼ˆåˆ©ç”¨å¯èƒ½æ™‚ï¼‰
    if GPU_AVAILABLE:
        start_time = time.time()
        self.setup_compute_backend(force_cpu=False)
        gpu_result = self.run_training_epoch()
        gpu_time = time.time() - start_time
        
        speedup = cpu_time / gpu_time
        print(f"GPUé«˜é€ŸåŒ–: {speedup:.2f}å€ ({cpu_time:.2f}s â†’ {gpu_time:.2f}s)")
```

**æŠ€è¡“çš„æ„ç¾©:**
- **æŸ”è»Ÿãªå®Ÿè¡Œç’°å¢ƒ**ã®æä¾›
- **ãƒ‡ãƒãƒƒã‚°ãƒ»æ€§èƒ½è§£æ**ã®æ”¯æ´
- **ç•°ãªã‚‹ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢**ã¸ã®å¯¾å¿œ

---

## 7. å¤šå±¤ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### 7.1 å‹•çš„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰

```python
# å¤šå±¤ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰ï¼ˆed_multi_lif_snn.py ã‚ˆã‚ŠæŠœç²‹ï¼‰
class MultiLayerEDNetwork:
    def __init__(self, input_size, hidden_sizes, output_size):
        """
        å‹•çš„å¤šå±¤ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æ§‹ç¯‰
        
        ã€ç‰¹å¾´ã€‘:
        - ä»»æ„ã®éš ã‚Œå±¤æ•°ã«å¯¾å¿œ
        - å„å±¤ã®ç‹¬ç«‹ã—ãŸé‡ã¿ç®¡ç†
        - ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
        """
        self.input_size = input_size      # 1568 (E/Iãƒšã‚¢)
        self.hidden_sizes = hidden_sizes  # [256, 128, 64] ãªã©
        self.output_size = output_size    # 10 (MNIST/Fashion-MNIST)
        
        # å±¤æ§‹é€ ã®å‹•çš„ç”Ÿæˆ
        self.layer_weights = self._build_layer_weights()
        self.layer_biases = self._build_layer_biases()
        self.neuron_types = self._build_neuron_types()
    
    def _build_layer_weights(self):
        """é‡ã¿è¡Œåˆ—ã®å‹•çš„ç”Ÿæˆ"""
        weights = []
        
        # å…¥åŠ›å±¤ â†’ ç¬¬1éš ã‚Œå±¤
        w1 = self._initialize_weights(self.hidden_sizes[0], self.input_size)
        weights.append(w1)
        
        # éš ã‚Œå±¤é–“ã®é‡ã¿
        for i in range(len(self.hidden_sizes) - 1):
            w_hidden = self._initialize_weights(
                self.hidden_sizes[i+1], 
                self.hidden_sizes[i]
            )
            weights.append(w_hidden)
        
        # æœ€çµ‚éš ã‚Œå±¤ â†’ å‡ºåŠ›å±¤
        w_output = self._initialize_weights(self.output_size, self.hidden_sizes[-1])
        weights.append(w_output)
        
        return weights
    
    def forward_pass_multilayer(self, input_data):
        """å¤šå±¤é †ä¼æ’­ã®å®Ÿè£…"""
        current_activity = input_data
        layer_activities = [current_activity]
        
        # å„éš ã‚Œå±¤ã®å‡¦ç†
        for layer_idx, layer_size in enumerate(self.hidden_sizes):
            # é‡ã¿ä»˜ãå…¥åŠ›
            weighted_input = self.xp.dot(self.layer_weights[layer_idx], current_activity)
            
            # LIFæ´»æ€§åŒ–
            current_activity = self._lif_activation(
                weighted_input, 
                layer_size,
                self.neuron_types[layer_idx]
            )
            
            layer_activities.append(current_activity)
        
        # å‡ºåŠ›å±¤å‡¦ç†
        final_weighted_input = self.xp.dot(self.layer_weights[-1], current_activity)
        output_activity = self._lif_activation(
            final_weighted_input,
            self.output_size,
            self.output_neuron_types
        )
        
        layer_activities.append(output_activity)
        return output_activity, layer_activities
```

### 7.2 éšå±¤çš„EDå­¦ç¿’

```python
# éšå±¤çš„å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ï¼ˆed_multi_lif_snn.py ã‚ˆã‚ŠæŠœç²‹ï¼‰
def hierarchical_ed_learning(self, input_batch, target_batch):
    """
    éšå±¤çš„EDå­¦ç¿’ã®å®Ÿè£…
    
    ã€åŸç†ã€‘: å„å±¤ãŒç‹¬ç«‹ã—ãŸã‚¢ãƒŸãƒ³æ¿ƒåº¦ã§å­¦ç¿’
    ã€åˆ©ç‚¹ã€‘: å±¤æ•°ã«é–¢ä¿‚ãªãå®‰å®šã—ãŸå­¦ç¿’
    """
    batch_size = len(input_batch)
    total_error = 0.0
    
    for sample_idx in range(batch_size):
        # é †ä¼æ’­
        output, layer_activities = self.forward_pass_multilayer(input_batch[sample_idx])
        
        # å‡ºåŠ›èª¤å·®è¨ˆç®—
        target = target_batch[sample_idx]
        output_error = target - output
        total_error += np.sum(output_error ** 2)
        
        # å„å±¤ã®ã‚¢ãƒŸãƒ³æ¿ƒåº¦è¨ˆç®—
        layer_amines = self._calculate_hierarchical_amines(output_error)
        
        # å…¨å±¤åŒæ™‚é‡ã¿æ›´æ–°ï¼ˆEDæ³•ã®ç‰¹å¾´ï¼‰
        for layer_idx in range(len(self.layer_weights)):
            # è©²å½“å±¤ã®å…¥åŠ›ã¨å‡ºåŠ›ã‚’å–å¾—
            layer_input = layer_activities[layer_idx]
            layer_output = layer_activities[layer_idx + 1]
            layer_amine = layer_amines[layer_idx]
            
            # EDæ³•é‡ã¿æ›´æ–°
            self._update_layer_weights_ed(
                layer_idx, 
                layer_input, 
                layer_output, 
                output_error,
                layer_amine
            )
    
    return total_error / batch_size

def _calculate_hierarchical_amines(self, output_error):
    """éšå±¤çš„ã‚¢ãƒŸãƒ³æ¿ƒåº¦ã®è¨ˆç®—"""
    layer_amines = []
    
    # å‡ºåŠ›å±¤ã‹ã‚‰å„éš ã‚Œå±¤ã¸ã®ã‚¢ãƒŸãƒ³æ‹¡æ•£
    for layer_depth in range(len(self.hidden_sizes) + 1):
        # æ‹¡æ•£ã«ã‚ˆã‚‹æ¸›è¡°
        amine = self.initial_amine * (self.diffusion_rate ** layer_depth)
        # èª¤å·®å¼·åº¦ã«ã‚ˆã‚‹èª¿æ•´
        amine *= np.mean(np.abs(output_error))
        layer_amines.append(amine)
    
    return layer_amines
```

**æŠ€è¡“çš„æ„ç¾©:**
- **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªæ·±å±¤å­¦ç¿’**
- **å®‰å®šã—ãŸå¤šå±¤å­¦ç¿’**
- **åŠ¹ç‡çš„ãªéšå±¤è¡¨ç¾å­¦ç¿’**

---

## ã¾ã¨ã‚

ã“ã®æŠ€è¡“ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§è§£èª¬ã—ãŸå®Ÿè£…ã¯ã€ä»¥ä¸‹ã®é©æ–°çš„ç‰¹å¾´ã‚’æŒã¡ã¾ã™ï¼š

### ğŸ§  ç”Ÿç‰©å­¦çš„å¦¥å½“æ€§
- **èª¤å·®é€†ä¼æ’­ã‚’ä½¿ã‚ãªã„**EDæ³•å­¦ç¿’
- **å®Œå…¨LIFåŒ–**ã«ã‚ˆã‚‹æ™‚é–“çš„ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹
- **E/Iãƒšã‚¢æ§‹é€ **ã¨Dale's Principle

### âš¡ æŠ€è¡“çš„å„ªä½æ€§
- **ä¸¦åˆ—è¨ˆç®—å¯èƒ½**ãªå­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
- **å‹¾é…æ¶ˆå¤±å•é¡Œã®æ ¹æœ¬çš„è§£æ±º**
- **GPU/CPUæŸ”è»Ÿå¯¾å¿œ**

### ğŸ”¬ ç ”ç©¶çš„ä¾¡å€¤
- **é‡‘å­å‹‡æ°ã‚ªãƒªã‚¸ãƒŠãƒ«ç†è«–**ã®å¿ å®Ÿãªå®Ÿè£…
- **ç¾ä»£çš„æœ€é©åŒ–æŠ€è¡“**ã¨ã®èåˆ
- **æ¬¡ä¸–ä»£AI**ã¸ã®ç¤ºå”†

ã“ã®å®Ÿè£…ã¯ã€ç”Ÿç‰©å­¦çš„çŸ¥èƒ½ã®è¨ˆç®—åŸç†ã‚’ç¾ä»£ã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ä¸Šã§å†ç¾ã—ã€å¾“æ¥ã®äººå·¥ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®é™ç•Œã‚’è¶…ãˆã‚‹æ–°ã—ã„å¯èƒ½æ€§ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚